{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-19T08:44:46.450912Z",
     "start_time": "2025-04-19T08:44:40.402376Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from enum import Enum\n",
    "from torch import nn\n",
    "from torcheval.metrics import MulticlassAccuracy, R2Score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T08:45:48.334534Z",
     "start_time": "2025-04-19T08:45:48.314534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RANDOM_STATE = 1337\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class Task(str, Enum):\n",
    "    CLASSIFICATION = 'classification'\n",
    "    REGRESSION = 'regression'\n",
    "\n",
    "\n",
    "loss_fn_map = {\n",
    "    Task.CLASSIFICATION: nn.CrossEntropyLoss(),\n",
    "    Task.REGRESSION: nn.MSELoss()\n",
    "}\n",
    "\n",
    "metric_map = {\n",
    "    Task.CLASSIFICATION: (MulticlassAccuracy, \"acc\"),\n",
    "    Task.REGRESSION: (R2Score, \"r2\")\n",
    "}\n",
    "\n",
    "AVB_TASKS = {Task.CLASSIFICATION, Task.REGRESSION}\n",
    "\n",
    "data_path = os.path.abspath(os.path.join('../', 'data'))\n",
    "diabetes_path = os.path.join(data_path, 'diabetes.csv')"
   ],
   "id": "fc80b054804daa09",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T08:45:49.235841Z",
     "start_time": "2025-04-19T08:45:49.211698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ANeuralNetwork(nn.Module):\n",
    "    def __init__(self, task, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        task = task.lower()\n",
    "        assert task in AVB_TASKS, f\"task: {task} should be either {AVB_TASKS}\"\n",
    "        self.output_dim = output_dim\n",
    "        if task == Task.REGRESSION:\n",
    "            self.output_dim = 1\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.out = nn.Linear(1024, self.output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return self.out(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        logits = self.forward(x)\n",
    "        if self.task == Task.CLASSIFICATION:\n",
    "            return torch.softmax(logits, dim=1)\n",
    "        else:\n",
    "            raise ValueError(\"probabilities <==> classification\")\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.task == Task.CLASSIFICATION:\n",
    "            return torch.argmax(self.forward(x), dim=1)\n",
    "        else:\n",
    "            return self.forward(x)\n",
    "\n",
    "\n",
    "class DiabetesTabularDataset(Dataset):\n",
    "    def __init__(self, diab_df, exclude_Y=False):\n",
    "        \"\"\" Implementing a custom case where we can put Y in and out of x.\n",
    "        exclude_Y = True ==> Y will not be in x (\"known\" variables)\n",
    "        We also return 2 kind of labels:\n",
    "            One is for classification (Class)\n",
    "            Other is for regression (Y)\n",
    "        We can think about rescaling all variables.\n",
    "        \"\"\"\n",
    "        self.orig_columns = diab_df.columns.values\n",
    "        self.exclude_Y = exclude_Y\n",
    "        drops = ['Class']\n",
    "\n",
    "        if exclude_Y:\n",
    "            drops = ['Y', 'Class']\n",
    "\n",
    "        self.x = torch.tensor(diab_df.drop(labels=drops, axis=1).values, dtype=torch.float32, device=DEVICE)\n",
    "        self.y_reg = torch.tensor(diab_df['Y'].values, dtype=torch.float32, device=DEVICE)\n",
    "        self.y_cat = torch.tensor(diab_df['Class'].values, dtype=torch.int64, device=DEVICE)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx) -> tuple:\n",
    "        \"\"\" returns, x, y_regression, y_categorical \"\"\"\n",
    "        return self.x[idx], self.y_reg[idx], self.y_cat[idx]\n",
    "\n",
    "\n",
    "def preprocess_df(df_path, n_cuts: int = 10):\n",
    "    # reading df, tab seperated\n",
    "    diabetes_df = pd.read_csv(df_path, sep='\\t')\n",
    "\n",
    "    # Calculating quantiles (which won't help us,\n",
    "    # since pandas got a better way to classify the quantiles)\n",
    "    # y_quantiles = diabetes_df[['Y']].quantile(q=np.arange(0.1, 1.1, 0.1))\n",
    "\n",
    "    # Classify the quantiles, renaming column to \"Class\"\n",
    "    y_categorical = pd.qcut(diabetes_df['Y'], n_cuts, labels=False)\n",
    "    y_categorical = y_categorical.rename(\"Class\")\n",
    "\n",
    "    diabetes_df = pd.concat([diabetes_df, y_categorical], axis=1)\n",
    "    return diabetes_df\n",
    "\n",
    "\n",
    "def questions_6_7():\n",
    "    \"\"\" Question 6 and 7, we create a Dataloader.\n",
    "    We create batches of size 10.\n",
    "    We print one batch.\n",
    "    \"\"\"\n",
    "    diabetes_df = preprocess_df(diabetes_path, 10)\n",
    "    train_diab_df, test_diab_df = train_test_split(\n",
    "        diabetes_df, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "    diabetes_dataset = DiabetesTabularDataset(train_diab_df)\n",
    "    diabetes_dataloder = DataLoader(diabetes_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "    x, y_reg, y_cat = next(iter(diabetes_dataloder))\n",
    "    # test all y_cat values are between 0 and 9 included\n",
    "\n",
    "    print(x, y_reg, y_cat)\n",
    "    print(len(diabetes_dataloder))\n",
    "\n",
    "\n",
    "def validation_loop(model, val_loader, loss_fn, task) -> (float, float):\n",
    "    \"\"\" run validation on val_loader, using loss_fn and metric using metric map and task.\n",
    "    returns the avg_loss, and metric value. \"\"\"\n",
    "    val_loss = 0.\n",
    "    assert task in AVB_TASKS, f\"{task} should be in {AVB_TASKS}\"\n",
    "    metric, metric_name = metric_map[task]\n",
    "    metric = metric(device=DEVICE)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y_reg, y_cls in val_loader:\n",
    "            preds = model(x).squeeze()\n",
    "            y_true = y_cls if task == 'classification' else y_reg\n",
    "            loss = loss_fn(preds, y_true)\n",
    "            metric.update(preds, y_true)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    return avg_val_loss, metric.compute()\n",
    "\n",
    "\n",
    "def train_model(\n",
    "        model: nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        valid_loader: DataLoader,\n",
    "        task: Task,\n",
    "        epochs: int = 10,\n",
    "        verbose: int = 1,\n",
    "        verbose_batch: int = 1,\n",
    "        lr: float = 1e-4,\n",
    "        wd: float = 0.05) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Given train/validation set, train the model `epochs` epochs, and validates at each epoch over\n",
    "    the validation set.\n",
    "    Required metric is Accuracy.\n",
    "\n",
    "    :param model:\n",
    "    :param train_loader:\n",
    "    :param valid_loader:\n",
    "    :param task: Task (currently 'classification' or 'regression')\n",
    "    :param epochs:\n",
    "    :param verbose: [0, 1, 2] Level of printing information (0 None, 2 Max)\n",
    "    :param verbose_batch: if verbose is 2, how many batches before printing metrices and loss.\n",
    "    :param lr: learning rate\n",
    "    :param wd: weight decay\n",
    "    :return: a model\n",
    "    \"\"\"\n",
    "\n",
    "    assert task in AVB_TASKS, f\"{task} should be in {AVB_TASKS}\"\n",
    "    loss_fn = loss_fn_map[task]\n",
    "    metric, metric_name = metric_map[task]\n",
    "    metric = metric(device=DEVICE)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.\n",
    "        model.train()\n",
    "        metric.reset()\n",
    "        for i, (x, y_reg, y_cls) in enumerate(train_loader):\n",
    "            opt.zero_grad()\n",
    "            preds = model(x).squeeze()\n",
    "            y_true = y_cls if task == Task.CLASSIFICATION else y_reg\n",
    "            loss = loss_fn(preds, y_true)\n",
    "            metric.update(preds, y_true)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Print every `verbose_batch` batches\n",
    "            if verbose >= 2 and i % verbose_batch == 0:\n",
    "                print(f\"Epoch [{epoch + 1}/{epochs}], \"\n",
    "                      f\"Step [{i}/{len(train_loader)}], \"\n",
    "                      f\"Loss: {loss.item():.4f}\", sep=',')\n",
    "\n",
    "        # End of epoch. Run validation and print outcomes\n",
    "        avg_val_loss, metric_val = validation_loop(model, valid_loader, loss_fn, task)\n",
    "        if verbose >= 1:\n",
    "            print(f\"Epoch [{epoch + 1:4}/{epochs}]\", end=f\", \")\n",
    "            print(f\"trn los: {running_loss / (epoch + 1):8.4f},\", f\"trn {metric_name}: {metric.compute():6.4f}\",\n",
    "                  end=', ')\n",
    "            print(f\"val loss: {avg_val_loss:8.4f}, val {metric_name}: {metric_val:6.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def general_solver(n_cuts=10,\n",
    "                   exclude_Y=False,\n",
    "                   task=Task.CLASSIFICATION,\n",
    "                   epochs=100, verbose=1,\n",
    "                   verbose_batch=10,\n",
    "                   lr: float = 1e-4):\n",
    "    \"\"\" we read the diabetes dataset, and create the \"Class\" column using n_cuts\n",
    "    We split to train and test (0.2)\n",
    "    We wrap the dataset with our custom DiabetesTabularDataset\n",
    "    and generate a DataLoader wrapping the dataset. batch_size is 10 and shuffle is True\n",
    "    We initialize (and instantiate) the neural network based on data (x.shape[1]) and n_cuts - which is\n",
    "    the output dim.\n",
    "    notice that n_cuts determine amount of classes (and our output dim)\n",
    "    We train, and watch resulted printed to screen. \"\"\"\n",
    "    diabetes_df = preprocess_df(diabetes_path, n_cuts)\n",
    "\n",
    "    # Stratification should be considered here.\n",
    "    # Weight balancing can be semi-ignored because of how we created the labels.\n",
    "    train_diab_df, valid_diab_df = train_test_split(\n",
    "        diabetes_df, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "    diab_training_ds = DiabetesTabularDataset(train_diab_df, exclude_Y=exclude_Y)\n",
    "    diab_training_dl = DataLoader(diab_training_ds, batch_size=10, shuffle=True)\n",
    "\n",
    "    diab_validation_ds = DiabetesTabularDataset(valid_diab_df, exclude_Y=exclude_Y)\n",
    "    diab_validation_dl = DataLoader(diab_validation_ds, batch_size=10, shuffle=True)\n",
    "\n",
    "    x, y_reg, y_cat = next(iter(diab_training_dl))\n",
    "\n",
    "    model = ANeuralNetwork(task=task, input_dim=x.shape[1], output_dim=n_cuts)\n",
    "    model.to(DEVICE)\n",
    "    model = train_model(model, diab_training_dl, diab_validation_dl, task=task, epochs=epochs, verbose=verbose,\n",
    "                        verbose_batch=verbose_batch, lr=lr)\n"
   ],
   "id": "aad19dd266ec9cdc",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T08:46:00.120428Z",
     "start_time": "2025-04-19T08:45:49.854295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def question_8():\n",
    "    general_solver(n_cuts=10, exclude_Y=False, task=Task.CLASSIFICATION, epochs=100)\n",
    "    # Epoch [   1/100], trn los: 190.9444, trn acc: 0.1530, val loss:   2.3679, val acc: 0.2472\n",
    "    # Epoch [ 100/100], trn los:   0.3279, trn acc: 0.5609, val loss:   0.9889, val acc: 0.5730\n",
    "\n",
    "question_8()"
   ],
   "id": "c40e78c845c8934f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [   1/100], trn los: 207.4843, trn acc: 0.1728, val loss:   2.3389, val acc: 0.1798\n",
      "Epoch [   2/100], trn los:  61.5089, trn acc: 0.2521, val loss:   2.1161, val acc: 0.3483\n",
      "Epoch [   3/100], trn los:  36.6176, trn acc: 0.2351, val loss:   1.4115, val acc: 0.4157\n",
      "Epoch [   4/100], trn los:  23.6608, trn acc: 0.2890, val loss:   1.4650, val acc: 0.4157\n",
      "Epoch [   5/100], trn los:  17.0875, trn acc: 0.2946, val loss:   1.7496, val acc: 0.4157\n",
      "Epoch [   6/100], trn los:  14.3922, trn acc: 0.3428, val loss:   1.2545, val acc: 0.4944\n",
      "Epoch [   7/100], trn los:  11.5731, trn acc: 0.2890, val loss:   1.5471, val acc: 0.3933\n",
      "Epoch [   8/100], trn los:   8.4177, trn acc: 0.3626, val loss:   1.4034, val acc: 0.3596\n",
      "Epoch [   9/100], trn los:   7.0692, trn acc: 0.3343, val loss:   1.4493, val acc: 0.3596\n",
      "Epoch [  10/100], trn los:   6.2698, trn acc: 0.3796, val loss:   1.3220, val acc: 0.3820\n",
      "Epoch [  11/100], trn los:   5.5316, trn acc: 0.3768, val loss:   1.7726, val acc: 0.3258\n",
      "Epoch [  12/100], trn los:   5.7638, trn acc: 0.3371, val loss:   1.3544, val acc: 0.3933\n",
      "Epoch [  13/100], trn los:   4.3453, trn acc: 0.3853, val loss:   1.5668, val acc: 0.3258\n",
      "Epoch [  14/100], trn los:   4.3129, trn acc: 0.3173, val loss:   1.2558, val acc: 0.4157\n",
      "Epoch [  15/100], trn los:   3.5044, trn acc: 0.4079, val loss:   1.1872, val acc: 0.4494\n",
      "Epoch [  16/100], trn los:   3.2693, trn acc: 0.4193, val loss:   1.2473, val acc: 0.4719\n",
      "Epoch [  17/100], trn los:   2.9657, trn acc: 0.4504, val loss:   1.2108, val acc: 0.4719\n",
      "Epoch [  18/100], trn los:   2.9321, trn acc: 0.3824, val loss:   1.2213, val acc: 0.4719\n",
      "Epoch [  19/100], trn los:   2.5722, trn acc: 0.4391, val loss:   1.3177, val acc: 0.4831\n",
      "Epoch [  20/100], trn los:   2.5325, trn acc: 0.4674, val loss:   1.3151, val acc: 0.4831\n",
      "Epoch [  21/100], trn los:   2.3951, trn acc: 0.4108, val loss:   1.1374, val acc: 0.5506\n",
      "Epoch [  22/100], trn los:   2.1762, trn acc: 0.4306, val loss:   1.2514, val acc: 0.3708\n",
      "Epoch [  23/100], trn los:   1.9703, trn acc: 0.4844, val loss:   1.0945, val acc: 0.4719\n",
      "Epoch [  24/100], trn los:   2.0341, trn acc: 0.3796, val loss:   1.1059, val acc: 0.5169\n",
      "Epoch [  25/100], trn los:   1.8418, trn acc: 0.4533, val loss:   1.1464, val acc: 0.4494\n",
      "Epoch [  26/100], trn los:   1.7980, trn acc: 0.4391, val loss:   1.2197, val acc: 0.4270\n",
      "Epoch [  27/100], trn los:   1.6054, trn acc: 0.4929, val loss:   1.1065, val acc: 0.5169\n",
      "Epoch [  28/100], trn los:   1.5355, trn acc: 0.4731, val loss:   1.0960, val acc: 0.4494\n",
      "Epoch [  29/100], trn los:   1.6996, trn acc: 0.4136, val loss:   1.2624, val acc: 0.4270\n",
      "Epoch [  30/100], trn los:   1.3756, trn acc: 0.5156, val loss:   1.2044, val acc: 0.4382\n",
      "Epoch [  31/100], trn los:   1.3870, trn acc: 0.4929, val loss:   1.1423, val acc: 0.4719\n",
      "Epoch [  32/100], trn los:   1.3916, trn acc: 0.4816, val loss:   1.2145, val acc: 0.4494\n",
      "Epoch [  33/100], trn los:   1.2624, trn acc: 0.4816, val loss:   1.2631, val acc: 0.4382\n",
      "Epoch [  34/100], trn los:   1.1689, trn acc: 0.4844, val loss:   1.0535, val acc: 0.5281\n",
      "Epoch [  35/100], trn los:   1.2733, trn acc: 0.4504, val loss:   1.2179, val acc: 0.5056\n",
      "Epoch [  36/100], trn los:   1.1136, trn acc: 0.4901, val loss:   1.1793, val acc: 0.4045\n",
      "Epoch [  37/100], trn los:   1.1334, trn acc: 0.4504, val loss:   1.2286, val acc: 0.5056\n",
      "Epoch [  38/100], trn los:   1.0802, trn acc: 0.4504, val loss:   1.2044, val acc: 0.4831\n",
      "Epoch [  39/100], trn los:   1.0304, trn acc: 0.4703, val loss:   0.9924, val acc: 0.5506\n",
      "Epoch [  40/100], trn los:   1.0622, trn acc: 0.4759, val loss:   1.1174, val acc: 0.4944\n",
      "Epoch [  41/100], trn los:   1.0072, trn acc: 0.4929, val loss:   1.1762, val acc: 0.4719\n",
      "Epoch [  42/100], trn los:   1.0359, trn acc: 0.4533, val loss:   1.0775, val acc: 0.4382\n",
      "Epoch [  43/100], trn los:   0.8779, trn acc: 0.5071, val loss:   1.2072, val acc: 0.4270\n",
      "Epoch [  44/100], trn los:   0.8758, trn acc: 0.4816, val loss:   1.1189, val acc: 0.4831\n",
      "Epoch [  45/100], trn los:   0.9290, trn acc: 0.4618, val loss:   1.0368, val acc: 0.5393\n",
      "Epoch [  46/100], trn los:   0.9029, trn acc: 0.4844, val loss:   1.1009, val acc: 0.5169\n",
      "Epoch [  47/100], trn los:   0.8100, trn acc: 0.5014, val loss:   1.0672, val acc: 0.4944\n",
      "Epoch [  48/100], trn los:   0.7905, trn acc: 0.4958, val loss:   1.0804, val acc: 0.5618\n",
      "Epoch [  49/100], trn los:   0.7779, trn acc: 0.4986, val loss:   1.1177, val acc: 0.4944\n",
      "Epoch [  50/100], trn los:   0.7295, trn acc: 0.4929, val loss:   1.0059, val acc: 0.5506\n",
      "Epoch [  51/100], trn los:   0.7382, trn acc: 0.5467, val loss:   1.1461, val acc: 0.3933\n",
      "Epoch [  52/100], trn los:   0.7103, trn acc: 0.5042, val loss:   1.0986, val acc: 0.4944\n",
      "Epoch [  53/100], trn los:   0.7102, trn acc: 0.5156, val loss:   1.0173, val acc: 0.4607\n",
      "Epoch [  54/100], trn los:   0.6793, trn acc: 0.5496, val loss:   1.0503, val acc: 0.5056\n",
      "Epoch [  55/100], trn los:   0.6996, trn acc: 0.5042, val loss:   1.1602, val acc: 0.4944\n",
      "Epoch [  56/100], trn los:   0.7017, trn acc: 0.4731, val loss:   1.1904, val acc: 0.4831\n",
      "Epoch [  57/100], trn los:   0.6453, trn acc: 0.5722, val loss:   1.1243, val acc: 0.4944\n",
      "Epoch [  58/100], trn los:   0.6522, trn acc: 0.5382, val loss:   1.1398, val acc: 0.4719\n",
      "Epoch [  59/100], trn los:   0.6590, trn acc: 0.5099, val loss:   1.2752, val acc: 0.4494\n",
      "Epoch [  60/100], trn los:   0.6134, trn acc: 0.5326, val loss:   1.1345, val acc: 0.4719\n",
      "Epoch [  61/100], trn los:   0.6235, trn acc: 0.5042, val loss:   1.0520, val acc: 0.4944\n",
      "Epoch [  62/100], trn los:   0.5850, trn acc: 0.5354, val loss:   1.0378, val acc: 0.5393\n",
      "Epoch [  63/100], trn los:   0.5837, trn acc: 0.5212, val loss:   1.0534, val acc: 0.5393\n",
      "Epoch [  64/100], trn los:   0.5860, trn acc: 0.5382, val loss:   1.0363, val acc: 0.5169\n",
      "Epoch [  65/100], trn los:   0.5789, trn acc: 0.5099, val loss:   1.0383, val acc: 0.5393\n",
      "Epoch [  66/100], trn los:   0.5617, trn acc: 0.5099, val loss:   1.2633, val acc: 0.4719\n",
      "Epoch [  67/100], trn los:   0.5553, trn acc: 0.5156, val loss:   1.0462, val acc: 0.5393\n",
      "Epoch [  68/100], trn los:   0.5330, trn acc: 0.5467, val loss:   1.1140, val acc: 0.5056\n",
      "Epoch [  69/100], trn los:   0.5216, trn acc: 0.5269, val loss:   1.0932, val acc: 0.5393\n",
      "Epoch [  70/100], trn los:   0.5051, trn acc: 0.5184, val loss:   1.1058, val acc: 0.4944\n",
      "Epoch [  71/100], trn los:   0.4890, trn acc: 0.5666, val loss:   1.2274, val acc: 0.4831\n",
      "Epoch [  72/100], trn los:   0.5050, trn acc: 0.5326, val loss:   0.9621, val acc: 0.6180\n",
      "Epoch [  73/100], trn los:   0.4559, trn acc: 0.5949, val loss:   1.0900, val acc: 0.4719\n",
      "Epoch [  74/100], trn los:   0.4781, trn acc: 0.5439, val loss:   1.0182, val acc: 0.4831\n",
      "Epoch [  75/100], trn los:   0.4637, trn acc: 0.5609, val loss:   1.0841, val acc: 0.5281\n",
      "Epoch [  76/100], trn los:   0.4701, trn acc: 0.5581, val loss:   1.2660, val acc: 0.4831\n",
      "Epoch [  77/100], trn los:   0.4453, trn acc: 0.5609, val loss:   1.0166, val acc: 0.5506\n",
      "Epoch [  78/100], trn los:   0.4875, trn acc: 0.4873, val loss:   1.0801, val acc: 0.5056\n",
      "Epoch [  79/100], trn los:   0.4214, trn acc: 0.6176, val loss:   0.9982, val acc: 0.5393\n",
      "Epoch [  80/100], trn los:   0.4605, trn acc: 0.5496, val loss:   1.1860, val acc: 0.4831\n",
      "Epoch [  81/100], trn los:   0.4388, trn acc: 0.5581, val loss:   1.1650, val acc: 0.5281\n",
      "Epoch [  82/100], trn los:   0.4342, trn acc: 0.5297, val loss:   1.1158, val acc: 0.5169\n",
      "Epoch [  83/100], trn los:   0.4102, trn acc: 0.5326, val loss:   1.1564, val acc: 0.5056\n",
      "Epoch [  84/100], trn los:   0.4208, trn acc: 0.5552, val loss:   1.1555, val acc: 0.4719\n",
      "Epoch [  85/100], trn los:   0.4194, trn acc: 0.5212, val loss:   1.0070, val acc: 0.5506\n",
      "Epoch [  86/100], trn los:   0.4349, trn acc: 0.5269, val loss:   0.9944, val acc: 0.5955\n",
      "Epoch [  87/100], trn los:   0.4007, trn acc: 0.5411, val loss:   1.0900, val acc: 0.5730\n",
      "Epoch [  88/100], trn los:   0.3843, trn acc: 0.5666, val loss:   1.0391, val acc: 0.5056\n",
      "Epoch [  89/100], trn los:   0.3933, trn acc: 0.5326, val loss:   1.1872, val acc: 0.4382\n",
      "Epoch [  90/100], trn los:   0.3880, trn acc: 0.5354, val loss:   1.1287, val acc: 0.5169\n",
      "Epoch [  91/100], trn los:   0.3906, trn acc: 0.5524, val loss:   1.1193, val acc: 0.5056\n",
      "Epoch [  92/100], trn los:   0.3972, trn acc: 0.5694, val loss:   1.1515, val acc: 0.4719\n",
      "Epoch [  93/100], trn los:   0.3596, trn acc: 0.5694, val loss:   1.1422, val acc: 0.4607\n",
      "Epoch [  94/100], trn los:   0.3520, trn acc: 0.5807, val loss:   1.0683, val acc: 0.5730\n",
      "Epoch [  95/100], trn los:   0.3598, trn acc: 0.5666, val loss:   1.0379, val acc: 0.5506\n",
      "Epoch [  96/100], trn los:   0.3441, trn acc: 0.6006, val loss:   1.1712, val acc: 0.4719\n",
      "Epoch [  97/100], trn los:   0.3537, trn acc: 0.5354, val loss:   1.2655, val acc: 0.5169\n",
      "Epoch [  98/100], trn los:   0.3538, trn acc: 0.5779, val loss:   1.0882, val acc: 0.5506\n",
      "Epoch [  99/100], trn los:   0.3314, trn acc: 0.5524, val loss:   0.9934, val acc: 0.5843\n",
      "Epoch [ 100/100], trn los:   0.3346, trn acc: 0.5864, val loss:   1.0608, val acc: 0.5730\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T08:47:20.498959Z",
     "start_time": "2025-04-19T08:46:29.578556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def question_9():\n",
    "    general_solver(n_cuts=10, exclude_Y=True, task=Task.CLASSIFICATION, epochs=500)\n",
    "    # Epoch [   5/500], trn los:  21.1454, trn acc: 0.1133, val loss:   2.5425, val acc: 0.0787\n",
    "    # Epoch [ 500/500], trn los:   0.1397, trn acc: 0.2975, val loss:   2.0022, val acc: 0.2135\n",
    "\n",
    "question_9()"
   ],
   "id": "7108c0c4344b4f09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [   1/500], trn los: 204.1978, trn acc: 0.1020, val loss:   2.7888, val acc: 0.1124\n",
      "Epoch [   2/500], trn los:  76.9981, trn acc: 0.1133, val loss:   3.1039, val acc: 0.0562\n",
      "Epoch [   3/500], trn los:  45.6112, trn acc: 0.1048, val loss:   2.4581, val acc: 0.1461\n",
      "Epoch [   4/500], trn los:  30.9191, trn acc: 0.0992, val loss:   2.4122, val acc: 0.1236\n",
      "Epoch [   5/500], trn los:  21.5485, trn acc: 0.1360, val loss:   2.3904, val acc: 0.1798\n",
      "Epoch [   6/500], trn los:  17.6079, trn acc: 0.1360, val loss:   2.3474, val acc: 0.1236\n",
      "Epoch [   7/500], trn los:  14.3318, trn acc: 0.1161, val loss:   2.2968, val acc: 0.1124\n",
      "Epoch [   8/500], trn los:  12.0636, trn acc: 0.1246, val loss:   2.2936, val acc: 0.1685\n",
      "Epoch [   9/500], trn los:  10.6704, trn acc: 0.1275, val loss:   2.2251, val acc: 0.1348\n",
      "Epoch [  10/500], trn los:   9.3776, trn acc: 0.1218, val loss:   2.3004, val acc: 0.0899\n",
      "Epoch [  11/500], trn los:   8.1675, trn acc: 0.1416, val loss:   2.2822, val acc: 0.1124\n",
      "Epoch [  12/500], trn los:   7.6417, trn acc: 0.1416, val loss:   2.2787, val acc: 0.1910\n",
      "Epoch [  13/500], trn los:   6.8176, trn acc: 0.1615, val loss:   2.2407, val acc: 0.1798\n",
      "Epoch [  14/500], trn los:   6.2346, trn acc: 0.1303, val loss:   2.2560, val acc: 0.1685\n",
      "Epoch [  15/500], trn los:   5.7915, trn acc: 0.1133, val loss:   2.2541, val acc: 0.1685\n",
      "Epoch [  16/500], trn los:   5.2858, trn acc: 0.1501, val loss:   2.2717, val acc: 0.1011\n",
      "Epoch [  17/500], trn los:   5.1367, trn acc: 0.1841, val loss:   2.2026, val acc: 0.1798\n",
      "Epoch [  18/500], trn los:   4.6707, trn acc: 0.1615, val loss:   2.2964, val acc: 0.1348\n",
      "Epoch [  19/500], trn los:   4.6553, trn acc: 0.1218, val loss:   2.1937, val acc: 0.1910\n",
      "Epoch [  20/500], trn los:   4.1616, trn acc: 0.1643, val loss:   2.2326, val acc: 0.1236\n",
      "Epoch [  21/500], trn los:   4.0721, trn acc: 0.1558, val loss:   2.2088, val acc: 0.1685\n",
      "Epoch [  22/500], trn los:   3.8705, trn acc: 0.1445, val loss:   2.2333, val acc: 0.1236\n",
      "Epoch [  23/500], trn los:   3.5960, trn acc: 0.1558, val loss:   2.2210, val acc: 0.1348\n",
      "Epoch [  24/500], trn los:   3.4308, trn acc: 0.1501, val loss:   2.1886, val acc: 0.1573\n",
      "Epoch [  25/500], trn los:   3.3193, trn acc: 0.1275, val loss:   2.2301, val acc: 0.1236\n",
      "Epoch [  26/500], trn los:   3.2204, trn acc: 0.1615, val loss:   2.2291, val acc: 0.1348\n",
      "Epoch [  27/500], trn los:   3.1137, trn acc: 0.1218, val loss:   2.2080, val acc: 0.1573\n",
      "Epoch [  28/500], trn los:   2.9868, trn acc: 0.1388, val loss:   2.2397, val acc: 0.1461\n",
      "Epoch [  29/500], trn los:   2.8353, trn acc: 0.1501, val loss:   2.1973, val acc: 0.1798\n",
      "Epoch [  30/500], trn los:   2.7307, trn acc: 0.1360, val loss:   2.1962, val acc: 0.1910\n",
      "Epoch [  31/500], trn los:   2.6954, trn acc: 0.1416, val loss:   2.1660, val acc: 0.1348\n",
      "Epoch [  32/500], trn los:   2.5686, trn acc: 0.1586, val loss:   2.2103, val acc: 0.1798\n",
      "Epoch [  33/500], trn los:   2.4733, trn acc: 0.1558, val loss:   2.1667, val acc: 0.2247\n",
      "Epoch [  34/500], trn los:   2.4295, trn acc: 0.1388, val loss:   2.1970, val acc: 0.1573\n",
      "Epoch [  35/500], trn los:   2.3523, trn acc: 0.1360, val loss:   2.1858, val acc: 0.1236\n",
      "Epoch [  36/500], trn los:   2.2454, trn acc: 0.1558, val loss:   2.1728, val acc: 0.1461\n",
      "Epoch [  37/500], trn los:   2.1812, trn acc: 0.1813, val loss:   2.1864, val acc: 0.1236\n",
      "Epoch [  38/500], trn los:   2.0954, trn acc: 0.1785, val loss:   2.1753, val acc: 0.1910\n",
      "Epoch [  39/500], trn los:   2.0661, trn acc: 0.1785, val loss:   2.1649, val acc: 0.1910\n",
      "Epoch [  40/500], trn los:   2.0063, trn acc: 0.1700, val loss:   2.1547, val acc: 0.1461\n",
      "Epoch [  41/500], trn los:   1.9518, trn acc: 0.1558, val loss:   2.1810, val acc: 0.1685\n",
      "Epoch [  42/500], trn los:   1.9232, trn acc: 0.1643, val loss:   2.1524, val acc: 0.2360\n",
      "Epoch [  43/500], trn los:   1.8399, trn acc: 0.1870, val loss:   2.1954, val acc: 0.1348\n",
      "Epoch [  44/500], trn los:   1.8111, trn acc: 0.1643, val loss:   2.1357, val acc: 0.1798\n",
      "Epoch [  45/500], trn los:   1.7636, trn acc: 0.2040, val loss:   2.1444, val acc: 0.1461\n",
      "Epoch [  46/500], trn los:   1.7570, trn acc: 0.1728, val loss:   2.1434, val acc: 0.1685\n",
      "Epoch [  47/500], trn los:   1.7044, trn acc: 0.1388, val loss:   2.1319, val acc: 0.2022\n",
      "Epoch [  48/500], trn los:   1.6536, trn acc: 0.1841, val loss:   2.1307, val acc: 0.1461\n",
      "Epoch [  49/500], trn los:   1.6093, trn acc: 0.1898, val loss:   2.1416, val acc: 0.1236\n",
      "Epoch [  50/500], trn los:   1.5835, trn acc: 0.1785, val loss:   2.1654, val acc: 0.1685\n",
      "Epoch [  51/500], trn los:   1.5568, trn acc: 0.1586, val loss:   2.1475, val acc: 0.1573\n",
      "Epoch [  52/500], trn los:   1.5386, trn acc: 0.1643, val loss:   2.1336, val acc: 0.1236\n",
      "Epoch [  53/500], trn los:   1.5021, trn acc: 0.1360, val loss:   2.1285, val acc: 0.2135\n",
      "Epoch [  54/500], trn los:   1.4660, trn acc: 0.1416, val loss:   2.1390, val acc: 0.1910\n",
      "Epoch [  55/500], trn los:   1.4650, trn acc: 0.1360, val loss:   2.1780, val acc: 0.1236\n",
      "Epoch [  56/500], trn los:   1.3998, trn acc: 0.1700, val loss:   2.1613, val acc: 0.1573\n",
      "Epoch [  57/500], trn los:   1.3844, trn acc: 0.1615, val loss:   2.1180, val acc: 0.1910\n",
      "Epoch [  58/500], trn los:   1.3612, trn acc: 0.2040, val loss:   2.1646, val acc: 0.1348\n",
      "Epoch [  59/500], trn los:   1.3404, trn acc: 0.1700, val loss:   2.1694, val acc: 0.1798\n",
      "Epoch [  60/500], trn los:   1.2967, trn acc: 0.1870, val loss:   2.1123, val acc: 0.2022\n",
      "Epoch [  61/500], trn los:   1.2929, trn acc: 0.1813, val loss:   2.1187, val acc: 0.1573\n",
      "Epoch [  62/500], trn los:   1.2635, trn acc: 0.1671, val loss:   2.1119, val acc: 0.1798\n",
      "Epoch [  63/500], trn los:   1.2521, trn acc: 0.1586, val loss:   2.1281, val acc: 0.1685\n",
      "Epoch [  64/500], trn los:   1.2318, trn acc: 0.1785, val loss:   2.1285, val acc: 0.2022\n",
      "Epoch [  65/500], trn los:   1.2061, trn acc: 0.1813, val loss:   2.1316, val acc: 0.2135\n",
      "Epoch [  66/500], trn los:   1.1967, trn acc: 0.1870, val loss:   2.1337, val acc: 0.1910\n",
      "Epoch [  67/500], trn los:   1.1631, trn acc: 0.1898, val loss:   2.1121, val acc: 0.1798\n",
      "Epoch [  68/500], trn los:   1.1694, trn acc: 0.1728, val loss:   2.1410, val acc: 0.1573\n",
      "Epoch [  69/500], trn los:   1.1401, trn acc: 0.1870, val loss:   2.1618, val acc: 0.1910\n",
      "Epoch [  70/500], trn los:   1.1273, trn acc: 0.1615, val loss:   2.1347, val acc: 0.1348\n",
      "Epoch [  71/500], trn los:   1.1073, trn acc: 0.1841, val loss:   2.1262, val acc: 0.2135\n",
      "Epoch [  72/500], trn los:   1.0917, trn acc: 0.2011, val loss:   2.1230, val acc: 0.1798\n",
      "Epoch [  73/500], trn los:   1.0745, trn acc: 0.1926, val loss:   2.1311, val acc: 0.1573\n",
      "Epoch [  74/500], trn los:   1.0734, trn acc: 0.1643, val loss:   2.1181, val acc: 0.1348\n",
      "Epoch [  75/500], trn los:   1.0360, trn acc: 0.1870, val loss:   2.1370, val acc: 0.1461\n",
      "Epoch [  76/500], trn los:   1.0435, trn acc: 0.1756, val loss:   2.1261, val acc: 0.1910\n",
      "Epoch [  77/500], trn los:   1.0370, trn acc: 0.1785, val loss:   2.1367, val acc: 0.2135\n",
      "Epoch [  78/500], trn los:   0.9951, trn acc: 0.1841, val loss:   2.1340, val acc: 0.1798\n",
      "Epoch [  79/500], trn los:   0.9771, trn acc: 0.1785, val loss:   2.1151, val acc: 0.2247\n",
      "Epoch [  80/500], trn los:   0.9871, trn acc: 0.1388, val loss:   2.1057, val acc: 0.1685\n",
      "Epoch [  81/500], trn los:   0.9637, trn acc: 0.1530, val loss:   2.1071, val acc: 0.2022\n",
      "Epoch [  82/500], trn los:   0.9626, trn acc: 0.1785, val loss:   2.1252, val acc: 0.1910\n",
      "Epoch [  83/500], trn los:   0.9412, trn acc: 0.1728, val loss:   2.1365, val acc: 0.1685\n",
      "Epoch [  84/500], trn los:   0.9386, trn acc: 0.1501, val loss:   2.1087, val acc: 0.1910\n",
      "Epoch [  85/500], trn los:   0.9158, trn acc: 0.1813, val loss:   2.1077, val acc: 0.2247\n",
      "Epoch [  86/500], trn los:   0.9048, trn acc: 0.1700, val loss:   2.1245, val acc: 0.1685\n",
      "Epoch [  87/500], trn los:   0.9006, trn acc: 0.1615, val loss:   2.1163, val acc: 0.2022\n",
      "Epoch [  88/500], trn los:   0.8847, trn acc: 0.1785, val loss:   2.1174, val acc: 0.1685\n",
      "Epoch [  89/500], trn los:   0.8868, trn acc: 0.1785, val loss:   2.1192, val acc: 0.2022\n",
      "Epoch [  90/500], trn los:   0.8528, trn acc: 0.1983, val loss:   2.1091, val acc: 0.1573\n",
      "Epoch [  91/500], trn los:   0.8510, trn acc: 0.1841, val loss:   2.1172, val acc: 0.1573\n",
      "Epoch [  92/500], trn los:   0.8360, trn acc: 0.1955, val loss:   2.0990, val acc: 0.1236\n",
      "Epoch [  93/500], trn los:   0.8344, trn acc: 0.1841, val loss:   2.1233, val acc: 0.1461\n",
      "Epoch [  94/500], trn los:   0.8171, trn acc: 0.1870, val loss:   2.1560, val acc: 0.1461\n",
      "Epoch [  95/500], trn los:   0.8229, trn acc: 0.1841, val loss:   2.0984, val acc: 0.1910\n",
      "Epoch [  96/500], trn los:   0.8048, trn acc: 0.1926, val loss:   2.0907, val acc: 0.2472\n",
      "Epoch [  97/500], trn los:   0.7906, trn acc: 0.1785, val loss:   2.0837, val acc: 0.1910\n",
      "Epoch [  98/500], trn los:   0.8033, trn acc: 0.1813, val loss:   2.0949, val acc: 0.1685\n",
      "Epoch [  99/500], trn los:   0.7860, trn acc: 0.1643, val loss:   2.1318, val acc: 0.1573\n",
      "Epoch [ 100/500], trn los:   0.7817, trn acc: 0.1756, val loss:   2.0972, val acc: 0.1798\n",
      "Epoch [ 101/500], trn los:   0.7547, trn acc: 0.2011, val loss:   2.1018, val acc: 0.1910\n",
      "Epoch [ 102/500], trn los:   0.7678, trn acc: 0.1785, val loss:   2.1161, val acc: 0.1685\n",
      "Epoch [ 103/500], trn los:   0.7530, trn acc: 0.1700, val loss:   2.0947, val acc: 0.1798\n",
      "Epoch [ 104/500], trn los:   0.7405, trn acc: 0.1898, val loss:   2.0943, val acc: 0.1798\n",
      "Epoch [ 105/500], trn los:   0.7292, trn acc: 0.1870, val loss:   2.0831, val acc: 0.1910\n",
      "Epoch [ 106/500], trn los:   0.7269, trn acc: 0.1643, val loss:   2.0894, val acc: 0.1910\n",
      "Epoch [ 107/500], trn los:   0.7219, trn acc: 0.2011, val loss:   2.1020, val acc: 0.1461\n",
      "Epoch [ 108/500], trn los:   0.7130, trn acc: 0.2040, val loss:   2.0829, val acc: 0.1461\n",
      "Epoch [ 109/500], trn los:   0.7158, trn acc: 0.1530, val loss:   2.0804, val acc: 0.1798\n",
      "Epoch [ 110/500], trn los:   0.7005, trn acc: 0.2040, val loss:   2.0765, val acc: 0.1910\n",
      "Epoch [ 111/500], trn los:   0.6949, trn acc: 0.1870, val loss:   2.0743, val acc: 0.2022\n",
      "Epoch [ 112/500], trn los:   0.6906, trn acc: 0.1870, val loss:   2.0944, val acc: 0.1798\n",
      "Epoch [ 113/500], trn los:   0.6819, trn acc: 0.1870, val loss:   2.0841, val acc: 0.1910\n",
      "Epoch [ 114/500], trn los:   0.6858, trn acc: 0.1813, val loss:   2.0990, val acc: 0.1685\n",
      "Epoch [ 115/500], trn los:   0.6751, trn acc: 0.2068, val loss:   2.0979, val acc: 0.1573\n",
      "Epoch [ 116/500], trn los:   0.6603, trn acc: 0.2011, val loss:   2.0909, val acc: 0.1685\n",
      "Epoch [ 117/500], trn los:   0.6594, trn acc: 0.1785, val loss:   2.0817, val acc: 0.1685\n",
      "Epoch [ 118/500], trn los:   0.6448, trn acc: 0.1983, val loss:   2.0736, val acc: 0.1910\n",
      "Epoch [ 119/500], trn los:   0.6506, trn acc: 0.1983, val loss:   2.0738, val acc: 0.1798\n",
      "Epoch [ 120/500], trn los:   0.6375, trn acc: 0.2125, val loss:   2.0677, val acc: 0.1910\n",
      "Epoch [ 121/500], trn los:   0.6435, trn acc: 0.1643, val loss:   2.0678, val acc: 0.1348\n",
      "Epoch [ 122/500], trn los:   0.6275, trn acc: 0.1813, val loss:   2.0821, val acc: 0.1461\n",
      "Epoch [ 123/500], trn los:   0.6225, trn acc: 0.2266, val loss:   2.0934, val acc: 0.1461\n",
      "Epoch [ 124/500], trn los:   0.6190, trn acc: 0.1983, val loss:   2.0721, val acc: 0.1685\n",
      "Epoch [ 125/500], trn los:   0.6124, trn acc: 0.2153, val loss:   2.0926, val acc: 0.1685\n",
      "Epoch [ 126/500], trn los:   0.6034, trn acc: 0.1926, val loss:   2.0817, val acc: 0.1910\n",
      "Epoch [ 127/500], trn los:   0.6091, trn acc: 0.1700, val loss:   2.0647, val acc: 0.1910\n",
      "Epoch [ 128/500], trn los:   0.5968, trn acc: 0.1671, val loss:   2.0750, val acc: 0.1910\n",
      "Epoch [ 129/500], trn los:   0.5977, trn acc: 0.1870, val loss:   2.0731, val acc: 0.1573\n",
      "Epoch [ 130/500], trn los:   0.5893, trn acc: 0.2011, val loss:   2.0927, val acc: 0.1798\n",
      "Epoch [ 131/500], trn los:   0.5931, trn acc: 0.2068, val loss:   2.0697, val acc: 0.1910\n",
      "Epoch [ 132/500], trn los:   0.5783, trn acc: 0.1983, val loss:   2.0677, val acc: 0.1910\n",
      "Epoch [ 133/500], trn los:   0.5772, trn acc: 0.1955, val loss:   2.1038, val acc: 0.1573\n",
      "Epoch [ 134/500], trn los:   0.5680, trn acc: 0.1841, val loss:   2.1442, val acc: 0.1573\n",
      "Epoch [ 135/500], trn los:   0.5695, trn acc: 0.1983, val loss:   2.0918, val acc: 0.1573\n",
      "Epoch [ 136/500], trn los:   0.5677, trn acc: 0.2068, val loss:   2.0794, val acc: 0.1573\n",
      "Epoch [ 137/500], trn los:   0.5660, trn acc: 0.1955, val loss:   2.1026, val acc: 0.1461\n",
      "Epoch [ 138/500], trn los:   0.5515, trn acc: 0.1926, val loss:   2.1178, val acc: 0.1798\n",
      "Epoch [ 139/500], trn los:   0.5513, trn acc: 0.1926, val loss:   2.0708, val acc: 0.1910\n",
      "Epoch [ 140/500], trn los:   0.5399, trn acc: 0.2096, val loss:   2.0760, val acc: 0.1798\n",
      "Epoch [ 141/500], trn los:   0.5447, trn acc: 0.1813, val loss:   2.0714, val acc: 0.1685\n",
      "Epoch [ 142/500], trn los:   0.5379, trn acc: 0.1898, val loss:   2.0590, val acc: 0.1910\n",
      "Epoch [ 143/500], trn los:   0.5234, trn acc: 0.2068, val loss:   2.0536, val acc: 0.1910\n",
      "Epoch [ 144/500], trn los:   0.5394, trn acc: 0.1756, val loss:   2.0668, val acc: 0.1685\n",
      "Epoch [ 145/500], trn los:   0.5183, trn acc: 0.2125, val loss:   2.0990, val acc: 0.1685\n",
      "Epoch [ 146/500], trn los:   0.5290, trn acc: 0.2125, val loss:   2.0676, val acc: 0.1685\n",
      "Epoch [ 147/500], trn los:   0.5147, trn acc: 0.2125, val loss:   2.0601, val acc: 0.2022\n",
      "Epoch [ 148/500], trn los:   0.5171, trn acc: 0.2011, val loss:   2.0706, val acc: 0.1685\n",
      "Epoch [ 149/500], trn los:   0.5088, trn acc: 0.2210, val loss:   2.0616, val acc: 0.1910\n",
      "Epoch [ 150/500], trn los:   0.5049, trn acc: 0.1983, val loss:   2.0583, val acc: 0.1798\n",
      "Epoch [ 151/500], trn los:   0.5004, trn acc: 0.1926, val loss:   2.0594, val acc: 0.2022\n",
      "Epoch [ 152/500], trn los:   0.4966, trn acc: 0.2238, val loss:   2.0905, val acc: 0.1798\n",
      "Epoch [ 153/500], trn los:   0.4964, trn acc: 0.2210, val loss:   2.0788, val acc: 0.1798\n",
      "Epoch [ 154/500], trn los:   0.4898, trn acc: 0.2380, val loss:   2.0738, val acc: 0.1685\n",
      "Epoch [ 155/500], trn los:   0.4869, trn acc: 0.1926, val loss:   2.0625, val acc: 0.1798\n",
      "Epoch [ 156/500], trn los:   0.4931, trn acc: 0.1643, val loss:   2.0628, val acc: 0.2247\n",
      "Epoch [ 157/500], trn los:   0.4845, trn acc: 0.1841, val loss:   2.0627, val acc: 0.1798\n",
      "Epoch [ 158/500], trn los:   0.4763, trn acc: 0.1983, val loss:   2.0576, val acc: 0.1910\n",
      "Epoch [ 159/500], trn los:   0.4726, trn acc: 0.1983, val loss:   2.0661, val acc: 0.1685\n",
      "Epoch [ 160/500], trn los:   0.4732, trn acc: 0.2323, val loss:   2.0590, val acc: 0.1910\n",
      "Epoch [ 161/500], trn los:   0.4652, trn acc: 0.2096, val loss:   2.0473, val acc: 0.2022\n",
      "Epoch [ 162/500], trn los:   0.4712, trn acc: 0.2011, val loss:   2.0537, val acc: 0.1685\n",
      "Epoch [ 163/500], trn los:   0.4638, trn acc: 0.1983, val loss:   2.0515, val acc: 0.2022\n",
      "Epoch [ 164/500], trn los:   0.4646, trn acc: 0.1926, val loss:   2.0528, val acc: 0.1798\n",
      "Epoch [ 165/500], trn los:   0.4682, trn acc: 0.1756, val loss:   2.0486, val acc: 0.1685\n",
      "Epoch [ 166/500], trn los:   0.4573, trn acc: 0.2125, val loss:   2.0622, val acc: 0.1910\n",
      "Epoch [ 167/500], trn los:   0.4447, trn acc: 0.1841, val loss:   2.0662, val acc: 0.2022\n",
      "Epoch [ 168/500], trn los:   0.4503, trn acc: 0.2125, val loss:   2.0814, val acc: 0.1685\n",
      "Epoch [ 169/500], trn los:   0.4421, trn acc: 0.2210, val loss:   2.0616, val acc: 0.1798\n",
      "Epoch [ 170/500], trn los:   0.4496, trn acc: 0.1813, val loss:   2.0679, val acc: 0.1798\n",
      "Epoch [ 171/500], trn los:   0.4406, trn acc: 0.1841, val loss:   2.0677, val acc: 0.1798\n",
      "Epoch [ 172/500], trn los:   0.4413, trn acc: 0.1983, val loss:   2.0531, val acc: 0.1685\n",
      "Epoch [ 173/500], trn los:   0.4406, trn acc: 0.1955, val loss:   2.0538, val acc: 0.1685\n",
      "Epoch [ 174/500], trn los:   0.4332, trn acc: 0.2125, val loss:   2.0428, val acc: 0.1910\n",
      "Epoch [ 175/500], trn los:   0.4328, trn acc: 0.1983, val loss:   2.0423, val acc: 0.1910\n",
      "Epoch [ 176/500], trn los:   0.4290, trn acc: 0.2011, val loss:   2.0470, val acc: 0.1798\n",
      "Epoch [ 177/500], trn los:   0.4224, trn acc: 0.2040, val loss:   2.0480, val acc: 0.2135\n",
      "Epoch [ 178/500], trn los:   0.4279, trn acc: 0.2266, val loss:   2.0508, val acc: 0.1798\n",
      "Epoch [ 179/500], trn los:   0.4211, trn acc: 0.2125, val loss:   2.0602, val acc: 0.1685\n",
      "Epoch [ 180/500], trn los:   0.4187, trn acc: 0.2181, val loss:   2.0461, val acc: 0.1798\n",
      "Epoch [ 181/500], trn los:   0.4202, trn acc: 0.2436, val loss:   2.0660, val acc: 0.1798\n",
      "Epoch [ 182/500], trn los:   0.4162, trn acc: 0.2040, val loss:   2.0519, val acc: 0.2022\n",
      "Epoch [ 183/500], trn los:   0.4160, trn acc: 0.2096, val loss:   2.0462, val acc: 0.1910\n",
      "Epoch [ 184/500], trn los:   0.4130, trn acc: 0.2011, val loss:   2.0470, val acc: 0.1910\n",
      "Epoch [ 185/500], trn los:   0.4068, trn acc: 0.1926, val loss:   2.0479, val acc: 0.2022\n",
      "Epoch [ 186/500], trn los:   0.4031, trn acc: 0.2380, val loss:   2.0418, val acc: 0.1798\n",
      "Epoch [ 187/500], trn los:   0.3995, trn acc: 0.2351, val loss:   2.0523, val acc: 0.1798\n",
      "Epoch [ 188/500], trn los:   0.3964, trn acc: 0.2323, val loss:   2.0341, val acc: 0.2135\n",
      "Epoch [ 189/500], trn los:   0.3980, trn acc: 0.2153, val loss:   2.0384, val acc: 0.1798\n",
      "Epoch [ 190/500], trn los:   0.3968, trn acc: 0.1926, val loss:   2.0548, val acc: 0.1798\n",
      "Epoch [ 191/500], trn los:   0.3910, trn acc: 0.2210, val loss:   2.0632, val acc: 0.1798\n",
      "Epoch [ 192/500], trn los:   0.3924, trn acc: 0.2011, val loss:   2.0564, val acc: 0.2022\n",
      "Epoch [ 193/500], trn los:   0.3916, trn acc: 0.2210, val loss:   2.0487, val acc: 0.2022\n",
      "Epoch [ 194/500], trn los:   0.3871, trn acc: 0.2153, val loss:   2.0521, val acc: 0.2022\n",
      "Epoch [ 195/500], trn los:   0.3859, trn acc: 0.2153, val loss:   2.0723, val acc: 0.1910\n",
      "Epoch [ 196/500], trn los:   0.3812, trn acc: 0.2210, val loss:   2.0373, val acc: 0.1910\n",
      "Epoch [ 197/500], trn los:   0.3794, trn acc: 0.2125, val loss:   2.0403, val acc: 0.1798\n",
      "Epoch [ 198/500], trn los:   0.3785, trn acc: 0.2125, val loss:   2.0424, val acc: 0.1910\n",
      "Epoch [ 199/500], trn los:   0.3828, trn acc: 0.2125, val loss:   2.0502, val acc: 0.1798\n",
      "Epoch [ 200/500], trn los:   0.3772, trn acc: 0.2040, val loss:   2.0374, val acc: 0.1798\n",
      "Epoch [ 201/500], trn los:   0.3755, trn acc: 0.2125, val loss:   2.0413, val acc: 0.2022\n",
      "Epoch [ 202/500], trn los:   0.3756, trn acc: 0.2295, val loss:   2.0379, val acc: 0.1910\n",
      "Epoch [ 203/500], trn los:   0.3733, trn acc: 0.2153, val loss:   2.0497, val acc: 0.1798\n",
      "Epoch [ 204/500], trn los:   0.3701, trn acc: 0.2238, val loss:   2.0549, val acc: 0.1910\n",
      "Epoch [ 205/500], trn los:   0.3603, trn acc: 0.2125, val loss:   2.0303, val acc: 0.1910\n",
      "Epoch [ 206/500], trn los:   0.3662, trn acc: 0.2181, val loss:   2.0482, val acc: 0.1685\n",
      "Epoch [ 207/500], trn los:   0.3625, trn acc: 0.2068, val loss:   2.0457, val acc: 0.1798\n",
      "Epoch [ 208/500], trn los:   0.3569, trn acc: 0.2125, val loss:   2.0252, val acc: 0.1910\n",
      "Epoch [ 209/500], trn los:   0.3601, trn acc: 0.2323, val loss:   2.0217, val acc: 0.2360\n",
      "Epoch [ 210/500], trn los:   0.3556, trn acc: 0.2125, val loss:   2.0270, val acc: 0.2135\n",
      "Epoch [ 211/500], trn los:   0.3457, trn acc: 0.2181, val loss:   2.0342, val acc: 0.1910\n",
      "Epoch [ 212/500], trn los:   0.3541, trn acc: 0.2266, val loss:   2.0726, val acc: 0.1798\n",
      "Epoch [ 213/500], trn los:   0.3478, trn acc: 0.2295, val loss:   2.0538, val acc: 0.1798\n",
      "Epoch [ 214/500], trn los:   0.3475, trn acc: 0.1983, val loss:   2.0283, val acc: 0.2022\n",
      "Epoch [ 215/500], trn los:   0.3452, trn acc: 0.2181, val loss:   2.0340, val acc: 0.1910\n",
      "Epoch [ 216/500], trn los:   0.3469, trn acc: 0.2040, val loss:   2.0289, val acc: 0.1910\n",
      "Epoch [ 217/500], trn los:   0.3485, trn acc: 0.2153, val loss:   2.0422, val acc: 0.2022\n",
      "Epoch [ 218/500], trn los:   0.3439, trn acc: 0.2096, val loss:   2.0394, val acc: 0.1910\n",
      "Epoch [ 219/500], trn los:   0.3378, trn acc: 0.2096, val loss:   2.0455, val acc: 0.1798\n",
      "Epoch [ 220/500], trn los:   0.3348, trn acc: 0.2153, val loss:   2.0441, val acc: 0.1910\n",
      "Epoch [ 221/500], trn los:   0.3360, trn acc: 0.2408, val loss:   2.0343, val acc: 0.1910\n",
      "Epoch [ 222/500], trn los:   0.3349, trn acc: 0.2125, val loss:   2.0207, val acc: 0.2135\n",
      "Epoch [ 223/500], trn los:   0.3321, trn acc: 0.2210, val loss:   2.0346, val acc: 0.1798\n",
      "Epoch [ 224/500], trn los:   0.3333, trn acc: 0.1870, val loss:   2.0120, val acc: 0.2135\n",
      "Epoch [ 225/500], trn los:   0.3300, trn acc: 0.2578, val loss:   2.0159, val acc: 0.1910\n",
      "Epoch [ 226/500], trn los:   0.3262, trn acc: 0.2210, val loss:   2.0284, val acc: 0.1910\n",
      "Epoch [ 227/500], trn los:   0.3244, trn acc: 0.2125, val loss:   2.0152, val acc: 0.2022\n",
      "Epoch [ 228/500], trn los:   0.3233, trn acc: 0.2238, val loss:   2.0185, val acc: 0.2135\n",
      "Epoch [ 229/500], trn los:   0.3299, trn acc: 0.2125, val loss:   2.0337, val acc: 0.1910\n",
      "Epoch [ 230/500], trn los:   0.3190, trn acc: 0.2238, val loss:   2.0122, val acc: 0.1910\n",
      "Epoch [ 231/500], trn los:   0.3207, trn acc: 0.2266, val loss:   2.0346, val acc: 0.1910\n",
      "Epoch [ 232/500], trn los:   0.3252, trn acc: 0.2210, val loss:   2.0274, val acc: 0.2022\n",
      "Epoch [ 233/500], trn los:   0.3153, trn acc: 0.2436, val loss:   2.0135, val acc: 0.2022\n",
      "Epoch [ 234/500], trn los:   0.3177, trn acc: 0.2210, val loss:   2.0322, val acc: 0.2022\n",
      "Epoch [ 235/500], trn los:   0.3162, trn acc: 0.2380, val loss:   2.0176, val acc: 0.1910\n",
      "Epoch [ 236/500], trn los:   0.3117, trn acc: 0.2351, val loss:   2.0188, val acc: 0.2022\n",
      "Epoch [ 237/500], trn los:   0.3130, trn acc: 0.2493, val loss:   2.0190, val acc: 0.1910\n",
      "Epoch [ 238/500], trn los:   0.3093, trn acc: 0.2295, val loss:   2.0173, val acc: 0.2022\n",
      "Epoch [ 239/500], trn los:   0.3109, trn acc: 0.2323, val loss:   2.0265, val acc: 0.2022\n",
      "Epoch [ 240/500], trn los:   0.3060, trn acc: 0.2691, val loss:   2.0102, val acc: 0.2022\n",
      "Epoch [ 241/500], trn los:   0.3062, trn acc: 0.2323, val loss:   2.0385, val acc: 0.1798\n",
      "Epoch [ 242/500], trn los:   0.3015, trn acc: 0.2125, val loss:   2.0478, val acc: 0.1798\n",
      "Epoch [ 243/500], trn los:   0.3044, trn acc: 0.2550, val loss:   2.0118, val acc: 0.2135\n",
      "Epoch [ 244/500], trn los:   0.3007, trn acc: 0.2238, val loss:   2.0149, val acc: 0.1910\n",
      "Epoch [ 245/500], trn los:   0.3006, trn acc: 0.2181, val loss:   2.0250, val acc: 0.2247\n",
      "Epoch [ 246/500], trn los:   0.3004, trn acc: 0.2408, val loss:   2.0118, val acc: 0.2247\n",
      "Epoch [ 247/500], trn los:   0.2994, trn acc: 0.2266, val loss:   2.0125, val acc: 0.2247\n",
      "Epoch [ 248/500], trn los:   0.2949, trn acc: 0.2351, val loss:   2.0236, val acc: 0.2247\n",
      "Epoch [ 249/500], trn los:   0.2965, trn acc: 0.2436, val loss:   2.0189, val acc: 0.2360\n",
      "Epoch [ 250/500], trn los:   0.2934, trn acc: 0.2238, val loss:   2.0101, val acc: 0.2022\n",
      "Epoch [ 251/500], trn los:   0.2943, trn acc: 0.2436, val loss:   2.0526, val acc: 0.2022\n",
      "Epoch [ 252/500], trn los:   0.2929, trn acc: 0.2351, val loss:   2.0392, val acc: 0.1685\n",
      "Epoch [ 253/500], trn los:   0.2941, trn acc: 0.1785, val loss:   2.0315, val acc: 0.1798\n",
      "Epoch [ 254/500], trn los:   0.2894, trn acc: 0.2040, val loss:   2.0117, val acc: 0.2135\n",
      "Epoch [ 255/500], trn los:   0.2903, trn acc: 0.2266, val loss:   2.0158, val acc: 0.1798\n",
      "Epoch [ 256/500], trn los:   0.2867, trn acc: 0.2436, val loss:   2.0244, val acc: 0.1910\n",
      "Epoch [ 257/500], trn los:   0.2876, trn acc: 0.2436, val loss:   2.0187, val acc: 0.2022\n",
      "Epoch [ 258/500], trn los:   0.2848, trn acc: 0.2465, val loss:   2.0184, val acc: 0.2135\n",
      "Epoch [ 259/500], trn los:   0.2831, trn acc: 0.2436, val loss:   2.0211, val acc: 0.2135\n",
      "Epoch [ 260/500], trn los:   0.2853, trn acc: 0.2266, val loss:   2.0177, val acc: 0.1910\n",
      "Epoch [ 261/500], trn los:   0.2798, trn acc: 0.2493, val loss:   2.0176, val acc: 0.1910\n",
      "Epoch [ 262/500], trn los:   0.2771, trn acc: 0.2351, val loss:   2.0252, val acc: 0.2022\n",
      "Epoch [ 263/500], trn los:   0.2823, trn acc: 0.2493, val loss:   2.0082, val acc: 0.2022\n",
      "Epoch [ 264/500], trn los:   0.2782, trn acc: 0.2323, val loss:   2.0081, val acc: 0.2135\n",
      "Epoch [ 265/500], trn los:   0.2760, trn acc: 0.2295, val loss:   2.0052, val acc: 0.1910\n",
      "Epoch [ 266/500], trn los:   0.2763, trn acc: 0.2465, val loss:   2.0074, val acc: 0.2022\n",
      "Epoch [ 267/500], trn los:   0.2742, trn acc: 0.2096, val loss:   2.0148, val acc: 0.2247\n",
      "Epoch [ 268/500], trn los:   0.2748, trn acc: 0.2521, val loss:   2.0085, val acc: 0.2022\n",
      "Epoch [ 269/500], trn los:   0.2714, trn acc: 0.2380, val loss:   2.0181, val acc: 0.2135\n",
      "Epoch [ 270/500], trn los:   0.2701, trn acc: 0.2266, val loss:   2.0499, val acc: 0.1685\n",
      "Epoch [ 271/500], trn los:   0.2713, trn acc: 0.2380, val loss:   2.0167, val acc: 0.2135\n",
      "Epoch [ 272/500], trn los:   0.2718, trn acc: 0.2210, val loss:   2.0084, val acc: 0.2247\n",
      "Epoch [ 273/500], trn los:   0.2707, trn acc: 0.2436, val loss:   2.0067, val acc: 0.2135\n",
      "Epoch [ 274/500], trn los:   0.2670, trn acc: 0.2323, val loss:   2.0023, val acc: 0.1798\n",
      "Epoch [ 275/500], trn los:   0.2686, trn acc: 0.2380, val loss:   2.0268, val acc: 0.1798\n",
      "Epoch [ 276/500], trn los:   0.2693, trn acc: 0.2351, val loss:   2.0047, val acc: 0.2135\n",
      "Epoch [ 277/500], trn los:   0.2679, trn acc: 0.2295, val loss:   2.0453, val acc: 0.1910\n",
      "Epoch [ 278/500], trn los:   0.2632, trn acc: 0.2408, val loss:   2.0224, val acc: 0.2022\n",
      "Epoch [ 279/500], trn los:   0.2628, trn acc: 0.2153, val loss:   2.0052, val acc: 0.1910\n",
      "Epoch [ 280/500], trn los:   0.2586, trn acc: 0.2323, val loss:   2.0022, val acc: 0.2135\n",
      "Epoch [ 281/500], trn los:   0.2578, trn acc: 0.2323, val loss:   2.0089, val acc: 0.2135\n",
      "Epoch [ 282/500], trn los:   0.2602, trn acc: 0.2238, val loss:   2.0041, val acc: 0.2135\n",
      "Epoch [ 283/500], trn los:   0.2584, trn acc: 0.2323, val loss:   2.0278, val acc: 0.1798\n",
      "Epoch [ 284/500], trn los:   0.2577, trn acc: 0.2181, val loss:   2.0068, val acc: 0.2360\n",
      "Epoch [ 285/500], trn los:   0.2565, trn acc: 0.2493, val loss:   2.0021, val acc: 0.1910\n",
      "Epoch [ 286/500], trn los:   0.2562, trn acc: 0.2465, val loss:   2.0023, val acc: 0.2135\n",
      "Epoch [ 287/500], trn los:   0.2577, trn acc: 0.2436, val loss:   2.0118, val acc: 0.1798\n",
      "Epoch [ 288/500], trn los:   0.2550, trn acc: 0.2068, val loss:   2.0234, val acc: 0.2022\n",
      "Epoch [ 289/500], trn los:   0.2524, trn acc: 0.2351, val loss:   2.0127, val acc: 0.1910\n",
      "Epoch [ 290/500], trn los:   0.2513, trn acc: 0.2436, val loss:   2.0241, val acc: 0.1910\n",
      "Epoch [ 291/500], trn los:   0.2540, trn acc: 0.2266, val loss:   2.0259, val acc: 0.1798\n",
      "Epoch [ 292/500], trn los:   0.2523, trn acc: 0.2323, val loss:   2.0142, val acc: 0.2022\n",
      "Epoch [ 293/500], trn los:   0.2527, trn acc: 0.2238, val loss:   2.0091, val acc: 0.2360\n",
      "Epoch [ 294/500], trn los:   0.2495, trn acc: 0.2323, val loss:   2.0358, val acc: 0.1798\n",
      "Epoch [ 295/500], trn los:   0.2438, trn acc: 0.2635, val loss:   2.0076, val acc: 0.2022\n",
      "Epoch [ 296/500], trn los:   0.2460, trn acc: 0.2521, val loss:   2.0281, val acc: 0.1910\n",
      "Epoch [ 297/500], trn los:   0.2443, trn acc: 0.2238, val loss:   2.0213, val acc: 0.1910\n",
      "Epoch [ 298/500], trn los:   0.2447, trn acc: 0.2068, val loss:   2.0139, val acc: 0.1910\n",
      "Epoch [ 299/500], trn los:   0.2479, trn acc: 0.2323, val loss:   2.0105, val acc: 0.2022\n",
      "Epoch [ 300/500], trn los:   0.2426, trn acc: 0.2606, val loss:   2.0139, val acc: 0.2360\n",
      "Epoch [ 301/500], trn los:   0.2443, trn acc: 0.2125, val loss:   2.0161, val acc: 0.1685\n",
      "Epoch [ 302/500], trn los:   0.2414, trn acc: 0.2238, val loss:   2.0203, val acc: 0.1910\n",
      "Epoch [ 303/500], trn los:   0.2422, trn acc: 0.2408, val loss:   2.0023, val acc: 0.2247\n",
      "Epoch [ 304/500], trn los:   0.2389, trn acc: 0.2521, val loss:   2.0197, val acc: 0.1798\n",
      "Epoch [ 305/500], trn los:   0.2402, trn acc: 0.2323, val loss:   1.9969, val acc: 0.2247\n",
      "Epoch [ 306/500], trn los:   0.2409, trn acc: 0.2238, val loss:   2.0064, val acc: 0.2135\n",
      "Epoch [ 307/500], trn los:   0.2399, trn acc: 0.2323, val loss:   2.0222, val acc: 0.1798\n",
      "Epoch [ 308/500], trn los:   0.2373, trn acc: 0.2323, val loss:   2.0267, val acc: 0.1798\n",
      "Epoch [ 309/500], trn los:   0.2357, trn acc: 0.2380, val loss:   2.0031, val acc: 0.1910\n",
      "Epoch [ 310/500], trn los:   0.2366, trn acc: 0.2323, val loss:   2.0102, val acc: 0.2022\n",
      "Epoch [ 311/500], trn los:   0.2323, trn acc: 0.2436, val loss:   2.0036, val acc: 0.2022\n",
      "Epoch [ 312/500], trn los:   0.2343, trn acc: 0.2210, val loss:   2.0077, val acc: 0.2022\n",
      "Epoch [ 313/500], trn los:   0.2339, trn acc: 0.2238, val loss:   2.0084, val acc: 0.2135\n",
      "Epoch [ 314/500], trn los:   0.2352, trn acc: 0.2295, val loss:   2.0179, val acc: 0.2247\n",
      "Epoch [ 315/500], trn los:   0.2283, trn acc: 0.2550, val loss:   2.0072, val acc: 0.2135\n",
      "Epoch [ 316/500], trn los:   0.2306, trn acc: 0.2493, val loss:   2.0101, val acc: 0.2022\n",
      "Epoch [ 317/500], trn los:   0.2297, trn acc: 0.2380, val loss:   2.0231, val acc: 0.2022\n",
      "Epoch [ 318/500], trn los:   0.2308, trn acc: 0.2238, val loss:   2.0146, val acc: 0.2135\n",
      "Epoch [ 319/500], trn los:   0.2284, trn acc: 0.2380, val loss:   2.0396, val acc: 0.1910\n",
      "Epoch [ 320/500], trn los:   0.2250, trn acc: 0.2521, val loss:   2.0160, val acc: 0.1910\n",
      "Epoch [ 321/500], trn los:   0.2300, trn acc: 0.2550, val loss:   2.0078, val acc: 0.2135\n",
      "Epoch [ 322/500], trn los:   0.2265, trn acc: 0.2323, val loss:   2.0078, val acc: 0.2135\n",
      "Epoch [ 323/500], trn los:   0.2262, trn acc: 0.2578, val loss:   2.0171, val acc: 0.2135\n",
      "Epoch [ 324/500], trn los:   0.2254, trn acc: 0.2295, val loss:   2.0142, val acc: 0.2247\n",
      "Epoch [ 325/500], trn los:   0.2240, trn acc: 0.2266, val loss:   2.0150, val acc: 0.2135\n",
      "Epoch [ 326/500], trn los:   0.2249, trn acc: 0.2351, val loss:   2.0125, val acc: 0.1798\n",
      "Epoch [ 327/500], trn los:   0.2241, trn acc: 0.2408, val loss:   2.0149, val acc: 0.2135\n",
      "Epoch [ 328/500], trn los:   0.2234, trn acc: 0.2521, val loss:   2.0113, val acc: 0.1798\n",
      "Epoch [ 329/500], trn los:   0.2219, trn acc: 0.2380, val loss:   2.0145, val acc: 0.1910\n",
      "Epoch [ 330/500], trn los:   0.2189, trn acc: 0.2493, val loss:   2.0099, val acc: 0.2247\n",
      "Epoch [ 331/500], trn los:   0.2208, trn acc: 0.2380, val loss:   2.0170, val acc: 0.2135\n",
      "Epoch [ 332/500], trn los:   0.2216, trn acc: 0.2323, val loss:   2.0146, val acc: 0.1910\n",
      "Epoch [ 333/500], trn los:   0.2206, trn acc: 0.2380, val loss:   2.0146, val acc: 0.1910\n",
      "Epoch [ 334/500], trn los:   0.2182, trn acc: 0.2436, val loss:   2.0111, val acc: 0.2135\n",
      "Epoch [ 335/500], trn los:   0.2189, trn acc: 0.2521, val loss:   2.0081, val acc: 0.2135\n",
      "Epoch [ 336/500], trn los:   0.2168, trn acc: 0.2351, val loss:   2.0124, val acc: 0.2247\n",
      "Epoch [ 337/500], trn los:   0.2149, trn acc: 0.2663, val loss:   2.0118, val acc: 0.1910\n",
      "Epoch [ 338/500], trn los:   0.2132, trn acc: 0.2351, val loss:   2.0363, val acc: 0.1910\n",
      "Epoch [ 339/500], trn los:   0.2179, trn acc: 0.2635, val loss:   2.0048, val acc: 0.2247\n",
      "Epoch [ 340/500], trn los:   0.2118, trn acc: 0.2493, val loss:   2.0069, val acc: 0.1798\n",
      "Epoch [ 341/500], trn los:   0.2131, trn acc: 0.2295, val loss:   2.0098, val acc: 0.2135\n",
      "Epoch [ 342/500], trn los:   0.2156, trn acc: 0.2295, val loss:   2.0018, val acc: 0.1685\n",
      "Epoch [ 343/500], trn los:   0.2128, trn acc: 0.2210, val loss:   2.0081, val acc: 0.2022\n",
      "Epoch [ 344/500], trn los:   0.2125, trn acc: 0.2380, val loss:   2.0218, val acc: 0.1685\n",
      "Epoch [ 345/500], trn los:   0.2103, trn acc: 0.2493, val loss:   2.0369, val acc: 0.1910\n",
      "Epoch [ 346/500], trn los:   0.2109, trn acc: 0.2436, val loss:   2.0255, val acc: 0.2022\n",
      "Epoch [ 347/500], trn los:   0.2101, trn acc: 0.2408, val loss:   2.0147, val acc: 0.1685\n",
      "Epoch [ 348/500], trn los:   0.2093, trn acc: 0.2521, val loss:   2.0318, val acc: 0.1798\n",
      "Epoch [ 349/500], trn los:   0.2078, trn acc: 0.2493, val loss:   2.0099, val acc: 0.2022\n",
      "Epoch [ 350/500], trn los:   0.2080, trn acc: 0.2436, val loss:   2.0016, val acc: 0.2022\n",
      "Epoch [ 351/500], trn los:   0.2067, trn acc: 0.2408, val loss:   2.0090, val acc: 0.2247\n",
      "Epoch [ 352/500], trn los:   0.2047, trn acc: 0.2578, val loss:   2.0036, val acc: 0.2135\n",
      "Epoch [ 353/500], trn los:   0.2048, trn acc: 0.2691, val loss:   1.9960, val acc: 0.1910\n",
      "Epoch [ 354/500], trn los:   0.2050, trn acc: 0.2663, val loss:   1.9981, val acc: 0.2022\n",
      "Epoch [ 355/500], trn los:   0.2036, trn acc: 0.2521, val loss:   2.0000, val acc: 0.1910\n",
      "Epoch [ 356/500], trn los:   0.2035, trn acc: 0.2351, val loss:   2.0029, val acc: 0.2022\n",
      "Epoch [ 357/500], trn los:   0.2010, trn acc: 0.2436, val loss:   1.9932, val acc: 0.2022\n",
      "Epoch [ 358/500], trn los:   0.2018, trn acc: 0.2436, val loss:   1.9959, val acc: 0.2135\n",
      "Epoch [ 359/500], trn los:   0.2030, trn acc: 0.2493, val loss:   2.0170, val acc: 0.1798\n",
      "Epoch [ 360/500], trn los:   0.1999, trn acc: 0.2380, val loss:   1.9895, val acc: 0.2135\n",
      "Epoch [ 361/500], trn los:   0.2031, trn acc: 0.2408, val loss:   1.9935, val acc: 0.2135\n",
      "Epoch [ 362/500], trn los:   0.2005, trn acc: 0.2266, val loss:   2.0054, val acc: 0.2247\n",
      "Epoch [ 363/500], trn los:   0.1993, trn acc: 0.2578, val loss:   1.9955, val acc: 0.2135\n",
      "Epoch [ 364/500], trn los:   0.1997, trn acc: 0.2663, val loss:   1.9939, val acc: 0.2247\n",
      "Epoch [ 365/500], trn los:   0.1987, trn acc: 0.2436, val loss:   1.9921, val acc: 0.2135\n",
      "Epoch [ 366/500], trn los:   0.1979, trn acc: 0.2521, val loss:   1.9950, val acc: 0.1798\n",
      "Epoch [ 367/500], trn los:   0.1963, trn acc: 0.2380, val loss:   1.9967, val acc: 0.2022\n",
      "Epoch [ 368/500], trn los:   0.1952, trn acc: 0.2748, val loss:   1.9886, val acc: 0.1910\n",
      "Epoch [ 369/500], trn los:   0.1963, trn acc: 0.2380, val loss:   1.9874, val acc: 0.2135\n",
      "Epoch [ 370/500], trn los:   0.1949, trn acc: 0.2436, val loss:   2.0027, val acc: 0.1910\n",
      "Epoch [ 371/500], trn los:   0.1939, trn acc: 0.2465, val loss:   2.0100, val acc: 0.1685\n",
      "Epoch [ 372/500], trn los:   0.1959, trn acc: 0.2380, val loss:   2.0222, val acc: 0.1798\n",
      "Epoch [ 373/500], trn los:   0.1929, trn acc: 0.2748, val loss:   1.9985, val acc: 0.2360\n",
      "Epoch [ 374/500], trn los:   0.1937, trn acc: 0.2436, val loss:   1.9962, val acc: 0.2135\n",
      "Epoch [ 375/500], trn los:   0.1921, trn acc: 0.2691, val loss:   1.9997, val acc: 0.2360\n",
      "Epoch [ 376/500], trn los:   0.1894, trn acc: 0.2606, val loss:   1.9957, val acc: 0.2135\n",
      "Epoch [ 377/500], trn los:   0.1892, trn acc: 0.2493, val loss:   1.9980, val acc: 0.2247\n",
      "Epoch [ 378/500], trn los:   0.1888, trn acc: 0.2521, val loss:   1.9953, val acc: 0.2247\n",
      "Epoch [ 379/500], trn los:   0.1916, trn acc: 0.2635, val loss:   2.0000, val acc: 0.2022\n",
      "Epoch [ 380/500], trn los:   0.1888, trn acc: 0.2635, val loss:   2.0352, val acc: 0.1685\n",
      "Epoch [ 381/500], trn los:   0.1886, trn acc: 0.2606, val loss:   1.9996, val acc: 0.1910\n",
      "Epoch [ 382/500], trn los:   0.1885, trn acc: 0.2351, val loss:   2.0036, val acc: 0.2135\n",
      "Epoch [ 383/500], trn los:   0.1867, trn acc: 0.2493, val loss:   2.0004, val acc: 0.2135\n",
      "Epoch [ 384/500], trn los:   0.1864, trn acc: 0.2323, val loss:   2.0029, val acc: 0.1798\n",
      "Epoch [ 385/500], trn los:   0.1890, trn acc: 0.2521, val loss:   2.0114, val acc: 0.2247\n",
      "Epoch [ 386/500], trn los:   0.1869, trn acc: 0.2635, val loss:   1.9898, val acc: 0.1910\n",
      "Epoch [ 387/500], trn los:   0.1860, trn acc: 0.2606, val loss:   1.9956, val acc: 0.2135\n",
      "Epoch [ 388/500], trn los:   0.1852, trn acc: 0.2578, val loss:   2.0186, val acc: 0.1798\n",
      "Epoch [ 389/500], trn los:   0.1859, trn acc: 0.2465, val loss:   1.9962, val acc: 0.2022\n",
      "Epoch [ 390/500], trn los:   0.1848, trn acc: 0.2635, val loss:   2.0075, val acc: 0.2135\n",
      "Epoch [ 391/500], trn los:   0.1846, trn acc: 0.2521, val loss:   2.0197, val acc: 0.2022\n",
      "Epoch [ 392/500], trn los:   0.1843, trn acc: 0.2521, val loss:   2.0125, val acc: 0.2135\n",
      "Epoch [ 393/500], trn los:   0.1830, trn acc: 0.2323, val loss:   1.9997, val acc: 0.2022\n",
      "Epoch [ 394/500], trn los:   0.1824, trn acc: 0.2521, val loss:   2.0099, val acc: 0.1910\n",
      "Epoch [ 395/500], trn los:   0.1840, trn acc: 0.2408, val loss:   2.0212, val acc: 0.1910\n",
      "Epoch [ 396/500], trn los:   0.1817, trn acc: 0.2720, val loss:   2.0260, val acc: 0.2022\n",
      "Epoch [ 397/500], trn los:   0.1834, trn acc: 0.2295, val loss:   2.0048, val acc: 0.2022\n",
      "Epoch [ 398/500], trn los:   0.1829, trn acc: 0.2351, val loss:   2.0168, val acc: 0.2247\n",
      "Epoch [ 399/500], trn los:   0.1832, trn acc: 0.2323, val loss:   2.0009, val acc: 0.2135\n",
      "Epoch [ 400/500], trn los:   0.1799, trn acc: 0.2748, val loss:   2.0028, val acc: 0.2247\n",
      "Epoch [ 401/500], trn los:   0.1797, trn acc: 0.2833, val loss:   1.9972, val acc: 0.2360\n",
      "Epoch [ 402/500], trn los:   0.1796, trn acc: 0.2578, val loss:   2.0065, val acc: 0.2135\n",
      "Epoch [ 403/500], trn los:   0.1775, trn acc: 0.2663, val loss:   2.0168, val acc: 0.2135\n",
      "Epoch [ 404/500], trn los:   0.1774, trn acc: 0.2436, val loss:   2.0094, val acc: 0.1910\n",
      "Epoch [ 405/500], trn los:   0.1783, trn acc: 0.2776, val loss:   2.0411, val acc: 0.1798\n",
      "Epoch [ 406/500], trn los:   0.1787, trn acc: 0.2550, val loss:   2.0195, val acc: 0.1910\n",
      "Epoch [ 407/500], trn los:   0.1756, trn acc: 0.2550, val loss:   2.0130, val acc: 0.1685\n",
      "Epoch [ 408/500], trn los:   0.1755, trn acc: 0.2465, val loss:   1.9982, val acc: 0.1910\n",
      "Epoch [ 409/500], trn los:   0.1754, trn acc: 0.2748, val loss:   2.0112, val acc: 0.1685\n",
      "Epoch [ 410/500], trn los:   0.1757, trn acc: 0.2635, val loss:   2.0103, val acc: 0.2247\n",
      "Epoch [ 411/500], trn los:   0.1748, trn acc: 0.2380, val loss:   2.0244, val acc: 0.2247\n",
      "Epoch [ 412/500], trn los:   0.1763, trn acc: 0.2493, val loss:   1.9987, val acc: 0.2022\n",
      "Epoch [ 413/500], trn los:   0.1735, trn acc: 0.2720, val loss:   2.0147, val acc: 0.1910\n",
      "Epoch [ 414/500], trn los:   0.1710, trn acc: 0.2578, val loss:   2.0101, val acc: 0.1798\n",
      "Epoch [ 415/500], trn los:   0.1748, trn acc: 0.2606, val loss:   2.0096, val acc: 0.1910\n",
      "Epoch [ 416/500], trn los:   0.1707, trn acc: 0.2465, val loss:   2.0032, val acc: 0.2022\n",
      "Epoch [ 417/500], trn los:   0.1728, trn acc: 0.2323, val loss:   2.0019, val acc: 0.1910\n",
      "Epoch [ 418/500], trn los:   0.1730, trn acc: 0.2408, val loss:   2.0025, val acc: 0.2022\n",
      "Epoch [ 419/500], trn los:   0.1723, trn acc: 0.2578, val loss:   2.0140, val acc: 0.1798\n",
      "Epoch [ 420/500], trn los:   0.1713, trn acc: 0.2521, val loss:   2.0121, val acc: 0.1910\n",
      "Epoch [ 421/500], trn los:   0.1687, trn acc: 0.2521, val loss:   2.0032, val acc: 0.1685\n",
      "Epoch [ 422/500], trn los:   0.1716, trn acc: 0.2720, val loss:   1.9975, val acc: 0.2135\n",
      "Epoch [ 423/500], trn los:   0.1711, trn acc: 0.2578, val loss:   2.0101, val acc: 0.1573\n",
      "Epoch [ 424/500], trn los:   0.1684, trn acc: 0.2748, val loss:   2.0019, val acc: 0.1685\n",
      "Epoch [ 425/500], trn los:   0.1674, trn acc: 0.2521, val loss:   2.0002, val acc: 0.1910\n",
      "Epoch [ 426/500], trn los:   0.1676, trn acc: 0.2493, val loss:   2.0049, val acc: 0.1685\n",
      "Epoch [ 427/500], trn los:   0.1686, trn acc: 0.2663, val loss:   2.0055, val acc: 0.2022\n",
      "Epoch [ 428/500], trn los:   0.1654, trn acc: 0.2635, val loss:   2.0064, val acc: 0.1798\n",
      "Epoch [ 429/500], trn los:   0.1665, trn acc: 0.2691, val loss:   1.9949, val acc: 0.2022\n",
      "Epoch [ 430/500], trn los:   0.1641, trn acc: 0.2606, val loss:   2.0108, val acc: 0.1798\n",
      "Epoch [ 431/500], trn los:   0.1659, trn acc: 0.2578, val loss:   1.9981, val acc: 0.2247\n",
      "Epoch [ 432/500], trn los:   0.1676, trn acc: 0.2493, val loss:   2.0068, val acc: 0.2247\n",
      "Epoch [ 433/500], trn los:   0.1661, trn acc: 0.2663, val loss:   2.0363, val acc: 0.2022\n",
      "Epoch [ 434/500], trn los:   0.1640, trn acc: 0.2550, val loss:   1.9943, val acc: 0.2247\n",
      "Epoch [ 435/500], trn los:   0.1643, trn acc: 0.2408, val loss:   2.0081, val acc: 0.1798\n",
      "Epoch [ 436/500], trn los:   0.1668, trn acc: 0.2635, val loss:   2.0250, val acc: 0.2022\n",
      "Epoch [ 437/500], trn los:   0.1645, trn acc: 0.2323, val loss:   2.0169, val acc: 0.1798\n",
      "Epoch [ 438/500], trn los:   0.1639, trn acc: 0.2521, val loss:   2.0110, val acc: 0.1798\n",
      "Epoch [ 439/500], trn los:   0.1615, trn acc: 0.2550, val loss:   2.0063, val acc: 0.2022\n",
      "Epoch [ 440/500], trn los:   0.1612, trn acc: 0.2493, val loss:   2.0064, val acc: 0.1798\n",
      "Epoch [ 441/500], trn los:   0.1599, trn acc: 0.2720, val loss:   2.0066, val acc: 0.2022\n",
      "Epoch [ 442/500], trn los:   0.1621, trn acc: 0.2635, val loss:   2.0000, val acc: 0.2247\n",
      "Epoch [ 443/500], trn los:   0.1626, trn acc: 0.2635, val loss:   2.0265, val acc: 0.1685\n",
      "Epoch [ 444/500], trn los:   0.1609, trn acc: 0.2691, val loss:   2.0052, val acc: 0.1685\n",
      "Epoch [ 445/500], trn los:   0.1611, trn acc: 0.2380, val loss:   2.0015, val acc: 0.2022\n",
      "Epoch [ 446/500], trn los:   0.1600, trn acc: 0.2663, val loss:   1.9956, val acc: 0.2247\n",
      "Epoch [ 447/500], trn los:   0.1604, trn acc: 0.2635, val loss:   1.9916, val acc: 0.2135\n",
      "Epoch [ 448/500], trn los:   0.1587, trn acc: 0.2606, val loss:   2.0057, val acc: 0.2022\n",
      "Epoch [ 449/500], trn los:   0.1592, trn acc: 0.2635, val loss:   1.9982, val acc: 0.2247\n",
      "Epoch [ 450/500], trn los:   0.1578, trn acc: 0.2663, val loss:   1.9977, val acc: 0.2247\n",
      "Epoch [ 451/500], trn los:   0.1581, trn acc: 0.2663, val loss:   2.0124, val acc: 0.1910\n",
      "Epoch [ 452/500], trn los:   0.1587, trn acc: 0.2635, val loss:   2.0115, val acc: 0.2022\n",
      "Epoch [ 453/500], trn los:   0.1577, trn acc: 0.2635, val loss:   2.0226, val acc: 0.1685\n",
      "Epoch [ 454/500], trn los:   0.1570, trn acc: 0.2493, val loss:   1.9989, val acc: 0.2135\n",
      "Epoch [ 455/500], trn los:   0.1571, trn acc: 0.2606, val loss:   2.0008, val acc: 0.2022\n",
      "Epoch [ 456/500], trn los:   0.1586, trn acc: 0.2691, val loss:   2.0048, val acc: 0.2022\n",
      "Epoch [ 457/500], trn los:   0.1578, trn acc: 0.2521, val loss:   2.0058, val acc: 0.1798\n",
      "Epoch [ 458/500], trn los:   0.1565, trn acc: 0.2493, val loss:   2.0027, val acc: 0.2022\n",
      "Epoch [ 459/500], trn los:   0.1560, trn acc: 0.2550, val loss:   1.9997, val acc: 0.1798\n",
      "Epoch [ 460/500], trn los:   0.1550, trn acc: 0.2323, val loss:   2.0159, val acc: 0.1798\n",
      "Epoch [ 461/500], trn los:   0.1548, trn acc: 0.2691, val loss:   2.0112, val acc: 0.1798\n",
      "Epoch [ 462/500], trn los:   0.1537, trn acc: 0.2578, val loss:   2.0058, val acc: 0.1910\n",
      "Epoch [ 463/500], trn los:   0.1536, trn acc: 0.2380, val loss:   2.0016, val acc: 0.2135\n",
      "Epoch [ 464/500], trn los:   0.1523, trn acc: 0.2833, val loss:   1.9993, val acc: 0.2022\n",
      "Epoch [ 465/500], trn los:   0.1545, trn acc: 0.2578, val loss:   2.0052, val acc: 0.2022\n",
      "Epoch [ 466/500], trn los:   0.1533, trn acc: 0.2550, val loss:   2.0037, val acc: 0.2022\n",
      "Epoch [ 467/500], trn los:   0.1521, trn acc: 0.2578, val loss:   2.0087, val acc: 0.2135\n",
      "Epoch [ 468/500], trn los:   0.1530, trn acc: 0.2663, val loss:   2.0022, val acc: 0.2022\n",
      "Epoch [ 469/500], trn los:   0.1520, trn acc: 0.2578, val loss:   2.0048, val acc: 0.2135\n",
      "Epoch [ 470/500], trn los:   0.1516, trn acc: 0.2691, val loss:   2.0009, val acc: 0.2022\n",
      "Epoch [ 471/500], trn los:   0.1516, trn acc: 0.2323, val loss:   2.0029, val acc: 0.2135\n",
      "Epoch [ 472/500], trn los:   0.1505, trn acc: 0.2606, val loss:   2.0045, val acc: 0.2135\n",
      "Epoch [ 473/500], trn los:   0.1499, trn acc: 0.2606, val loss:   1.9968, val acc: 0.2022\n",
      "Epoch [ 474/500], trn los:   0.1498, trn acc: 0.2550, val loss:   2.0099, val acc: 0.1798\n",
      "Epoch [ 475/500], trn los:   0.1497, trn acc: 0.2550, val loss:   2.0028, val acc: 0.2022\n",
      "Epoch [ 476/500], trn los:   0.1490, trn acc: 0.2550, val loss:   1.9926, val acc: 0.1910\n",
      "Epoch [ 477/500], trn los:   0.1494, trn acc: 0.2975, val loss:   2.0106, val acc: 0.1573\n",
      "Epoch [ 478/500], trn los:   0.1506, trn acc: 0.2635, val loss:   2.0027, val acc: 0.1798\n",
      "Epoch [ 479/500], trn los:   0.1496, trn acc: 0.2550, val loss:   2.0148, val acc: 0.1798\n",
      "Epoch [ 480/500], trn los:   0.1467, trn acc: 0.2975, val loss:   1.9974, val acc: 0.2247\n",
      "Epoch [ 481/500], trn los:   0.1483, trn acc: 0.2578, val loss:   1.9999, val acc: 0.2135\n",
      "Epoch [ 482/500], trn los:   0.1471, trn acc: 0.2550, val loss:   2.0047, val acc: 0.2022\n",
      "Epoch [ 483/500], trn los:   0.1472, trn acc: 0.2975, val loss:   2.0082, val acc: 0.1798\n",
      "Epoch [ 484/500], trn los:   0.1484, trn acc: 0.2521, val loss:   2.0058, val acc: 0.1798\n",
      "Epoch [ 485/500], trn los:   0.1482, trn acc: 0.2776, val loss:   2.0065, val acc: 0.1685\n",
      "Epoch [ 486/500], trn los:   0.1455, trn acc: 0.2578, val loss:   2.0051, val acc: 0.2135\n",
      "Epoch [ 487/500], trn los:   0.1458, trn acc: 0.2578, val loss:   2.0018, val acc: 0.1798\n",
      "Epoch [ 488/500], trn los:   0.1477, trn acc: 0.2408, val loss:   2.0087, val acc: 0.2135\n",
      "Epoch [ 489/500], trn los:   0.1462, trn acc: 0.2351, val loss:   2.0091, val acc: 0.1798\n",
      "Epoch [ 490/500], trn los:   0.1461, trn acc: 0.2521, val loss:   1.9985, val acc: 0.1798\n",
      "Epoch [ 491/500], trn los:   0.1445, trn acc: 0.2720, val loss:   2.0017, val acc: 0.1910\n",
      "Epoch [ 492/500], trn los:   0.1437, trn acc: 0.2663, val loss:   1.9988, val acc: 0.2135\n",
      "Epoch [ 493/500], trn los:   0.1429, trn acc: 0.2748, val loss:   1.9998, val acc: 0.2022\n",
      "Epoch [ 494/500], trn los:   0.1433, trn acc: 0.2663, val loss:   1.9972, val acc: 0.1910\n",
      "Epoch [ 495/500], trn los:   0.1429, trn acc: 0.2918, val loss:   1.9934, val acc: 0.2022\n",
      "Epoch [ 496/500], trn los:   0.1437, trn acc: 0.2493, val loss:   2.0056, val acc: 0.2135\n",
      "Epoch [ 497/500], trn los:   0.1438, trn acc: 0.2748, val loss:   2.0075, val acc: 0.2022\n",
      "Epoch [ 498/500], trn los:   0.1413, trn acc: 0.2521, val loss:   2.0080, val acc: 0.2022\n",
      "Epoch [ 499/500], trn los:   0.1411, trn acc: 0.2691, val loss:   2.0015, val acc: 0.2135\n",
      "Epoch [ 500/500], trn los:   0.1422, trn acc: 0.2720, val loss:   2.0060, val acc: 0.2135\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T08:47:41.122831Z",
     "start_time": "2025-04-19T08:47:20.501863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def question_12():\n",
    "    general_solver(n_cuts=100, exclude_Y=False, task=Task.CLASSIFICATION, epochs=200, lr=3e-5)\n",
    "    # We lowered the learning rate a bit here, We also increased the dropout % for this training session\n",
    "    # Epoch [   1/200], trn los: 470.0365, trn acc: 0.0057, val loss:   6.4315, val acc: 0.0225\n",
    "    # Epoch [ 200/200], trn los:   0.5688, trn acc: 0.1161, val loss:   3.5989, val acc: 0.1124\n",
    "\n",
    "question_12()"
   ],
   "id": "70941464143916cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [   1/200], trn los: 368.4034, trn acc: 0.0170, val loss:   5.4951, val acc: 0.0225\n",
      "Epoch [   2/200], trn los: 137.8186, trn acc: 0.0113, val loss:   5.1567, val acc: 0.0337\n",
      "Epoch [   3/200], trn los:  87.4727, trn acc: 0.0113, val loss:   4.8444, val acc: 0.0225\n",
      "Epoch [   4/200], trn los:  62.2816, trn acc: 0.0198, val loss:   4.6519, val acc: 0.0449\n",
      "Epoch [   5/200], trn los:  47.1679, trn acc: 0.0170, val loss:   4.6746, val acc: 0.0000\n",
      "Epoch [   6/200], trn los:  36.8394, trn acc: 0.0170, val loss:   4.5231, val acc: 0.0337\n",
      "Epoch [   7/200], trn los:  30.9495, trn acc: 0.0142, val loss:   4.4906, val acc: 0.0337\n",
      "Epoch [   8/200], trn los:  24.9444, trn acc: 0.0113, val loss:   4.4797, val acc: 0.0562\n",
      "Epoch [   9/200], trn los:  21.8564, trn acc: 0.0255, val loss:   4.4153, val acc: 0.0562\n",
      "Epoch [  10/200], trn los:  18.9029, trn acc: 0.0113, val loss:   4.4201, val acc: 0.0787\n",
      "Epoch [  11/200], trn los:  16.7772, trn acc: 0.0397, val loss:   4.3948, val acc: 0.0449\n",
      "Epoch [  12/200], trn los:  15.8892, trn acc: 0.0227, val loss:   4.3651, val acc: 0.0449\n",
      "Epoch [  13/200], trn los:  13.9276, trn acc: 0.0198, val loss:   4.3175, val acc: 0.0674\n",
      "Epoch [  14/200], trn los:  12.8988, trn acc: 0.0227, val loss:   4.3305, val acc: 0.0337\n",
      "Epoch [  15/200], trn los:  11.4255, trn acc: 0.0340, val loss:   4.3334, val acc: 0.0562\n",
      "Epoch [  16/200], trn los:  10.8729, trn acc: 0.0227, val loss:   4.3261, val acc: 0.0674\n",
      "Epoch [  17/200], trn los:   9.9605, trn acc: 0.0340, val loss:   4.2869, val acc: 0.0787\n",
      "Epoch [  18/200], trn los:   9.5375, trn acc: 0.0340, val loss:   4.2874, val acc: 0.0674\n",
      "Epoch [  19/200], trn los:   8.7115, trn acc: 0.0425, val loss:   4.3005, val acc: 0.0449\n",
      "Epoch [  20/200], trn los:   8.0717, trn acc: 0.0397, val loss:   4.2663, val acc: 0.0449\n",
      "Epoch [  21/200], trn los:   7.7762, trn acc: 0.0312, val loss:   4.2930, val acc: 0.0562\n",
      "Epoch [  22/200], trn los:   7.1334, trn acc: 0.0482, val loss:   4.2439, val acc: 0.0449\n",
      "Epoch [  23/200], trn los:   7.2068, trn acc: 0.0255, val loss:   4.2465, val acc: 0.0449\n",
      "Epoch [  24/200], trn los:   6.6267, trn acc: 0.0255, val loss:   4.2273, val acc: 0.0337\n",
      "Epoch [  25/200], trn los:   6.3761, trn acc: 0.0227, val loss:   4.1949, val acc: 0.0449\n",
      "Epoch [  26/200], trn los:   5.9854, trn acc: 0.0368, val loss:   4.1952, val acc: 0.0449\n",
      "Epoch [  27/200], trn los:   5.7458, trn acc: 0.0482, val loss:   4.1765, val acc: 0.0562\n",
      "Epoch [  28/200], trn los:   5.5720, trn acc: 0.0425, val loss:   4.1719, val acc: 0.0674\n",
      "Epoch [  29/200], trn los:   5.3468, trn acc: 0.0312, val loss:   4.1456, val acc: 0.0787\n",
      "Epoch [  30/200], trn los:   5.0796, trn acc: 0.0595, val loss:   4.1386, val acc: 0.0787\n",
      "Epoch [  31/200], trn los:   4.8303, trn acc: 0.0510, val loss:   4.1326, val acc: 0.0787\n",
      "Epoch [  32/200], trn los:   4.7324, trn acc: 0.0283, val loss:   4.0959, val acc: 0.0787\n",
      "Epoch [  33/200], trn los:   4.5766, trn acc: 0.0510, val loss:   4.0898, val acc: 0.0787\n",
      "Epoch [  34/200], trn los:   4.4928, trn acc: 0.0453, val loss:   4.0975, val acc: 0.0674\n",
      "Epoch [  35/200], trn los:   4.4081, trn acc: 0.0538, val loss:   4.0722, val acc: 0.0787\n",
      "Epoch [  36/200], trn los:   4.1396, trn acc: 0.0368, val loss:   4.0588, val acc: 0.0562\n",
      "Epoch [  37/200], trn los:   4.0938, trn acc: 0.0397, val loss:   4.0481, val acc: 0.0562\n",
      "Epoch [  38/200], trn los:   3.9469, trn acc: 0.0482, val loss:   4.0614, val acc: 0.0674\n",
      "Epoch [  39/200], trn los:   3.7712, trn acc: 0.0312, val loss:   4.0855, val acc: 0.0449\n",
      "Epoch [  40/200], trn los:   3.7327, trn acc: 0.0425, val loss:   4.0669, val acc: 0.0674\n",
      "Epoch [  41/200], trn los:   3.5225, trn acc: 0.0510, val loss:   4.0258, val acc: 0.0674\n",
      "Epoch [  42/200], trn los:   3.4491, trn acc: 0.0652, val loss:   4.0093, val acc: 0.0449\n",
      "Epoch [  43/200], trn los:   3.3706, trn acc: 0.0368, val loss:   3.9898, val acc: 0.0562\n",
      "Epoch [  44/200], trn los:   3.2778, trn acc: 0.0340, val loss:   3.9989, val acc: 0.0674\n",
      "Epoch [  45/200], trn los:   3.1300, trn acc: 0.0765, val loss:   4.0059, val acc: 0.0787\n",
      "Epoch [  46/200], trn los:   3.1412, trn acc: 0.0680, val loss:   4.0321, val acc: 0.0225\n",
      "Epoch [  47/200], trn los:   3.0485, trn acc: 0.0737, val loss:   3.9925, val acc: 0.1124\n",
      "Epoch [  48/200], trn los:   3.0048, trn acc: 0.0708, val loss:   4.0038, val acc: 0.1124\n",
      "Epoch [  49/200], trn los:   2.9283, trn acc: 0.0368, val loss:   3.9933, val acc: 0.0787\n",
      "Epoch [  50/200], trn los:   2.7955, trn acc: 0.0482, val loss:   3.9628, val acc: 0.0337\n",
      "Epoch [  51/200], trn los:   2.7683, trn acc: 0.0623, val loss:   3.9487, val acc: 0.0449\n",
      "Epoch [  52/200], trn los:   2.7197, trn acc: 0.0595, val loss:   3.9329, val acc: 0.1011\n",
      "Epoch [  53/200], trn los:   2.6409, trn acc: 0.0907, val loss:   3.8955, val acc: 0.1124\n",
      "Epoch [  54/200], trn los:   2.5813, trn acc: 0.0567, val loss:   3.8966, val acc: 0.1011\n",
      "Epoch [  55/200], trn los:   2.4919, trn acc: 0.0708, val loss:   3.8774, val acc: 0.1011\n",
      "Epoch [  56/200], trn los:   2.5018, trn acc: 0.0538, val loss:   3.8682, val acc: 0.1124\n",
      "Epoch [  57/200], trn los:   2.4074, trn acc: 0.0680, val loss:   3.8811, val acc: 0.0899\n",
      "Epoch [  58/200], trn los:   2.3750, trn acc: 0.0567, val loss:   3.8714, val acc: 0.0787\n",
      "Epoch [  59/200], trn los:   2.3318, trn acc: 0.0538, val loss:   3.8509, val acc: 0.1011\n",
      "Epoch [  60/200], trn los:   2.2634, trn acc: 0.0737, val loss:   3.8738, val acc: 0.1011\n",
      "Epoch [  61/200], trn los:   2.2407, trn acc: 0.0595, val loss:   3.8529, val acc: 0.0899\n",
      "Epoch [  62/200], trn los:   2.1991, trn acc: 0.0680, val loss:   3.8610, val acc: 0.0674\n",
      "Epoch [  63/200], trn los:   2.0984, trn acc: 0.0935, val loss:   3.8842, val acc: 0.0674\n",
      "Epoch [  64/200], trn los:   2.1355, trn acc: 0.0595, val loss:   3.8645, val acc: 0.0899\n",
      "Epoch [  65/200], trn los:   2.0578, trn acc: 0.0567, val loss:   3.8531, val acc: 0.0787\n",
      "Epoch [  66/200], trn los:   2.0200, trn acc: 0.0623, val loss:   3.8697, val acc: 0.0449\n",
      "Epoch [  67/200], trn los:   1.9944, trn acc: 0.0595, val loss:   3.8631, val acc: 0.0449\n",
      "Epoch [  68/200], trn los:   1.9337, trn acc: 0.0878, val loss:   3.8762, val acc: 0.0674\n",
      "Epoch [  69/200], trn los:   1.9283, trn acc: 0.0765, val loss:   3.8366, val acc: 0.0787\n",
      "Epoch [  70/200], trn los:   1.9043, trn acc: 0.0822, val loss:   3.8137, val acc: 0.0562\n",
      "Epoch [  71/200], trn los:   1.8348, trn acc: 0.1076, val loss:   3.8047, val acc: 0.0674\n",
      "Epoch [  72/200], trn los:   1.8632, trn acc: 0.0453, val loss:   3.8015, val acc: 0.0899\n",
      "Epoch [  73/200], trn los:   1.7619, trn acc: 0.0935, val loss:   3.7863, val acc: 0.1124\n",
      "Epoch [  74/200], trn los:   1.7793, trn acc: 0.0652, val loss:   3.7747, val acc: 0.0899\n",
      "Epoch [  75/200], trn los:   1.7400, trn acc: 0.0708, val loss:   3.7823, val acc: 0.0787\n",
      "Epoch [  76/200], trn los:   1.6926, trn acc: 0.0793, val loss:   3.8007, val acc: 0.0899\n",
      "Epoch [  77/200], trn los:   1.7041, trn acc: 0.0878, val loss:   3.8057, val acc: 0.0674\n",
      "Epoch [  78/200], trn los:   1.6697, trn acc: 0.0793, val loss:   3.8133, val acc: 0.0449\n",
      "Epoch [  79/200], trn los:   1.6115, trn acc: 0.0935, val loss:   3.8145, val acc: 0.0674\n",
      "Epoch [  80/200], trn los:   1.6148, trn acc: 0.0935, val loss:   3.7824, val acc: 0.0899\n",
      "Epoch [  81/200], trn los:   1.5613, trn acc: 0.0992, val loss:   3.7426, val acc: 0.0787\n",
      "Epoch [  82/200], trn los:   1.5526, trn acc: 0.0737, val loss:   3.7435, val acc: 0.0787\n",
      "Epoch [  83/200], trn los:   1.5126, trn acc: 0.1133, val loss:   3.7359, val acc: 0.0674\n",
      "Epoch [  84/200], trn los:   1.5117, trn acc: 0.0850, val loss:   3.7399, val acc: 0.0899\n",
      "Epoch [  85/200], trn los:   1.4944, trn acc: 0.1161, val loss:   3.7513, val acc: 0.0899\n",
      "Epoch [  86/200], trn los:   1.4840, trn acc: 0.0765, val loss:   3.7472, val acc: 0.0899\n",
      "Epoch [  87/200], trn los:   1.4193, trn acc: 0.1076, val loss:   3.7278, val acc: 0.0899\n",
      "Epoch [  88/200], trn los:   1.4118, trn acc: 0.0850, val loss:   3.7275, val acc: 0.1011\n",
      "Epoch [  89/200], trn los:   1.3958, trn acc: 0.0793, val loss:   3.7549, val acc: 0.0787\n",
      "Epoch [  90/200], trn los:   1.3994, trn acc: 0.0765, val loss:   3.7607, val acc: 0.0562\n",
      "Epoch [  91/200], trn los:   1.3655, trn acc: 0.0935, val loss:   3.7340, val acc: 0.0899\n",
      "Epoch [  92/200], trn los:   1.3528, trn acc: 0.1076, val loss:   3.7317, val acc: 0.0899\n",
      "Epoch [  93/200], trn los:   1.3312, trn acc: 0.0822, val loss:   3.6978, val acc: 0.1011\n",
      "Epoch [  94/200], trn los:   1.3329, trn acc: 0.0708, val loss:   3.7013, val acc: 0.0562\n",
      "Epoch [  95/200], trn los:   1.3040, trn acc: 0.0822, val loss:   3.7300, val acc: 0.0787\n",
      "Epoch [  96/200], trn los:   1.2861, trn acc: 0.0708, val loss:   3.7117, val acc: 0.1011\n",
      "Epoch [  97/200], trn los:   1.2610, trn acc: 0.1076, val loss:   3.7390, val acc: 0.0787\n",
      "Epoch [  98/200], trn los:   1.2703, trn acc: 0.0963, val loss:   3.6875, val acc: 0.0562\n",
      "Epoch [  99/200], trn los:   1.2543, trn acc: 0.1020, val loss:   3.6970, val acc: 0.0674\n",
      "Epoch [ 100/200], trn los:   1.2150, trn acc: 0.0992, val loss:   3.6812, val acc: 0.0787\n",
      "Epoch [ 101/200], trn los:   1.1980, trn acc: 0.0793, val loss:   3.6527, val acc: 0.0899\n",
      "Epoch [ 102/200], trn los:   1.2055, trn acc: 0.1048, val loss:   3.6729, val acc: 0.0674\n",
      "Epoch [ 103/200], trn los:   1.1688, trn acc: 0.0822, val loss:   3.6791, val acc: 0.0562\n",
      "Epoch [ 104/200], trn los:   1.1636, trn acc: 0.1161, val loss:   3.7254, val acc: 0.0787\n",
      "Epoch [ 105/200], trn los:   1.1557, trn acc: 0.0737, val loss:   3.6798, val acc: 0.0787\n",
      "Epoch [ 106/200], trn los:   1.1301, trn acc: 0.1048, val loss:   3.6826, val acc: 0.0899\n",
      "Epoch [ 107/200], trn los:   1.1162, trn acc: 0.0907, val loss:   3.6828, val acc: 0.0787\n",
      "Epoch [ 108/200], trn los:   1.1150, trn acc: 0.0737, val loss:   3.6942, val acc: 0.0787\n",
      "Epoch [ 109/200], trn los:   1.0957, trn acc: 0.1048, val loss:   3.6820, val acc: 0.0899\n",
      "Epoch [ 110/200], trn los:   1.0902, trn acc: 0.1161, val loss:   3.6847, val acc: 0.0899\n",
      "Epoch [ 111/200], trn los:   1.0809, trn acc: 0.1218, val loss:   3.6531, val acc: 0.0674\n",
      "Epoch [ 112/200], trn los:   1.0679, trn acc: 0.1190, val loss:   3.6678, val acc: 0.0787\n",
      "Epoch [ 113/200], trn los:   1.0450, trn acc: 0.1020, val loss:   3.6671, val acc: 0.0787\n",
      "Epoch [ 114/200], trn los:   1.0409, trn acc: 0.0907, val loss:   3.6587, val acc: 0.0899\n",
      "Epoch [ 115/200], trn los:   1.0094, trn acc: 0.1303, val loss:   3.6829, val acc: 0.1011\n",
      "Epoch [ 116/200], trn los:   1.0023, trn acc: 0.1246, val loss:   3.6575, val acc: 0.1011\n",
      "Epoch [ 117/200], trn los:   0.9969, trn acc: 0.1303, val loss:   3.6377, val acc: 0.0674\n",
      "Epoch [ 118/200], trn los:   0.9909, trn acc: 0.1105, val loss:   3.6349, val acc: 0.0787\n",
      "Epoch [ 119/200], trn los:   0.9847, trn acc: 0.1161, val loss:   3.6861, val acc: 0.0562\n",
      "Epoch [ 120/200], trn los:   0.9848, trn acc: 0.1076, val loss:   3.6611, val acc: 0.0674\n",
      "Epoch [ 121/200], trn los:   0.9495, trn acc: 0.1133, val loss:   3.6582, val acc: 0.0674\n",
      "Epoch [ 122/200], trn los:   0.9717, trn acc: 0.1275, val loss:   3.6463, val acc: 0.0787\n",
      "Epoch [ 123/200], trn los:   0.9215, trn acc: 0.1501, val loss:   3.6877, val acc: 0.0562\n",
      "Epoch [ 124/200], trn los:   0.9332, trn acc: 0.1161, val loss:   3.6841, val acc: 0.0674\n",
      "Epoch [ 125/200], trn los:   0.9278, trn acc: 0.1048, val loss:   3.6580, val acc: 0.0562\n",
      "Epoch [ 126/200], trn los:   0.9104, trn acc: 0.1275, val loss:   3.6710, val acc: 0.0787\n",
      "Epoch [ 127/200], trn los:   0.9155, trn acc: 0.0992, val loss:   3.6407, val acc: 0.0674\n",
      "Epoch [ 128/200], trn los:   0.8818, trn acc: 0.1076, val loss:   3.6456, val acc: 0.0899\n",
      "Epoch [ 129/200], trn los:   0.8834, trn acc: 0.1076, val loss:   3.6654, val acc: 0.1011\n",
      "Epoch [ 130/200], trn los:   0.8853, trn acc: 0.1246, val loss:   3.6821, val acc: 0.0899\n",
      "Epoch [ 131/200], trn los:   0.8650, trn acc: 0.1275, val loss:   3.6583, val acc: 0.0787\n",
      "Epoch [ 132/200], trn los:   0.8633, trn acc: 0.1190, val loss:   3.6874, val acc: 0.0787\n",
      "Epoch [ 133/200], trn los:   0.8623, trn acc: 0.1360, val loss:   3.6796, val acc: 0.0787\n",
      "Epoch [ 134/200], trn los:   0.8494, trn acc: 0.1388, val loss:   3.6782, val acc: 0.0674\n",
      "Epoch [ 135/200], trn los:   0.8271, trn acc: 0.1275, val loss:   3.6554, val acc: 0.0562\n",
      "Epoch [ 136/200], trn los:   0.8191, trn acc: 0.1161, val loss:   3.6774, val acc: 0.0787\n",
      "Epoch [ 137/200], trn los:   0.8178, trn acc: 0.1700, val loss:   3.6522, val acc: 0.0674\n",
      "Epoch [ 138/200], trn los:   0.8024, trn acc: 0.1530, val loss:   3.6622, val acc: 0.0787\n",
      "Epoch [ 139/200], trn los:   0.8038, trn acc: 0.1388, val loss:   3.6433, val acc: 0.0787\n",
      "Epoch [ 140/200], trn los:   0.8052, trn acc: 0.1275, val loss:   3.6542, val acc: 0.0787\n",
      "Epoch [ 141/200], trn los:   0.7915, trn acc: 0.1360, val loss:   3.6277, val acc: 0.0674\n",
      "Epoch [ 142/200], trn los:   0.7870, trn acc: 0.1331, val loss:   3.6351, val acc: 0.0787\n",
      "Epoch [ 143/200], trn los:   0.7681, trn acc: 0.1416, val loss:   3.6412, val acc: 0.1011\n",
      "Epoch [ 144/200], trn los:   0.7708, trn acc: 0.1473, val loss:   3.6262, val acc: 0.1124\n",
      "Epoch [ 145/200], trn los:   0.7688, trn acc: 0.1501, val loss:   3.6403, val acc: 0.0899\n",
      "Epoch [ 146/200], trn los:   0.7601, trn acc: 0.1246, val loss:   3.6345, val acc: 0.0562\n",
      "Epoch [ 147/200], trn los:   0.7619, trn acc: 0.1190, val loss:   3.6099, val acc: 0.0787\n",
      "Epoch [ 148/200], trn los:   0.7465, trn acc: 0.1331, val loss:   3.6178, val acc: 0.0787\n",
      "Epoch [ 149/200], trn los:   0.7256, trn acc: 0.1473, val loss:   3.6344, val acc: 0.0674\n",
      "Epoch [ 150/200], trn los:   0.7330, trn acc: 0.1360, val loss:   3.6417, val acc: 0.0899\n",
      "Epoch [ 151/200], trn los:   0.7141, trn acc: 0.1473, val loss:   3.6203, val acc: 0.0562\n",
      "Epoch [ 152/200], trn los:   0.7086, trn acc: 0.1445, val loss:   3.6421, val acc: 0.0787\n",
      "Epoch [ 153/200], trn los:   0.7343, trn acc: 0.1076, val loss:   3.6587, val acc: 0.0787\n",
      "Epoch [ 154/200], trn los:   0.6994, trn acc: 0.1671, val loss:   3.6643, val acc: 0.0449\n",
      "Epoch [ 155/200], trn los:   0.6909, trn acc: 0.1416, val loss:   3.6941, val acc: 0.0787\n",
      "Epoch [ 156/200], trn los:   0.6963, trn acc: 0.1388, val loss:   3.6635, val acc: 0.0449\n",
      "Epoch [ 157/200], trn los:   0.7014, trn acc: 0.1303, val loss:   3.6816, val acc: 0.0674\n",
      "Epoch [ 158/200], trn los:   0.6736, trn acc: 0.1218, val loss:   3.6667, val acc: 0.0562\n",
      "Epoch [ 159/200], trn los:   0.6843, trn acc: 0.1501, val loss:   3.6581, val acc: 0.0674\n",
      "Epoch [ 160/200], trn los:   0.6693, trn acc: 0.1473, val loss:   3.6778, val acc: 0.0899\n",
      "Epoch [ 161/200], trn los:   0.6666, trn acc: 0.1501, val loss:   3.7021, val acc: 0.0449\n",
      "Epoch [ 162/200], trn los:   0.6674, trn acc: 0.1671, val loss:   3.6999, val acc: 0.0674\n",
      "Epoch [ 163/200], trn los:   0.6440, trn acc: 0.1558, val loss:   3.6971, val acc: 0.0899\n",
      "Epoch [ 164/200], trn los:   0.6573, trn acc: 0.1530, val loss:   3.7235, val acc: 0.0899\n",
      "Epoch [ 165/200], trn los:   0.6576, trn acc: 0.1501, val loss:   3.7073, val acc: 0.0787\n",
      "Epoch [ 166/200], trn los:   0.6437, trn acc: 0.1473, val loss:   3.6940, val acc: 0.0674\n",
      "Epoch [ 167/200], trn los:   0.6406, trn acc: 0.1445, val loss:   3.6976, val acc: 0.0899\n",
      "Epoch [ 168/200], trn los:   0.6322, trn acc: 0.1501, val loss:   3.7165, val acc: 0.0899\n",
      "Epoch [ 169/200], trn los:   0.6240, trn acc: 0.1473, val loss:   3.7079, val acc: 0.0787\n",
      "Epoch [ 170/200], trn los:   0.6170, trn acc: 0.1643, val loss:   3.7264, val acc: 0.0562\n",
      "Epoch [ 171/200], trn los:   0.6349, trn acc: 0.1473, val loss:   3.7125, val acc: 0.0899\n",
      "Epoch [ 172/200], trn los:   0.6157, trn acc: 0.1501, val loss:   3.7083, val acc: 0.0674\n",
      "Epoch [ 173/200], trn los:   0.6016, trn acc: 0.1615, val loss:   3.7355, val acc: 0.0674\n",
      "Epoch [ 174/200], trn los:   0.6205, trn acc: 0.1671, val loss:   3.7202, val acc: 0.0674\n",
      "Epoch [ 175/200], trn los:   0.5910, trn acc: 0.1983, val loss:   3.7202, val acc: 0.0674\n",
      "Epoch [ 176/200], trn los:   0.6061, trn acc: 0.1331, val loss:   3.7115, val acc: 0.0674\n",
      "Epoch [ 177/200], trn los:   0.6038, trn acc: 0.1445, val loss:   3.6755, val acc: 0.0899\n",
      "Epoch [ 178/200], trn los:   0.5863, trn acc: 0.1388, val loss:   3.7066, val acc: 0.1011\n",
      "Epoch [ 179/200], trn los:   0.5930, trn acc: 0.1501, val loss:   3.6989, val acc: 0.1011\n",
      "Epoch [ 180/200], trn los:   0.5797, trn acc: 0.1246, val loss:   3.7122, val acc: 0.0787\n",
      "Epoch [ 181/200], trn los:   0.5753, trn acc: 0.1785, val loss:   3.7112, val acc: 0.0674\n",
      "Epoch [ 182/200], trn los:   0.5668, trn acc: 0.1473, val loss:   3.7073, val acc: 0.1011\n",
      "Epoch [ 183/200], trn los:   0.5659, trn acc: 0.1558, val loss:   3.7100, val acc: 0.0674\n",
      "Epoch [ 184/200], trn los:   0.5654, trn acc: 0.1558, val loss:   3.7144, val acc: 0.0562\n",
      "Epoch [ 185/200], trn los:   0.5635, trn acc: 0.1615, val loss:   3.7174, val acc: 0.0674\n",
      "Epoch [ 186/200], trn los:   0.5578, trn acc: 0.1955, val loss:   3.7446, val acc: 0.0787\n",
      "Epoch [ 187/200], trn los:   0.5439, trn acc: 0.1671, val loss:   3.7262, val acc: 0.0899\n",
      "Epoch [ 188/200], trn los:   0.5397, trn acc: 0.1983, val loss:   3.7182, val acc: 0.0674\n",
      "Epoch [ 189/200], trn los:   0.5512, trn acc: 0.1530, val loss:   3.7529, val acc: 0.0337\n",
      "Epoch [ 190/200], trn los:   0.5448, trn acc: 0.1671, val loss:   3.7375, val acc: 0.0674\n",
      "Epoch [ 191/200], trn los:   0.5362, trn acc: 0.1756, val loss:   3.7711, val acc: 0.0562\n",
      "Epoch [ 192/200], trn los:   0.5396, trn acc: 0.1501, val loss:   3.7442, val acc: 0.0787\n",
      "Epoch [ 193/200], trn los:   0.5294, trn acc: 0.1728, val loss:   3.7806, val acc: 0.0674\n",
      "Epoch [ 194/200], trn los:   0.5292, trn acc: 0.1671, val loss:   3.7880, val acc: 0.0787\n",
      "Epoch [ 195/200], trn los:   0.5260, trn acc: 0.1530, val loss:   3.7688, val acc: 0.0899\n",
      "Epoch [ 196/200], trn los:   0.5270, trn acc: 0.1643, val loss:   3.7867, val acc: 0.0674\n",
      "Epoch [ 197/200], trn los:   0.5305, trn acc: 0.1445, val loss:   3.7708, val acc: 0.0787\n",
      "Epoch [ 198/200], trn los:   0.5207, trn acc: 0.1671, val loss:   3.7558, val acc: 0.0787\n",
      "Epoch [ 199/200], trn los:   0.5064, trn acc: 0.1870, val loss:   3.7607, val acc: 0.0449\n",
      "Epoch [ 200/200], trn los:   0.5109, trn acc: 0.1671, val loss:   3.7621, val acc: 0.0674\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T08:48:01.395044Z",
     "start_time": "2025-04-19T08:47:41.139780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def question_13():\n",
    "    general_solver(n_cuts=100, exclude_Y=True, task=Task.CLASSIFICATION, epochs=200, lr=1e-4)\n",
    "    # Epoch [   1/200], trn los: 311.1128, trn acc: 0.0113, val loss:   5.0817, val acc: 0.0000\n",
    "    # Epoch [  67/200], trn los:   2.2001, trn acc: 0.0397, val loss:   4.9264, val acc: 0.0337\n",
    "    # Epoch [ 200/200], trn los:   0.3902, trn acc: 0.3399, val loss:   7.6031, val acc: 0.0000\n",
    "\n",
    "    # So we can see a beautiful overfit here. Where we started with 1% accuracy (which fits 100 cuts)\n",
    "    # At our best (around epoch 67, we can see the train acc is about 4% and validation at 3.3%)\n",
    "    # After that we overfit and get a great 34% accuracy which worth nothing because validation is 0.\n",
    "\n",
    "question_13()"
   ],
   "id": "c6862656d113dcc6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [   1/200], trn los: 310.8179, trn acc: 0.0028, val loss:   5.4382, val acc: 0.0000\n",
      "Epoch [   2/200], trn los: 110.8832, trn acc: 0.0170, val loss:   4.8352, val acc: 0.0112\n",
      "Epoch [   3/200], trn los:  67.3587, trn acc: 0.0057, val loss:   4.7820, val acc: 0.0112\n",
      "Epoch [   4/200], trn los:  46.4552, trn acc: 0.0085, val loss:   4.7115, val acc: 0.0000\n",
      "Epoch [   5/200], trn los:  37.4015, trn acc: 0.0170, val loss:   4.6717, val acc: 0.0000\n",
      "Epoch [   6/200], trn los:  30.4078, trn acc: 0.0142, val loss:   4.6666, val acc: 0.0000\n",
      "Epoch [   7/200], trn los:  25.2429, trn acc: 0.0113, val loss:   4.6622, val acc: 0.0112\n",
      "Epoch [   8/200], trn los:  21.9583, trn acc: 0.0085, val loss:   4.6979, val acc: 0.0225\n",
      "Epoch [   9/200], trn los:  19.3444, trn acc: 0.0000, val loss:   4.6796, val acc: 0.0000\n",
      "Epoch [  10/200], trn los:  17.1099, trn acc: 0.0227, val loss:   4.7135, val acc: 0.0000\n",
      "Epoch [  11/200], trn los:  15.7051, trn acc: 0.0142, val loss:   4.6995, val acc: 0.0000\n",
      "Epoch [  12/200], trn los:  14.1490, trn acc: 0.0085, val loss:   4.6460, val acc: 0.0225\n",
      "Epoch [  13/200], trn los:  12.8258, trn acc: 0.0255, val loss:   4.6557, val acc: 0.0000\n",
      "Epoch [  14/200], trn los:  12.0090, trn acc: 0.0113, val loss:   4.6494, val acc: 0.0112\n",
      "Epoch [  15/200], trn los:  11.2077, trn acc: 0.0142, val loss:   4.6417, val acc: 0.0112\n",
      "Epoch [  16/200], trn los:  10.3679, trn acc: 0.0085, val loss:   4.6417, val acc: 0.0225\n",
      "Epoch [  17/200], trn los:   9.9536, trn acc: 0.0142, val loss:   4.6492, val acc: 0.0000\n",
      "Epoch [  18/200], trn los:   9.2978, trn acc: 0.0085, val loss:   4.6527, val acc: 0.0000\n",
      "Epoch [  19/200], trn los:   8.6825, trn acc: 0.0113, val loss:   4.6487, val acc: 0.0000\n",
      "Epoch [  20/200], trn los:   8.2877, trn acc: 0.0227, val loss:   4.6565, val acc: 0.0000\n",
      "Epoch [  21/200], trn los:   7.8586, trn acc: 0.0227, val loss:   4.6672, val acc: 0.0000\n",
      "Epoch [  22/200], trn los:   7.4646, trn acc: 0.0198, val loss:   4.6318, val acc: 0.0112\n",
      "Epoch [  23/200], trn los:   7.0296, trn acc: 0.0312, val loss:   4.6319, val acc: 0.0225\n",
      "Epoch [  24/200], trn los:   6.8456, trn acc: 0.0170, val loss:   4.6108, val acc: 0.0337\n",
      "Epoch [  25/200], trn los:   6.4572, trn acc: 0.0397, val loss:   4.6164, val acc: 0.0112\n",
      "Epoch [  26/200], trn los:   6.2775, trn acc: 0.0170, val loss:   4.6268, val acc: 0.0112\n",
      "Epoch [  27/200], trn los:   6.0672, trn acc: 0.0142, val loss:   4.6469, val acc: 0.0225\n",
      "Epoch [  28/200], trn los:   5.8436, trn acc: 0.0283, val loss:   4.6983, val acc: 0.0112\n",
      "Epoch [  29/200], trn los:   5.5969, trn acc: 0.0198, val loss:   4.6452, val acc: 0.0112\n",
      "Epoch [  30/200], trn los:   5.3972, trn acc: 0.0255, val loss:   4.6463, val acc: 0.0000\n",
      "Epoch [  31/200], trn los:   5.1531, trn acc: 0.0312, val loss:   4.6908, val acc: 0.0225\n",
      "Epoch [  32/200], trn los:   4.9670, trn acc: 0.0425, val loss:   4.6773, val acc: 0.0337\n",
      "Epoch [  33/200], trn los:   4.8262, trn acc: 0.0397, val loss:   4.6979, val acc: 0.0000\n",
      "Epoch [  34/200], trn los:   4.6691, trn acc: 0.0198, val loss:   4.6603, val acc: 0.0000\n",
      "Epoch [  35/200], trn los:   4.5704, trn acc: 0.0255, val loss:   4.6740, val acc: 0.0112\n",
      "Epoch [  36/200], trn los:   4.4035, trn acc: 0.0283, val loss:   4.6482, val acc: 0.0112\n",
      "Epoch [  37/200], trn los:   4.2412, trn acc: 0.0368, val loss:   4.6926, val acc: 0.0112\n",
      "Epoch [  38/200], trn los:   4.1298, trn acc: 0.0198, val loss:   4.6975, val acc: 0.0112\n",
      "Epoch [  39/200], trn los:   4.0077, trn acc: 0.0312, val loss:   4.7006, val acc: 0.0112\n",
      "Epoch [  40/200], trn los:   3.8920, trn acc: 0.0170, val loss:   4.6969, val acc: 0.0225\n",
      "Epoch [  41/200], trn los:   3.8159, trn acc: 0.0340, val loss:   4.7128, val acc: 0.0225\n",
      "Epoch [  42/200], trn los:   3.6647, trn acc: 0.0283, val loss:   4.7113, val acc: 0.0112\n",
      "Epoch [  43/200], trn los:   3.5781, trn acc: 0.0368, val loss:   4.7521, val acc: 0.0225\n",
      "Epoch [  44/200], trn los:   3.5108, trn acc: 0.0368, val loss:   4.7215, val acc: 0.0112\n",
      "Epoch [  45/200], trn los:   3.3670, trn acc: 0.0482, val loss:   4.7263, val acc: 0.0112\n",
      "Epoch [  46/200], trn los:   3.3178, trn acc: 0.0425, val loss:   4.6741, val acc: 0.0225\n",
      "Epoch [  47/200], trn los:   3.2348, trn acc: 0.0368, val loss:   4.7330, val acc: 0.0112\n",
      "Epoch [  48/200], trn los:   3.1733, trn acc: 0.0425, val loss:   4.8146, val acc: 0.0112\n",
      "Epoch [  49/200], trn los:   3.0697, trn acc: 0.0482, val loss:   4.8019, val acc: 0.0112\n",
      "Epoch [  50/200], trn los:   3.0248, trn acc: 0.0340, val loss:   4.7717, val acc: 0.0225\n",
      "Epoch [  51/200], trn los:   2.9781, trn acc: 0.0368, val loss:   4.7279, val acc: 0.0000\n",
      "Epoch [  52/200], trn los:   2.8980, trn acc: 0.0397, val loss:   4.7319, val acc: 0.0112\n",
      "Epoch [  53/200], trn los:   2.8177, trn acc: 0.0368, val loss:   4.8169, val acc: 0.0225\n",
      "Epoch [  54/200], trn los:   2.7907, trn acc: 0.0482, val loss:   4.7797, val acc: 0.0000\n",
      "Epoch [  55/200], trn los:   2.7280, trn acc: 0.0425, val loss:   4.7835, val acc: 0.0225\n",
      "Epoch [  56/200], trn los:   2.6659, trn acc: 0.0482, val loss:   4.8135, val acc: 0.0225\n",
      "Epoch [  57/200], trn los:   2.6186, trn acc: 0.0425, val loss:   4.8055, val acc: 0.0225\n",
      "Epoch [  58/200], trn los:   2.5315, trn acc: 0.0567, val loss:   4.8275, val acc: 0.0112\n",
      "Epoch [  59/200], trn los:   2.5121, trn acc: 0.0567, val loss:   4.8389, val acc: 0.0225\n",
      "Epoch [  60/200], trn los:   2.4460, trn acc: 0.0538, val loss:   4.9057, val acc: 0.0225\n",
      "Epoch [  61/200], trn los:   2.4045, trn acc: 0.0510, val loss:   4.8697, val acc: 0.0112\n",
      "Epoch [  62/200], trn los:   2.3887, trn acc: 0.0623, val loss:   4.8424, val acc: 0.0225\n",
      "Epoch [  63/200], trn los:   2.3529, trn acc: 0.0510, val loss:   4.8814, val acc: 0.0337\n",
      "Epoch [  64/200], trn los:   2.2978, trn acc: 0.0453, val loss:   4.8887, val acc: 0.0112\n",
      "Epoch [  65/200], trn los:   2.2478, trn acc: 0.0340, val loss:   4.9113, val acc: 0.0337\n",
      "Epoch [  66/200], trn los:   2.2016, trn acc: 0.0652, val loss:   4.9259, val acc: 0.0225\n",
      "Epoch [  67/200], trn los:   2.1608, trn acc: 0.0453, val loss:   4.9164, val acc: 0.0337\n",
      "Epoch [  68/200], trn los:   2.1139, trn acc: 0.0538, val loss:   4.9344, val acc: 0.0112\n",
      "Epoch [  69/200], trn los:   2.0788, trn acc: 0.0510, val loss:   4.9843, val acc: 0.0225\n",
      "Epoch [  70/200], trn los:   2.0582, trn acc: 0.0737, val loss:   4.9362, val acc: 0.0112\n",
      "Epoch [  71/200], trn los:   1.9799, trn acc: 0.0425, val loss:   4.9767, val acc: 0.0337\n",
      "Epoch [  72/200], trn los:   1.9842, trn acc: 0.0510, val loss:   4.9739, val acc: 0.0225\n",
      "Epoch [  73/200], trn los:   1.9574, trn acc: 0.0538, val loss:   4.9881, val acc: 0.0112\n",
      "Epoch [  74/200], trn los:   1.9184, trn acc: 0.0793, val loss:   5.0280, val acc: 0.0225\n",
      "Epoch [  75/200], trn los:   1.8769, trn acc: 0.0510, val loss:   5.0055, val acc: 0.0225\n",
      "Epoch [  76/200], trn los:   1.8607, trn acc: 0.0708, val loss:   5.0556, val acc: 0.0225\n",
      "Epoch [  77/200], trn los:   1.8224, trn acc: 0.0680, val loss:   5.0448, val acc: 0.0225\n",
      "Epoch [  78/200], trn los:   1.7885, trn acc: 0.0652, val loss:   5.1036, val acc: 0.0225\n",
      "Epoch [  79/200], trn los:   1.7697, trn acc: 0.0538, val loss:   5.1205, val acc: 0.0112\n",
      "Epoch [  80/200], trn los:   1.7499, trn acc: 0.0623, val loss:   5.0826, val acc: 0.0112\n",
      "Epoch [  81/200], trn los:   1.7232, trn acc: 0.0737, val loss:   5.1865, val acc: 0.0225\n",
      "Epoch [  82/200], trn los:   1.7031, trn acc: 0.0595, val loss:   5.1629, val acc: 0.0225\n",
      "Epoch [  83/200], trn los:   1.6571, trn acc: 0.0793, val loss:   5.1795, val acc: 0.0000\n",
      "Epoch [  84/200], trn los:   1.6435, trn acc: 0.0850, val loss:   5.1633, val acc: 0.0112\n",
      "Epoch [  85/200], trn los:   1.6196, trn acc: 0.0708, val loss:   5.1690, val acc: 0.0112\n",
      "Epoch [  86/200], trn los:   1.5868, trn acc: 0.0907, val loss:   5.2380, val acc: 0.0225\n",
      "Epoch [  87/200], trn los:   1.5590, trn acc: 0.0737, val loss:   5.2862, val acc: 0.0000\n",
      "Epoch [  88/200], trn los:   1.5572, trn acc: 0.0623, val loss:   5.2929, val acc: 0.0112\n",
      "Epoch [  89/200], trn los:   1.5370, trn acc: 0.0765, val loss:   5.2071, val acc: 0.0112\n",
      "Epoch [  90/200], trn los:   1.4904, trn acc: 0.0850, val loss:   5.3026, val acc: 0.0112\n",
      "Epoch [  91/200], trn los:   1.4749, trn acc: 0.0737, val loss:   5.3304, val acc: 0.0112\n",
      "Epoch [  92/200], trn los:   1.4440, trn acc: 0.0935, val loss:   5.3387, val acc: 0.0112\n",
      "Epoch [  93/200], trn los:   1.4354, trn acc: 0.0737, val loss:   5.3527, val acc: 0.0000\n",
      "Epoch [  94/200], trn los:   1.4293, trn acc: 0.0765, val loss:   5.3772, val acc: 0.0112\n",
      "Epoch [  95/200], trn los:   1.4043, trn acc: 0.0907, val loss:   5.3339, val acc: 0.0225\n",
      "Epoch [  96/200], trn los:   1.3698, trn acc: 0.1048, val loss:   5.3785, val acc: 0.0225\n",
      "Epoch [  97/200], trn los:   1.3354, trn acc: 0.0907, val loss:   5.4196, val acc: 0.0000\n",
      "Epoch [  98/200], trn los:   1.3322, trn acc: 0.0737, val loss:   5.4228, val acc: 0.0000\n",
      "Epoch [  99/200], trn los:   1.3019, trn acc: 0.0907, val loss:   5.4062, val acc: 0.0112\n",
      "Epoch [ 100/200], trn los:   1.2862, trn acc: 0.0992, val loss:   5.4967, val acc: 0.0000\n",
      "Epoch [ 101/200], trn los:   1.2800, trn acc: 0.0822, val loss:   5.4801, val acc: 0.0112\n",
      "Epoch [ 102/200], trn los:   1.2594, trn acc: 0.0935, val loss:   5.5354, val acc: 0.0000\n",
      "Epoch [ 103/200], trn los:   1.2238, trn acc: 0.1133, val loss:   5.5032, val acc: 0.0112\n",
      "Epoch [ 104/200], trn los:   1.2352, trn acc: 0.1020, val loss:   5.5762, val acc: 0.0225\n",
      "Epoch [ 105/200], trn los:   1.2174, trn acc: 0.1161, val loss:   5.5381, val acc: 0.0000\n",
      "Epoch [ 106/200], trn los:   1.2132, trn acc: 0.0793, val loss:   5.4745, val acc: 0.0000\n",
      "Epoch [ 107/200], trn los:   1.1699, trn acc: 0.1161, val loss:   5.6418, val acc: 0.0000\n",
      "Epoch [ 108/200], trn los:   1.1588, trn acc: 0.1190, val loss:   5.6468, val acc: 0.0112\n",
      "Epoch [ 109/200], trn los:   1.1565, trn acc: 0.1133, val loss:   5.6471, val acc: 0.0112\n",
      "Epoch [ 110/200], trn los:   1.1308, trn acc: 0.1105, val loss:   5.6353, val acc: 0.0000\n",
      "Epoch [ 111/200], trn los:   1.1191, trn acc: 0.1133, val loss:   5.7030, val acc: 0.0000\n",
      "Epoch [ 112/200], trn los:   1.1134, trn acc: 0.1076, val loss:   5.6959, val acc: 0.0000\n",
      "Epoch [ 113/200], trn los:   1.0900, trn acc: 0.1190, val loss:   5.7533, val acc: 0.0000\n",
      "Epoch [ 114/200], trn los:   1.0664, trn acc: 0.1303, val loss:   5.8026, val acc: 0.0000\n",
      "Epoch [ 115/200], trn los:   1.0673, trn acc: 0.1105, val loss:   5.7820, val acc: 0.0000\n",
      "Epoch [ 116/200], trn los:   1.0456, trn acc: 0.1076, val loss:   5.8173, val acc: 0.0112\n",
      "Epoch [ 117/200], trn los:   1.0371, trn acc: 0.1445, val loss:   5.8155, val acc: 0.0000\n",
      "Epoch [ 118/200], trn los:   1.0268, trn acc: 0.1133, val loss:   5.8490, val acc: 0.0000\n",
      "Epoch [ 119/200], trn los:   0.9984, trn acc: 0.1275, val loss:   5.8230, val acc: 0.0000\n",
      "Epoch [ 120/200], trn los:   0.9878, trn acc: 0.1388, val loss:   5.8639, val acc: 0.0000\n",
      "Epoch [ 121/200], trn los:   0.9807, trn acc: 0.1076, val loss:   5.9229, val acc: 0.0000\n",
      "Epoch [ 122/200], trn los:   0.9774, trn acc: 0.1105, val loss:   5.8735, val acc: 0.0000\n",
      "Epoch [ 123/200], trn los:   0.9575, trn acc: 0.1190, val loss:   5.9227, val acc: 0.0000\n",
      "Epoch [ 124/200], trn los:   0.9395, trn acc: 0.1303, val loss:   5.9641, val acc: 0.0000\n",
      "Epoch [ 125/200], trn los:   0.9179, trn acc: 0.1671, val loss:   6.0401, val acc: 0.0112\n",
      "Epoch [ 126/200], trn los:   0.9096, trn acc: 0.1756, val loss:   6.0049, val acc: 0.0000\n",
      "Epoch [ 127/200], trn los:   0.9128, trn acc: 0.1586, val loss:   6.0017, val acc: 0.0000\n",
      "Epoch [ 128/200], trn los:   0.8894, trn acc: 0.1558, val loss:   6.0187, val acc: 0.0000\n",
      "Epoch [ 129/200], trn los:   0.8817, trn acc: 0.1530, val loss:   6.0466, val acc: 0.0000\n",
      "Epoch [ 130/200], trn los:   0.8830, trn acc: 0.1445, val loss:   6.0491, val acc: 0.0000\n",
      "Epoch [ 131/200], trn los:   0.8581, trn acc: 0.1501, val loss:   6.1173, val acc: 0.0000\n",
      "Epoch [ 132/200], trn los:   0.8403, trn acc: 0.1558, val loss:   6.1468, val acc: 0.0000\n",
      "Epoch [ 133/200], trn los:   0.8326, trn acc: 0.1700, val loss:   6.2738, val acc: 0.0000\n",
      "Epoch [ 134/200], trn los:   0.8297, trn acc: 0.1586, val loss:   6.0935, val acc: 0.0000\n",
      "Epoch [ 135/200], trn los:   0.8230, trn acc: 0.1501, val loss:   6.1804, val acc: 0.0000\n",
      "Epoch [ 136/200], trn los:   0.8008, trn acc: 0.1473, val loss:   6.2590, val acc: 0.0000\n",
      "Epoch [ 137/200], trn los:   0.7922, trn acc: 0.1615, val loss:   6.2584, val acc: 0.0000\n",
      "Epoch [ 138/200], trn los:   0.7857, trn acc: 0.1700, val loss:   6.2195, val acc: 0.0000\n",
      "Epoch [ 139/200], trn los:   0.7956, trn acc: 0.1473, val loss:   6.2638, val acc: 0.0000\n",
      "Epoch [ 140/200], trn los:   0.7556, trn acc: 0.1926, val loss:   6.2768, val acc: 0.0000\n",
      "Epoch [ 141/200], trn los:   0.7493, trn acc: 0.1898, val loss:   6.3553, val acc: 0.0000\n",
      "Epoch [ 142/200], trn los:   0.7418, trn acc: 0.1643, val loss:   6.3623, val acc: 0.0000\n",
      "Epoch [ 143/200], trn los:   0.7321, trn acc: 0.1813, val loss:   6.3587, val acc: 0.0000\n",
      "Epoch [ 144/200], trn los:   0.7312, trn acc: 0.1700, val loss:   6.3746, val acc: 0.0000\n",
      "Epoch [ 145/200], trn los:   0.7221, trn acc: 0.1813, val loss:   6.3914, val acc: 0.0000\n",
      "Epoch [ 146/200], trn los:   0.7251, trn acc: 0.1586, val loss:   6.4519, val acc: 0.0000\n",
      "Epoch [ 147/200], trn los:   0.6920, trn acc: 0.2011, val loss:   6.4413, val acc: 0.0000\n",
      "Epoch [ 148/200], trn los:   0.7052, trn acc: 0.1643, val loss:   6.4153, val acc: 0.0000\n",
      "Epoch [ 149/200], trn los:   0.6911, trn acc: 0.1955, val loss:   6.5023, val acc: 0.0000\n",
      "Epoch [ 150/200], trn los:   0.6686, trn acc: 0.2153, val loss:   6.5312, val acc: 0.0000\n",
      "Epoch [ 151/200], trn los:   0.6634, trn acc: 0.2210, val loss:   6.5148, val acc: 0.0000\n",
      "Epoch [ 152/200], trn los:   0.6498, trn acc: 0.2153, val loss:   6.6836, val acc: 0.0000\n",
      "Epoch [ 153/200], trn los:   0.6467, trn acc: 0.2323, val loss:   6.7438, val acc: 0.0000\n",
      "Epoch [ 154/200], trn los:   0.6364, trn acc: 0.2238, val loss:   6.6290, val acc: 0.0000\n",
      "Epoch [ 155/200], trn los:   0.6351, trn acc: 0.2125, val loss:   6.7907, val acc: 0.0000\n",
      "Epoch [ 156/200], trn los:   0.6215, trn acc: 0.2238, val loss:   6.7403, val acc: 0.0000\n",
      "Epoch [ 157/200], trn los:   0.6224, trn acc: 0.2210, val loss:   6.7283, val acc: 0.0000\n",
      "Epoch [ 158/200], trn los:   0.6156, trn acc: 0.2096, val loss:   6.7978, val acc: 0.0000\n",
      "Epoch [ 159/200], trn los:   0.6098, trn acc: 0.2125, val loss:   6.7603, val acc: 0.0000\n",
      "Epoch [ 160/200], trn los:   0.5898, trn acc: 0.2266, val loss:   6.8955, val acc: 0.0000\n",
      "Epoch [ 161/200], trn los:   0.5860, trn acc: 0.2238, val loss:   6.8229, val acc: 0.0000\n",
      "Epoch [ 162/200], trn los:   0.5801, trn acc: 0.2380, val loss:   6.8421, val acc: 0.0000\n",
      "Epoch [ 163/200], trn los:   0.5863, trn acc: 0.2550, val loss:   6.9300, val acc: 0.0000\n",
      "Epoch [ 164/200], trn los:   0.5732, trn acc: 0.2720, val loss:   6.8913, val acc: 0.0000\n",
      "Epoch [ 165/200], trn los:   0.5655, trn acc: 0.2521, val loss:   6.8865, val acc: 0.0000\n",
      "Epoch [ 166/200], trn los:   0.5549, trn acc: 0.2436, val loss:   6.9153, val acc: 0.0000\n",
      "Epoch [ 167/200], trn los:   0.5530, trn acc: 0.2380, val loss:   6.9929, val acc: 0.0000\n",
      "Epoch [ 168/200], trn los:   0.5465, trn acc: 0.2323, val loss:   6.9442, val acc: 0.0000\n",
      "Epoch [ 169/200], trn los:   0.5440, trn acc: 0.2663, val loss:   6.9748, val acc: 0.0000\n",
      "Epoch [ 170/200], trn los:   0.5382, trn acc: 0.2691, val loss:   7.0307, val acc: 0.0000\n",
      "Epoch [ 171/200], trn los:   0.5300, trn acc: 0.2748, val loss:   7.0533, val acc: 0.0000\n",
      "Epoch [ 172/200], trn los:   0.5168, trn acc: 0.2776, val loss:   7.0684, val acc: 0.0000\n",
      "Epoch [ 173/200], trn los:   0.5089, trn acc: 0.2861, val loss:   7.0944, val acc: 0.0000\n",
      "Epoch [ 174/200], trn los:   0.5049, trn acc: 0.2691, val loss:   7.1241, val acc: 0.0000\n",
      "Epoch [ 175/200], trn los:   0.4832, trn acc: 0.3286, val loss:   7.1958, val acc: 0.0000\n",
      "Epoch [ 176/200], trn los:   0.4957, trn acc: 0.2946, val loss:   7.2252, val acc: 0.0000\n",
      "Epoch [ 177/200], trn los:   0.4910, trn acc: 0.2833, val loss:   7.2444, val acc: 0.0000\n",
      "Epoch [ 178/200], trn los:   0.4695, trn acc: 0.3088, val loss:   7.3662, val acc: 0.0000\n",
      "Epoch [ 179/200], trn los:   0.4604, trn acc: 0.3144, val loss:   7.2852, val acc: 0.0000\n",
      "Epoch [ 180/200], trn los:   0.4675, trn acc: 0.2975, val loss:   7.3244, val acc: 0.0000\n",
      "Epoch [ 181/200], trn los:   0.4616, trn acc: 0.3229, val loss:   7.2791, val acc: 0.0000\n",
      "Epoch [ 182/200], trn los:   0.4502, trn acc: 0.3343, val loss:   7.4069, val acc: 0.0000\n",
      "Epoch [ 183/200], trn los:   0.4497, trn acc: 0.3144, val loss:   7.4269, val acc: 0.0000\n",
      "Epoch [ 184/200], trn los:   0.4332, trn acc: 0.3399, val loss:   7.4086, val acc: 0.0000\n",
      "Epoch [ 185/200], trn los:   0.4448, trn acc: 0.3088, val loss:   7.3148, val acc: 0.0000\n",
      "Epoch [ 186/200], trn los:   0.4289, trn acc: 0.3456, val loss:   7.4515, val acc: 0.0000\n",
      "Epoch [ 187/200], trn los:   0.4240, trn acc: 0.3711, val loss:   7.4383, val acc: 0.0000\n",
      "Epoch [ 188/200], trn los:   0.4151, trn acc: 0.3626, val loss:   7.5810, val acc: 0.0000\n",
      "Epoch [ 189/200], trn los:   0.4152, trn acc: 0.3314, val loss:   7.6316, val acc: 0.0000\n",
      "Epoch [ 190/200], trn los:   0.4082, trn acc: 0.3456, val loss:   7.6319, val acc: 0.0000\n",
      "Epoch [ 191/200], trn los:   0.4116, trn acc: 0.3201, val loss:   7.6330, val acc: 0.0000\n",
      "Epoch [ 192/200], trn los:   0.4179, trn acc: 0.3343, val loss:   7.5585, val acc: 0.0000\n",
      "Epoch [ 193/200], trn los:   0.3967, trn acc: 0.3853, val loss:   7.6501, val acc: 0.0000\n",
      "Epoch [ 194/200], trn los:   0.3940, trn acc: 0.3853, val loss:   7.7336, val acc: 0.0112\n",
      "Epoch [ 195/200], trn los:   0.3919, trn acc: 0.3626, val loss:   7.7118, val acc: 0.0000\n",
      "Epoch [ 196/200], trn los:   0.3848, trn acc: 0.3824, val loss:   7.7140, val acc: 0.0000\n",
      "Epoch [ 197/200], trn los:   0.3749, trn acc: 0.4079, val loss:   7.8354, val acc: 0.0000\n",
      "Epoch [ 198/200], trn los:   0.3782, trn acc: 0.3881, val loss:   7.8379, val acc: 0.0000\n",
      "Epoch [ 199/200], trn los:   0.3783, trn acc: 0.3966, val loss:   7.8480, val acc: 0.0000\n",
      "Epoch [ 200/200], trn los:   0.3733, trn acc: 0.3513, val loss:   7.9234, val acc: 0.0000\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T08:49:48.859515Z",
     "start_time": "2025-04-19T08:48:01.412018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def question_14():\n",
    "    general_solver(n_cuts=1, exclude_Y=True, task=Task.REGRESSION, epochs=1000, lr=1e-4, verbose=1)\n",
    "    # Epoch [   1/1000], trn los: 331214.6368, trn r2: -0.5712, val loss: 5517.4431, val r2: 0.0567\n",
    "    # Epoch [ 100/1000], trn los: 1174.3142, trn r2: 0.4493, val loss: 3013.6842, val r2: 0.4818\n",
    "    # Epoch [ 728/1000], trn los: 121.1772, trn r2: 0.5838, val loss: 2487.0921, val r2: 0.5720\n",
    "    # Epoch [1000/1000], trn los:  73.8316, trn r2: 0.6607, val loss: 2743.2695, val r2: 0.5307\n",
    "\n",
    "    # We can see we start the train terrible with a huge loss and negative r2.\n",
    "    # In epoch 100, we can see we’ve improved and not overfitting yet (train and validation at the same level)\n",
    "    # In epoch 728 we can see we kept improving, and this is the maximum r2 and best epoch to stop.\n",
    "    # In epoch 1000 we can see the overfit with trn r2 >> val r2.\n",
    "\n",
    "question_14()"
   ],
   "id": "3cc39b281b868829",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [   1/1000], trn los: 293966.6459, trn r2: -0.3951, val loss: 5230.2759, val r2: 0.1023\n",
      "Epoch [   2/1000], trn los: 95255.8559, trn r2: 0.0946, val loss: 4868.4341, val r2: 0.1626\n",
      "Epoch [   3/1000], trn los: 61612.4268, trn r2: 0.1482, val loss: 5013.5965, val r2: 0.1422\n",
      "Epoch [   4/1000], trn los: 44582.8522, trn r2: 0.1698, val loss: 4335.9025, val r2: 0.2596\n",
      "Epoch [   5/1000], trn los: 34470.4560, trn r2: 0.2011, val loss: 4164.9932, val r2: 0.2844\n",
      "Epoch [   6/1000], trn los: 27750.7362, trn r2: 0.2498, val loss: 4010.2820, val r2: 0.3114\n",
      "Epoch [   7/1000], trn los: 23001.3043, trn r2: 0.2431, val loss: 3832.2544, val r2: 0.3472\n",
      "Epoch [   8/1000], trn los: 20556.4908, trn r2: 0.2319, val loss: 3750.8399, val r2: 0.3527\n",
      "Epoch [   9/1000], trn los: 17191.3702, trn r2: 0.2713, val loss: 3798.1630, val r2: 0.3464\n",
      "Epoch [  10/1000], trn los: 16112.4484, trn r2: 0.2756, val loss: 3907.2255, val r2: 0.3332\n",
      "Epoch [  11/1000], trn los: 13259.3773, trn r2: 0.3128, val loss: 4214.2699, val r2: 0.2787\n",
      "Epoch [  12/1000], trn los: 12032.9197, trn r2: 0.3327, val loss: 3529.7644, val r2: 0.3962\n",
      "Epoch [  13/1000], trn los: 10929.0334, trn r2: 0.3415, val loss: 3437.2375, val r2: 0.4095\n",
      "Epoch [  14/1000], trn los: 10851.5965, trn r2: 0.3090, val loss: 3418.8765, val r2: 0.4124\n",
      "Epoch [  15/1000], trn los: 9287.5427, trn r2: 0.3444, val loss: 3375.2678, val r2: 0.4225\n",
      "Epoch [  16/1000], trn los: 8855.5675, trn r2: 0.3436, val loss: 3356.3649, val r2: 0.4258\n",
      "Epoch [  17/1000], trn los: 8230.9983, trn r2: 0.3543, val loss: 4301.3348, val r2: 0.2705\n",
      "Epoch [  18/1000], trn los: 8369.7565, trn r2: 0.2996, val loss: 4257.4895, val r2: 0.2737\n",
      "Epoch [  19/1000], trn los: 7384.0655, trn r2: 0.3407, val loss: 3406.6507, val r2: 0.4166\n",
      "Epoch [  20/1000], trn los: 7006.3335, trn r2: 0.3403, val loss: 3708.7453, val r2: 0.3630\n",
      "Epoch [  21/1000], trn los: 6483.8918, trn r2: 0.3526, val loss: 3334.7712, val r2: 0.4286\n",
      "Epoch [  22/1000], trn los: 6270.8419, trn r2: 0.3598, val loss: 4390.4122, val r2: 0.2498\n",
      "Epoch [  23/1000], trn los: 6081.6088, trn r2: 0.3389, val loss: 4016.9763, val r2: 0.3159\n",
      "Epoch [  24/1000], trn los: 5725.8369, trn r2: 0.3498, val loss: 3357.6814, val r2: 0.4252\n",
      "Epoch [  25/1000], trn los: 5480.2111, trn r2: 0.3560, val loss: 3246.7309, val r2: 0.4499\n",
      "Epoch [  26/1000], trn los: 5061.1817, trn r2: 0.3769, val loss: 3199.3426, val r2: 0.4487\n",
      "Epoch [  27/1000], trn los: 5179.8803, trn r2: 0.3466, val loss: 3453.7560, val r2: 0.4097\n",
      "Epoch [  28/1000], trn los: 4837.1386, trn r2: 0.3617, val loss: 3224.0270, val r2: 0.4470\n",
      "Epoch [  29/1000], trn los: 4576.4124, trn r2: 0.3744, val loss: 3175.6636, val r2: 0.4533\n",
      "Epoch [  30/1000], trn los: 4386.0870, trn r2: 0.3872, val loss: 3182.4320, val r2: 0.4530\n",
      "Epoch [  31/1000], trn los: 4173.7720, trn r2: 0.3861, val loss: 3817.6938, val r2: 0.3453\n",
      "Epoch [  32/1000], trn los: 4116.7367, trn r2: 0.3940, val loss: 3740.1886, val r2: 0.3566\n",
      "Epoch [  33/1000], trn los: 4348.9567, trn r2: 0.3224, val loss: 3238.4985, val r2: 0.4427\n",
      "Epoch [  34/1000], trn los: 3864.1135, trn r2: 0.3757, val loss: 4286.9502, val r2: 0.2638\n",
      "Epoch [  35/1000], trn los: 3825.2731, trn r2: 0.3702, val loss: 3194.9189, val r2: 0.4537\n",
      "Epoch [  36/1000], trn los: 3732.2334, trn r2: 0.3892, val loss: 3314.1984, val r2: 0.4299\n",
      "Epoch [  37/1000], trn los: 3396.4331, trn r2: 0.4025, val loss: 3282.4985, val r2: 0.4449\n",
      "Epoch [  38/1000], trn los: 3592.8232, trn r2: 0.3676, val loss: 3182.7953, val r2: 0.4541\n",
      "Epoch [  39/1000], trn los: 3538.0954, trn r2: 0.3451, val loss: 3403.3109, val r2: 0.4121\n",
      "Epoch [  40/1000], trn los: 3122.5847, trn r2: 0.4201, val loss: 3548.8955, val r2: 0.3910\n",
      "Epoch [  41/1000], trn los: 3184.2887, trn r2: 0.4089, val loss: 3137.0809, val r2: 0.4622\n",
      "Epoch [  42/1000], trn los: 2901.5586, trn r2: 0.4331, val loss: 3376.1444, val r2: 0.4273\n",
      "Epoch [  43/1000], trn los: 3036.2681, trn r2: 0.3963, val loss: 3289.6619, val r2: 0.4356\n",
      "Epoch [  44/1000], trn los: 2908.5557, trn r2: 0.3918, val loss: 3838.8060, val r2: 0.3400\n",
      "Epoch [  45/1000], trn los: 2908.9707, trn r2: 0.3774, val loss: 3284.1235, val r2: 0.4365\n",
      "Epoch [  46/1000], trn los: 2916.6878, trn r2: 0.3954, val loss: 3309.3920, val r2: 0.4330\n",
      "Epoch [  47/1000], trn los: 2876.5323, trn r2: 0.3670, val loss: 3357.4982, val r2: 0.4241\n",
      "Epoch [  48/1000], trn los: 2630.6995, trn r2: 0.4106, val loss: 3552.9017, val r2: 0.3901\n",
      "Epoch [  49/1000], trn los: 2596.0962, trn r2: 0.4014, val loss: 3087.4613, val r2: 0.4673\n",
      "Epoch [  50/1000], trn los: 2551.4029, trn r2: 0.4061, val loss: 3376.5720, val r2: 0.4229\n",
      "Epoch [  51/1000], trn los: 2386.8636, trn r2: 0.4263, val loss: 3050.2817, val r2: 0.4767\n",
      "Epoch [  52/1000], trn los: 2400.0262, trn r2: 0.4190, val loss: 3097.4138, val r2: 0.4683\n",
      "Epoch [  53/1000], trn los: 2352.9698, trn r2: 0.4119, val loss: 3691.7710, val r2: 0.3702\n",
      "Epoch [  54/1000], trn los: 2402.8271, trn r2: 0.3850, val loss: 3654.7085, val r2: 0.3740\n",
      "Epoch [  55/1000], trn los: 2377.1472, trn r2: 0.4036, val loss: 3123.0368, val r2: 0.4631\n",
      "Epoch [  56/1000], trn los: 2182.9335, trn r2: 0.4196, val loss: 3070.7854, val r2: 0.4799\n",
      "Epoch [  57/1000], trn los: 2334.2668, trn r2: 0.3699, val loss: 4142.3732, val r2: 0.2962\n",
      "Epoch [  58/1000], trn los: 2237.4873, trn r2: 0.3885, val loss: 4897.8985, val r2: 0.1565\n",
      "Epoch [  59/1000], trn los: 2472.5534, trn r2: 0.3350, val loss: 3064.5221, val r2: 0.4741\n",
      "Epoch [  60/1000], trn los: 2280.9788, trn r2: 0.3667, val loss: 3144.6444, val r2: 0.4589\n",
      "Epoch [  61/1000], trn los: 2066.0823, trn r2: 0.4133, val loss: 3251.4778, val r2: 0.4385\n",
      "Epoch [  62/1000], trn los: 1986.0020, trn r2: 0.4254, val loss: 3225.5935, val r2: 0.4479\n",
      "Epoch [  63/1000], trn los: 1982.7782, trn r2: 0.4093, val loss: 3117.5190, val r2: 0.4637\n",
      "Epoch [  64/1000], trn los: 2109.0638, trn r2: 0.3796, val loss: 3205.3150, val r2: 0.4536\n",
      "Epoch [  65/1000], trn los: 2026.3048, trn r2: 0.3777, val loss: 3609.8147, val r2: 0.3890\n",
      "Epoch [  66/1000], trn los: 1921.8854, trn r2: 0.4133, val loss: 3038.3180, val r2: 0.4773\n",
      "Epoch [  67/1000], trn los: 1821.8324, trn r2: 0.4214, val loss: 3505.0291, val r2: 0.4007\n",
      "Epoch [  68/1000], trn los: 1785.0221, trn r2: 0.4258, val loss: 3435.5796, val r2: 0.4089\n",
      "Epoch [  69/1000], trn los: 1768.3632, trn r2: 0.4273, val loss: 3113.0594, val r2: 0.4644\n",
      "Epoch [  70/1000], trn los: 1794.7268, trn r2: 0.4229, val loss: 3497.4105, val r2: 0.4057\n",
      "Epoch [  71/1000], trn los: 1892.7042, trn r2: 0.3686, val loss: 3046.5165, val r2: 0.4792\n",
      "Epoch [  72/1000], trn los: 1632.1372, trn r2: 0.4483, val loss: 3562.2335, val r2: 0.3871\n",
      "Epoch [  73/1000], trn los: 1809.0868, trn r2: 0.3973, val loss: 2993.4740, val r2: 0.4855\n",
      "Epoch [  74/1000], trn los: 1581.0122, trn r2: 0.4511, val loss: 3786.8927, val r2: 0.3505\n",
      "Epoch [  75/1000], trn los: 1736.6150, trn r2: 0.4135, val loss: 3003.2301, val r2: 0.4830\n",
      "Epoch [  76/1000], trn los: 1710.9972, trn r2: 0.3898, val loss: 3004.3056, val r2: 0.4841\n",
      "Epoch [  77/1000], trn los: 1650.6007, trn r2: 0.4000, val loss: 3014.2094, val r2: 0.4821\n",
      "Epoch [  78/1000], trn los: 1516.4199, trn r2: 0.4405, val loss: 3319.3808, val r2: 0.4274\n",
      "Epoch [  79/1000], trn los: 1519.4507, trn r2: 0.4340, val loss: 3013.6527, val r2: 0.4821\n",
      "Epoch [  80/1000], trn los: 1744.8997, trn r2: 0.3396, val loss: 3158.4793, val r2: 0.4534\n",
      "Epoch [  81/1000], trn los: 1544.0967, trn r2: 0.4172, val loss: 3183.5553, val r2: 0.4541\n",
      "Epoch [  82/1000], trn los: 1485.9933, trn r2: 0.4295, val loss: 3449.9308, val r2: 0.4084\n",
      "Epoch [  83/1000], trn los: 1490.9894, trn r2: 0.4367, val loss: 2995.8023, val r2: 0.4828\n",
      "Epoch [  84/1000], trn los: 1405.8480, trn r2: 0.4494, val loss: 4569.9488, val r2: 0.2131\n",
      "Epoch [  85/1000], trn los: 1416.8703, trn r2: 0.4277, val loss: 3201.0489, val r2: 0.4464\n",
      "Epoch [  86/1000], trn los: 1309.7281, trn r2: 0.4676, val loss: 3107.2790, val r2: 0.4667\n",
      "Epoch [  87/1000], trn los: 1536.8787, trn r2: 0.3636, val loss: 3733.9076, val r2: 0.3634\n",
      "Epoch [  88/1000], trn los: 1395.7861, trn r2: 0.4280, val loss: 3280.8168, val r2: 0.4347\n",
      "Epoch [  89/1000], trn los: 1429.6936, trn r2: 0.4052, val loss: 3894.0990, val r2: 0.3300\n",
      "Epoch [  90/1000], trn los: 1418.2087, trn r2: 0.4010, val loss: 3032.4780, val r2: 0.4816\n",
      "Epoch [  91/1000], trn los: 1293.3895, trn r2: 0.4462, val loss: 3076.1230, val r2: 0.4714\n",
      "Epoch [  92/1000], trn los: 1371.5692, trn r2: 0.4069, val loss: 3088.3751, val r2: 0.4662\n",
      "Epoch [  93/1000], trn los: 1251.3010, trn r2: 0.4630, val loss: 3027.6972, val r2: 0.4840\n",
      "Epoch [  94/1000], trn los: 1248.3100, trn r2: 0.4455, val loss: 2968.4498, val r2: 0.4887\n",
      "Epoch [  95/1000], trn los: 1273.4662, trn r2: 0.4484, val loss: 3046.1437, val r2: 0.4781\n",
      "Epoch [  96/1000], trn los: 1274.1021, trn r2: 0.4328, val loss: 3018.6120, val r2: 0.4848\n",
      "Epoch [  97/1000], trn los: 1269.5364, trn r2: 0.4260, val loss: 3095.1131, val r2: 0.4696\n",
      "Epoch [  98/1000], trn los: 1189.9857, trn r2: 0.4504, val loss: 2980.8628, val r2: 0.4887\n",
      "Epoch [  99/1000], trn los: 1190.8777, trn r2: 0.4536, val loss: 3659.7424, val r2: 0.3721\n",
      "Epoch [ 100/1000], trn los: 1241.2599, trn r2: 0.4323, val loss: 3251.3255, val r2: 0.4437\n",
      "Epoch [ 101/1000], trn los: 1281.4046, trn r2: 0.4037, val loss: 3353.4368, val r2: 0.4220\n",
      "Epoch [ 102/1000], trn los: 1182.2300, trn r2: 0.4265, val loss: 3076.1209, val r2: 0.4727\n",
      "Epoch [ 103/1000], trn los: 1189.9929, trn r2: 0.4196, val loss: 2989.3999, val r2: 0.4888\n",
      "Epoch [ 104/1000], trn los: 1176.1001, trn r2: 0.4300, val loss: 3132.4034, val r2: 0.4617\n",
      "Epoch [ 105/1000], trn los: 1131.2294, trn r2: 0.4611, val loss: 2986.8781, val r2: 0.4857\n",
      "Epoch [ 106/1000], trn los: 1135.5694, trn r2: 0.4430, val loss: 3077.9334, val r2: 0.4745\n",
      "Epoch [ 107/1000], trn los: 1093.8486, trn r2: 0.4451, val loss: 3416.7209, val r2: 0.4126\n",
      "Epoch [ 108/1000], trn los: 1116.6838, trn r2: 0.4273, val loss: 3003.7157, val r2: 0.4852\n",
      "Epoch [ 109/1000], trn los: 1129.9234, trn r2: 0.4157, val loss: 3918.9713, val r2: 0.3279\n",
      "Epoch [ 110/1000], trn los: 1108.6282, trn r2: 0.4206, val loss: 3026.1155, val r2: 0.4829\n",
      "Epoch [ 111/1000], trn los: 1024.6394, trn r2: 0.4606, val loss: 3661.1393, val r2: 0.3699\n",
      "Epoch [ 112/1000], trn los: 1130.3500, trn r2: 0.4340, val loss: 3434.2420, val r2: 0.4116\n",
      "Epoch [ 113/1000], trn los: 1161.7821, trn r2: 0.3925, val loss: 3965.5539, val r2: 0.3291\n",
      "Epoch [ 114/1000], trn los: 1080.2328, trn r2: 0.4228, val loss: 2998.8601, val r2: 0.4910\n",
      "Epoch [ 115/1000], trn los: 1062.9307, trn r2: 0.4425, val loss: 3020.6931, val r2: 0.4805\n",
      "Epoch [ 116/1000], trn los: 1059.8014, trn r2: 0.4351, val loss: 2984.5827, val r2: 0.4941\n",
      "Epoch [ 117/1000], trn los: 1080.7901, trn r2: 0.4166, val loss: 3408.2753, val r2: 0.4172\n",
      "Epoch [ 118/1000], trn los: 1013.6887, trn r2: 0.4344, val loss: 3494.7165, val r2: 0.4028\n",
      "Epoch [ 119/1000], trn los: 1025.5543, trn r2: 0.4213, val loss: 2966.9800, val r2: 0.4942\n",
      "Epoch [ 120/1000], trn los: 978.3535, trn r2: 0.4467, val loss: 3166.9813, val r2: 0.4587\n",
      "Epoch [ 121/1000], trn los: 961.3407, trn r2: 0.4610, val loss: 2937.0459, val r2: 0.4949\n",
      "Epoch [ 122/1000], trn los: 955.8169, trn r2: 0.4469, val loss: 3353.4796, val r2: 0.4244\n",
      "Epoch [ 123/1000], trn los: 936.5560, trn r2: 0.4535, val loss: 3093.4782, val r2: 0.4695\n",
      "Epoch [ 124/1000], trn los: 940.0155, trn r2: 0.4499, val loss: 3023.2088, val r2: 0.4822\n",
      "Epoch [ 125/1000], trn los: 921.9502, trn r2: 0.4653, val loss: 3140.3051, val r2: 0.4605\n",
      "Epoch [ 126/1000], trn los: 899.9989, trn r2: 0.4638, val loss: 2935.2898, val r2: 0.4951\n",
      "Epoch [ 127/1000], trn los: 952.4389, trn r2: 0.4602, val loss: 2981.3558, val r2: 0.4925\n",
      "Epoch [ 128/1000], trn los: 990.2254, trn r2: 0.4123, val loss: 3224.7968, val r2: 0.4471\n",
      "Epoch [ 129/1000], trn los: 919.1730, trn r2: 0.4476, val loss: 3302.0182, val r2: 0.4366\n",
      "Epoch [ 130/1000], trn los: 935.5450, trn r2: 0.4367, val loss: 3312.6689, val r2: 0.4361\n",
      "Epoch [ 131/1000], trn los: 953.9031, trn r2: 0.4352, val loss: 3055.5305, val r2: 0.4762\n",
      "Epoch [ 132/1000], trn los: 906.9828, trn r2: 0.4456, val loss: 3452.8245, val r2: 0.4105\n",
      "Epoch [ 133/1000], trn los: 870.4157, trn r2: 0.4496, val loss: 3062.4645, val r2: 0.4744\n",
      "Epoch [ 134/1000], trn los: 920.7898, trn r2: 0.4266, val loss: 2906.5809, val r2: 0.4980\n",
      "Epoch [ 135/1000], trn los: 876.3385, trn r2: 0.4428, val loss: 2929.2794, val r2: 0.4990\n",
      "Epoch [ 136/1000], trn los: 920.7600, trn r2: 0.4109, val loss: 2958.9832, val r2: 0.4921\n",
      "Epoch [ 137/1000], trn los: 821.5225, trn r2: 0.4654, val loss: 3265.2497, val r2: 0.4412\n",
      "Epoch [ 138/1000], trn los: 877.7598, trn r2: 0.4290, val loss: 3026.8506, val r2: 0.4829\n",
      "Epoch [ 139/1000], trn los: 880.7504, trn r2: 0.4336, val loss: 3542.3793, val r2: 0.3879\n",
      "Epoch [ 140/1000], trn los: 855.0779, trn r2: 0.4423, val loss: 3149.7459, val r2: 0.4658\n",
      "Epoch [ 141/1000], trn los: 850.9007, trn r2: 0.4308, val loss: 3381.2905, val r2: 0.4208\n",
      "Epoch [ 142/1000], trn los: 794.0528, trn r2: 0.4764, val loss: 2974.8944, val r2: 0.4873\n",
      "Epoch [ 143/1000], trn los: 774.2394, trn r2: 0.4770, val loss: 3045.8720, val r2: 0.4766\n",
      "Epoch [ 144/1000], trn los: 792.1196, trn r2: 0.4675, val loss: 3163.2978, val r2: 0.4541\n",
      "Epoch [ 145/1000], trn los: 841.7459, trn r2: 0.4381, val loss: 2985.8909, val r2: 0.4907\n",
      "Epoch [ 146/1000], trn los: 803.1585, trn r2: 0.4515, val loss: 3013.9710, val r2: 0.4825\n",
      "Epoch [ 147/1000], trn los: 826.1462, trn r2: 0.4550, val loss: 2971.3395, val r2: 0.4873\n",
      "Epoch [ 148/1000], trn los: 811.1572, trn r2: 0.4415, val loss: 3410.2027, val r2: 0.4188\n",
      "Epoch [ 149/1000], trn los: 817.6325, trn r2: 0.4267, val loss: 3333.3758, val r2: 0.4300\n",
      "Epoch [ 150/1000], trn los: 839.0376, trn r2: 0.4235, val loss: 3192.4250, val r2: 0.4587\n",
      "Epoch [ 151/1000], trn los: 787.7851, trn r2: 0.4424, val loss: 2939.7372, val r2: 0.4949\n",
      "Epoch [ 152/1000], trn los: 758.5708, trn r2: 0.4547, val loss: 3209.2031, val r2: 0.4570\n",
      "Epoch [ 153/1000], trn los: 783.2007, trn r2: 0.4496, val loss: 3014.9973, val r2: 0.4868\n",
      "Epoch [ 154/1000], trn los: 776.4939, trn r2: 0.4438, val loss: 3417.6870, val r2: 0.4188\n",
      "Epoch [ 155/1000], trn los: 804.3790, trn r2: 0.4330, val loss: 2938.7497, val r2: 0.4973\n",
      "Epoch [ 156/1000], trn los: 810.4224, trn r2: 0.4060, val loss: 3200.9296, val r2: 0.4498\n",
      "Epoch [ 157/1000], trn los: 723.1945, trn r2: 0.4704, val loss: 2958.7663, val r2: 0.4961\n",
      "Epoch [ 158/1000], trn los: 744.4502, trn r2: 0.4468, val loss: 3224.9272, val r2: 0.4493\n",
      "Epoch [ 159/1000], trn los: 719.7351, trn r2: 0.4605, val loss: 2975.3387, val r2: 0.4897\n",
      "Epoch [ 160/1000], trn los: 747.8715, trn r2: 0.4621, val loss: 2987.8525, val r2: 0.4876\n",
      "Epoch [ 161/1000], trn los: 730.5849, trn r2: 0.4557, val loss: 2919.6782, val r2: 0.4977\n",
      "Epoch [ 162/1000], trn los: 789.6777, trn r2: 0.4103, val loss: 3178.7499, val r2: 0.4547\n",
      "Epoch [ 163/1000], trn los: 753.7692, trn r2: 0.4326, val loss: 2943.1876, val r2: 0.4956\n",
      "Epoch [ 164/1000], trn los: 709.5091, trn r2: 0.4579, val loss: 2983.2185, val r2: 0.4871\n",
      "Epoch [ 165/1000], trn los: 740.8929, trn r2: 0.4213, val loss: 3042.2466, val r2: 0.4772\n",
      "Epoch [ 166/1000], trn los: 699.0456, trn r2: 0.4545, val loss: 2963.9111, val r2: 0.4904\n",
      "Epoch [ 167/1000], trn los: 668.3234, trn r2: 0.4738, val loss: 3616.9463, val r2: 0.3773\n",
      "Epoch [ 168/1000], trn los: 682.3885, trn r2: 0.4592, val loss: 2951.4187, val r2: 0.4977\n",
      "Epoch [ 169/1000], trn los: 673.1212, trn r2: 0.4652, val loss: 2882.4135, val r2: 0.5024\n",
      "Epoch [ 170/1000], trn los: 667.2183, trn r2: 0.4697, val loss: 3122.8771, val r2: 0.4676\n",
      "Epoch [ 171/1000], trn los: 645.2891, trn r2: 0.4991, val loss: 3160.1174, val r2: 0.4579\n",
      "Epoch [ 172/1000], trn los: 662.3963, trn r2: 0.4686, val loss: 2932.8581, val r2: 0.5006\n",
      "Epoch [ 173/1000], trn los: 736.5455, trn r2: 0.4149, val loss: 2898.0535, val r2: 0.5012\n",
      "Epoch [ 174/1000], trn los: 661.2985, trn r2: 0.4649, val loss: 2875.9691, val r2: 0.5035\n",
      "Epoch [ 175/1000], trn los: 686.3202, trn r2: 0.4378, val loss: 2996.4923, val r2: 0.4896\n",
      "Epoch [ 176/1000], trn los: 649.6958, trn r2: 0.4590, val loss: 3331.5721, val r2: 0.4296\n",
      "Epoch [ 177/1000], trn los: 690.4706, trn r2: 0.4426, val loss: 2888.8004, val r2: 0.5026\n",
      "Epoch [ 178/1000], trn los: 637.2741, trn r2: 0.4808, val loss: 3678.9880, val r2: 0.3707\n",
      "Epoch [ 179/1000], trn los: 660.0410, trn r2: 0.4556, val loss: 2959.3829, val r2: 0.4969\n",
      "Epoch [ 180/1000], trn los: 665.7581, trn r2: 0.4501, val loss: 3226.3770, val r2: 0.4479\n",
      "Epoch [ 181/1000], trn los: 633.5375, trn r2: 0.4711, val loss: 3627.9529, val r2: 0.3766\n",
      "Epoch [ 182/1000], trn los: 642.3916, trn r2: 0.4564, val loss: 3151.8212, val r2: 0.4632\n",
      "Epoch [ 183/1000], trn los: 649.7548, trn r2: 0.4387, val loss: 3031.6996, val r2: 0.4820\n",
      "Epoch [ 184/1000], trn los: 661.9918, trn r2: 0.4311, val loss: 3497.6752, val r2: 0.4028\n",
      "Epoch [ 185/1000], trn los: 627.1500, trn r2: 0.4569, val loss: 2962.3036, val r2: 0.5016\n",
      "Epoch [ 186/1000], trn los: 643.8162, trn r2: 0.4308, val loss: 2984.2473, val r2: 0.4869\n",
      "Epoch [ 187/1000], trn los: 592.7658, trn r2: 0.4834, val loss: 3224.8892, val r2: 0.4468\n",
      "Epoch [ 188/1000], trn los: 605.9976, trn r2: 0.4581, val loss: 2869.6781, val r2: 0.5066\n",
      "Epoch [ 189/1000], trn los: 597.3528, trn r2: 0.4638, val loss: 3212.8607, val r2: 0.4476\n",
      "Epoch [ 190/1000], trn los: 625.1050, trn r2: 0.4400, val loss: 2939.8081, val r2: 0.4955\n",
      "Epoch [ 191/1000], trn los: 626.0833, trn r2: 0.4594, val loss: 3367.8528, val r2: 0.4216\n",
      "Epoch [ 192/1000], trn los: 597.0696, trn r2: 0.4694, val loss: 3041.4571, val r2: 0.4795\n",
      "Epoch [ 193/1000], trn los: 595.3344, trn r2: 0.4538, val loss: 2891.4574, val r2: 0.5016\n",
      "Epoch [ 194/1000], trn los: 576.8090, trn r2: 0.4714, val loss: 3060.0023, val r2: 0.4719\n",
      "Epoch [ 195/1000], trn los: 666.6540, trn r2: 0.3906, val loss: 3435.6850, val r2: 0.4070\n",
      "Epoch [ 196/1000], trn los: 571.8521, trn r2: 0.4765, val loss: 3138.6047, val r2: 0.4640\n",
      "Epoch [ 197/1000], trn los: 579.3049, trn r2: 0.4689, val loss: 2927.4619, val r2: 0.4956\n",
      "Epoch [ 198/1000], trn los: 553.1843, trn r2: 0.4836, val loss: 3317.2397, val r2: 0.4322\n",
      "Epoch [ 199/1000], trn los: 549.6687, trn r2: 0.4905, val loss: 3415.1206, val r2: 0.4136\n",
      "Epoch [ 200/1000], trn los: 560.5800, trn r2: 0.4790, val loss: 3365.6322, val r2: 0.4244\n",
      "Epoch [ 201/1000], trn los: 535.3935, trn r2: 0.4910, val loss: 3235.1596, val r2: 0.4436\n",
      "Epoch [ 202/1000], trn los: 552.2656, trn r2: 0.4727, val loss: 2891.1980, val r2: 0.5024\n",
      "Epoch [ 203/1000], trn los: 525.8344, trn r2: 0.4942, val loss: 3228.7660, val r2: 0.4489\n",
      "Epoch [ 204/1000], trn los: 601.9193, trn r2: 0.4276, val loss: 2899.1229, val r2: 0.5004\n",
      "Epoch [ 205/1000], trn los: 606.2815, trn r2: 0.4193, val loss: 2852.2029, val r2: 0.5075\n",
      "Epoch [ 206/1000], trn los: 542.8667, trn r2: 0.4834, val loss: 3060.4670, val r2: 0.4773\n",
      "Epoch [ 207/1000], trn los: 565.3041, trn r2: 0.4503, val loss: 2961.5231, val r2: 0.4936\n",
      "Epoch [ 208/1000], trn los: 543.9695, trn r2: 0.4700, val loss: 2882.6364, val r2: 0.5073\n",
      "Epoch [ 209/1000], trn los: 554.0684, trn r2: 0.4580, val loss: 3498.1582, val r2: 0.4038\n",
      "Epoch [ 210/1000], trn los: 585.5414, trn r2: 0.4379, val loss: 3065.1118, val r2: 0.4760\n",
      "Epoch [ 211/1000], trn los: 569.2105, trn r2: 0.4462, val loss: 2853.2827, val r2: 0.5111\n",
      "Epoch [ 212/1000], trn los: 524.6489, trn r2: 0.4759, val loss: 2934.5438, val r2: 0.4981\n",
      "Epoch [ 213/1000], trn los: 550.6178, trn r2: 0.4626, val loss: 2880.3046, val r2: 0.5042\n",
      "Epoch [ 214/1000], trn los: 504.5603, trn r2: 0.4920, val loss: 3169.5009, val r2: 0.4562\n",
      "Epoch [ 215/1000], trn los: 490.3470, trn r2: 0.5040, val loss: 3312.1413, val r2: 0.4283\n",
      "Epoch [ 216/1000], trn los: 513.4118, trn r2: 0.4773, val loss: 2956.0827, val r2: 0.4941\n",
      "Epoch [ 217/1000], trn los: 540.7376, trn r2: 0.4471, val loss: 3177.8730, val r2: 0.4613\n",
      "Epoch [ 218/1000], trn los: 504.0217, trn r2: 0.4785, val loss: 2892.4889, val r2: 0.5021\n",
      "Epoch [ 219/1000], trn los: 521.7006, trn r2: 0.4595, val loss: 2917.1325, val r2: 0.4981\n",
      "Epoch [ 220/1000], trn los: 521.0350, trn r2: 0.4628, val loss: 3048.1621, val r2: 0.4775\n",
      "Epoch [ 221/1000], trn los: 535.0514, trn r2: 0.4437, val loss: 3294.3427, val r2: 0.4345\n",
      "Epoch [ 222/1000], trn los: 475.3784, trn r2: 0.5028, val loss: 2865.1153, val r2: 0.5075\n",
      "Epoch [ 223/1000], trn los: 490.7660, trn r2: 0.4841, val loss: 3152.7880, val r2: 0.4607\n",
      "Epoch [ 224/1000], trn los: 499.5507, trn r2: 0.4747, val loss: 2892.8937, val r2: 0.5098\n",
      "Epoch [ 225/1000], trn los: 514.7034, trn r2: 0.4644, val loss: 2885.8707, val r2: 0.5075\n",
      "Epoch [ 226/1000], trn los: 501.2521, trn r2: 0.4689, val loss: 3348.8060, val r2: 0.4277\n",
      "Epoch [ 227/1000], trn los: 483.1268, trn r2: 0.4854, val loss: 3090.6991, val r2: 0.4679\n",
      "Epoch [ 228/1000], trn los: 535.2930, trn r2: 0.4229, val loss: 2922.7592, val r2: 0.4987\n",
      "Epoch [ 229/1000], trn los: 491.7793, trn r2: 0.4732, val loss: 2907.6729, val r2: 0.4995\n",
      "Epoch [ 230/1000], trn los: 487.8473, trn r2: 0.4771, val loss: 3022.5815, val r2: 0.4810\n",
      "Epoch [ 231/1000], trn los: 482.8136, trn r2: 0.4743, val loss: 3147.9555, val r2: 0.4590\n",
      "Epoch [ 232/1000], trn los: 491.1384, trn r2: 0.4611, val loss: 2882.4874, val r2: 0.5083\n",
      "Epoch [ 233/1000], trn los: 498.4266, trn r2: 0.4708, val loss: 3007.6637, val r2: 0.4849\n",
      "Epoch [ 234/1000], trn los: 498.6546, trn r2: 0.4698, val loss: 3060.3562, val r2: 0.4775\n",
      "Epoch [ 235/1000], trn los: 510.9489, trn r2: 0.4337, val loss: 2822.2876, val r2: 0.5144\n",
      "Epoch [ 236/1000], trn los: 514.2132, trn r2: 0.4272, val loss: 2935.6499, val r2: 0.4951\n",
      "Epoch [ 237/1000], trn los: 475.6595, trn r2: 0.4671, val loss: 2886.8970, val r2: 0.5019\n",
      "Epoch [ 238/1000], trn los: 491.8292, trn r2: 0.4583, val loss: 3024.0695, val r2: 0.4793\n",
      "Epoch [ 239/1000], trn los: 511.0312, trn r2: 0.4239, val loss: 2862.1818, val r2: 0.5136\n",
      "Epoch [ 240/1000], trn los: 483.8747, trn r2: 0.4671, val loss: 2927.0846, val r2: 0.4962\n",
      "Epoch [ 241/1000], trn los: 428.0533, trn r2: 0.5144, val loss: 2813.7082, val r2: 0.5181\n",
      "Epoch [ 242/1000], trn los: 482.9778, trn r2: 0.4726, val loss: 2989.1509, val r2: 0.4864\n",
      "Epoch [ 243/1000], trn los: 516.9826, trn r2: 0.4075, val loss: 2902.1932, val r2: 0.5013\n",
      "Epoch [ 244/1000], trn los: 457.1868, trn r2: 0.4783, val loss: 3083.5753, val r2: 0.4746\n",
      "Epoch [ 245/1000], trn los: 474.9842, trn r2: 0.4469, val loss: 2905.1437, val r2: 0.4996\n",
      "Epoch [ 246/1000], trn los: 476.4587, trn r2: 0.4535, val loss: 2983.1992, val r2: 0.4859\n",
      "Epoch [ 247/1000], trn los: 465.5930, trn r2: 0.4550, val loss: 2990.2828, val r2: 0.4860\n",
      "Epoch [ 248/1000], trn los: 445.0173, trn r2: 0.4900, val loss: 2828.5919, val r2: 0.5181\n",
      "Epoch [ 249/1000], trn los: 427.3461, trn r2: 0.5087, val loss: 2834.2953, val r2: 0.5145\n",
      "Epoch [ 250/1000], trn los: 432.7924, trn r2: 0.4923, val loss: 2817.3541, val r2: 0.5148\n",
      "Epoch [ 251/1000], trn los: 465.0675, trn r2: 0.4456, val loss: 2840.4469, val r2: 0.5118\n",
      "Epoch [ 252/1000], trn los: 450.3710, trn r2: 0.4688, val loss: 2898.8779, val r2: 0.5072\n",
      "Epoch [ 253/1000], trn los: 491.2116, trn r2: 0.4257, val loss: 2907.8349, val r2: 0.5001\n",
      "Epoch [ 254/1000], trn los: 428.9038, trn r2: 0.4995, val loss: 2961.6884, val r2: 0.4908\n",
      "Epoch [ 255/1000], trn los: 437.5683, trn r2: 0.4857, val loss: 3072.0330, val r2: 0.4765\n",
      "Epoch [ 256/1000], trn los: 452.4338, trn r2: 0.4506, val loss: 2944.5935, val r2: 0.4986\n",
      "Epoch [ 257/1000], trn los: 465.3344, trn r2: 0.4459, val loss: 3013.2961, val r2: 0.4832\n",
      "Epoch [ 258/1000], trn los: 439.0948, trn r2: 0.4664, val loss: 2960.2996, val r2: 0.4950\n",
      "Epoch [ 259/1000], trn los: 414.9100, trn r2: 0.4929, val loss: 3260.6973, val r2: 0.4391\n",
      "Epoch [ 260/1000], trn los: 423.4636, trn r2: 0.4841, val loss: 2882.1536, val r2: 0.5050\n",
      "Epoch [ 261/1000], trn los: 393.9917, trn r2: 0.5111, val loss: 2889.9460, val r2: 0.5062\n",
      "Epoch [ 262/1000], trn los: 439.0019, trn r2: 0.4661, val loss: 2806.3171, val r2: 0.5222\n",
      "Epoch [ 263/1000], trn los: 417.4578, trn r2: 0.4792, val loss: 2897.4889, val r2: 0.5029\n",
      "Epoch [ 264/1000], trn los: 420.5168, trn r2: 0.4804, val loss: 2826.2072, val r2: 0.5198\n",
      "Epoch [ 265/1000], trn los: 432.8095, trn r2: 0.4673, val loss: 2831.2886, val r2: 0.5110\n",
      "Epoch [ 266/1000], trn los: 395.7596, trn r2: 0.5007, val loss: 2796.3634, val r2: 0.5195\n",
      "Epoch [ 267/1000], trn los: 414.5664, trn r2: 0.4971, val loss: 2841.0872, val r2: 0.5120\n",
      "Epoch [ 268/1000], trn los: 403.2644, trn r2: 0.4875, val loss: 2845.6237, val r2: 0.5096\n",
      "Epoch [ 269/1000], trn los: 421.4737, trn r2: 0.4675, val loss: 3125.1803, val r2: 0.4606\n",
      "Epoch [ 270/1000], trn los: 407.6409, trn r2: 0.4839, val loss: 2844.6375, val r2: 0.5098\n",
      "Epoch [ 271/1000], trn los: 419.8716, trn r2: 0.4711, val loss: 2984.6219, val r2: 0.4879\n",
      "Epoch [ 272/1000], trn los: 389.5906, trn r2: 0.5020, val loss: 3014.5153, val r2: 0.4850\n",
      "Epoch [ 273/1000], trn los: 383.9271, trn r2: 0.5014, val loss: 2902.8177, val r2: 0.5043\n",
      "Epoch [ 274/1000], trn los: 391.2972, trn r2: 0.4946, val loss: 2801.1401, val r2: 0.5184\n",
      "Epoch [ 275/1000], trn los: 416.1599, trn r2: 0.4617, val loss: 2823.8492, val r2: 0.5168\n",
      "Epoch [ 276/1000], trn los: 396.7350, trn r2: 0.4874, val loss: 2915.1616, val r2: 0.4978\n",
      "Epoch [ 277/1000], trn los: 403.0175, trn r2: 0.4813, val loss: 3053.4569, val r2: 0.4786\n",
      "Epoch [ 278/1000], trn los: 395.5206, trn r2: 0.4945, val loss: 2869.3792, val r2: 0.5136\n",
      "Epoch [ 279/1000], trn los: 411.3283, trn r2: 0.4704, val loss: 3122.1638, val r2: 0.4635\n",
      "Epoch [ 280/1000], trn los: 405.6415, trn r2: 0.4594, val loss: 3099.3123, val r2: 0.4677\n",
      "Epoch [ 281/1000], trn los: 417.3416, trn r2: 0.4741, val loss: 3070.7792, val r2: 0.4748\n",
      "Epoch [ 282/1000], trn los: 391.0072, trn r2: 0.4798, val loss: 3186.6433, val r2: 0.4549\n",
      "Epoch [ 283/1000], trn los: 382.5379, trn r2: 0.4959, val loss: 2980.5466, val r2: 0.4910\n",
      "Epoch [ 284/1000], trn los: 361.0035, trn r2: 0.5161, val loss: 2758.4513, val r2: 0.5255\n",
      "Epoch [ 285/1000], trn los: 393.4828, trn r2: 0.4732, val loss: 3155.8123, val r2: 0.4551\n",
      "Epoch [ 286/1000], trn los: 362.6725, trn r2: 0.5075, val loss: 2810.1354, val r2: 0.5188\n",
      "Epoch [ 287/1000], trn los: 380.9830, trn r2: 0.4879, val loss: 2760.6807, val r2: 0.5234\n",
      "Epoch [ 288/1000], trn los: 394.0017, trn r2: 0.4781, val loss: 2791.1145, val r2: 0.5196\n",
      "Epoch [ 289/1000], trn los: 372.9908, trn r2: 0.4889, val loss: 3020.7406, val r2: 0.4827\n",
      "Epoch [ 290/1000], trn los: 362.0027, trn r2: 0.5009, val loss: 2895.4193, val r2: 0.5058\n",
      "Epoch [ 291/1000], trn los: 376.5860, trn r2: 0.4789, val loss: 2861.4257, val r2: 0.5147\n",
      "Epoch [ 292/1000], trn los: 383.2159, trn r2: 0.4762, val loss: 3059.1348, val r2: 0.4820\n",
      "Epoch [ 293/1000], trn los: 390.8041, trn r2: 0.4603, val loss: 3148.4161, val r2: 0.4664\n",
      "Epoch [ 294/1000], trn los: 374.2578, trn r2: 0.4949, val loss: 2790.6466, val r2: 0.5202\n",
      "Epoch [ 295/1000], trn los: 384.5399, trn r2: 0.4652, val loss: 2887.6854, val r2: 0.5026\n",
      "Epoch [ 296/1000], trn los: 355.5499, trn r2: 0.5057, val loss: 2785.2854, val r2: 0.5205\n",
      "Epoch [ 297/1000], trn los: 359.6370, trn r2: 0.4999, val loss: 2813.7627, val r2: 0.5207\n",
      "Epoch [ 298/1000], trn los: 358.5297, trn r2: 0.5005, val loss: 2823.7824, val r2: 0.5134\n",
      "Epoch [ 299/1000], trn los: 371.3781, trn r2: 0.4813, val loss: 2853.8282, val r2: 0.5094\n",
      "Epoch [ 300/1000], trn los: 364.5200, trn r2: 0.5054, val loss: 2791.6939, val r2: 0.5202\n",
      "Epoch [ 301/1000], trn los: 367.8523, trn r2: 0.4928, val loss: 2850.4364, val r2: 0.5103\n",
      "Epoch [ 302/1000], trn los: 355.6942, trn r2: 0.4979, val loss: 2847.5339, val r2: 0.5126\n",
      "Epoch [ 303/1000], trn los: 350.0583, trn r2: 0.5075, val loss: 3228.3826, val r2: 0.4433\n",
      "Epoch [ 304/1000], trn los: 348.9504, trn r2: 0.5206, val loss: 3053.2796, val r2: 0.4749\n",
      "Epoch [ 305/1000], trn los: 356.6521, trn r2: 0.4971, val loss: 3398.8045, val r2: 0.4147\n",
      "Epoch [ 306/1000], trn los: 347.8023, trn r2: 0.5038, val loss: 2808.2604, val r2: 0.5174\n",
      "Epoch [ 307/1000], trn los: 357.9485, trn r2: 0.4785, val loss: 2818.4988, val r2: 0.5180\n",
      "Epoch [ 308/1000], trn los: 359.5718, trn r2: 0.4758, val loss: 2848.3839, val r2: 0.5200\n",
      "Epoch [ 309/1000], trn los: 352.4851, trn r2: 0.4852, val loss: 2832.3138, val r2: 0.5157\n",
      "Epoch [ 310/1000], trn los: 345.0694, trn r2: 0.4939, val loss: 2968.3345, val r2: 0.4953\n",
      "Epoch [ 311/1000], trn los: 372.9221, trn r2: 0.4547, val loss: 2811.7189, val r2: 0.5175\n",
      "Epoch [ 312/1000], trn los: 342.2806, trn r2: 0.5014, val loss: 3209.3883, val r2: 0.4459\n",
      "Epoch [ 313/1000], trn los: 339.4941, trn r2: 0.5012, val loss: 2818.8275, val r2: 0.5190\n",
      "Epoch [ 314/1000], trn los: 343.5586, trn r2: 0.4872, val loss: 2829.0980, val r2: 0.5154\n",
      "Epoch [ 315/1000], trn los: 357.4439, trn r2: 0.4738, val loss: 2893.6371, val r2: 0.5072\n",
      "Epoch [ 316/1000], trn los: 348.3205, trn r2: 0.4982, val loss: 2899.6316, val r2: 0.5065\n",
      "Epoch [ 317/1000], trn los: 344.7109, trn r2: 0.4957, val loss: 2837.8339, val r2: 0.5162\n",
      "Epoch [ 318/1000], trn los: 315.8382, trn r2: 0.5267, val loss: 2909.0480, val r2: 0.5059\n",
      "Epoch [ 319/1000], trn los: 328.9180, trn r2: 0.5016, val loss: 2784.3500, val r2: 0.5209\n",
      "Epoch [ 320/1000], trn los: 363.2103, trn r2: 0.4604, val loss: 2814.5527, val r2: 0.5180\n",
      "Epoch [ 321/1000], trn los: 341.0383, trn r2: 0.4916, val loss: 3418.9086, val r2: 0.4135\n",
      "Epoch [ 322/1000], trn los: 362.0754, trn r2: 0.4647, val loss: 2776.1698, val r2: 0.5214\n",
      "Epoch [ 323/1000], trn los: 343.8218, trn r2: 0.4779, val loss: 2873.6619, val r2: 0.5072\n",
      "Epoch [ 324/1000], trn los: 333.9970, trn r2: 0.4871, val loss: 2860.9766, val r2: 0.5094\n",
      "Epoch [ 325/1000], trn los: 337.5953, trn r2: 0.4872, val loss: 2741.7878, val r2: 0.5310\n",
      "Epoch [ 326/1000], trn los: 312.3048, trn r2: 0.5303, val loss: 3046.7967, val r2: 0.4818\n",
      "Epoch [ 327/1000], trn los: 338.9257, trn r2: 0.4936, val loss: 2787.5045, val r2: 0.5274\n",
      "Epoch [ 328/1000], trn los: 327.1625, trn r2: 0.4964, val loss: 2790.2509, val r2: 0.5212\n",
      "Epoch [ 329/1000], trn los: 326.2924, trn r2: 0.5096, val loss: 3033.1720, val r2: 0.4795\n",
      "Epoch [ 330/1000], trn los: 344.4931, trn r2: 0.4869, val loss: 3119.7436, val r2: 0.4637\n",
      "Epoch [ 331/1000], trn los: 312.9930, trn r2: 0.5097, val loss: 2856.6156, val r2: 0.5116\n",
      "Epoch [ 332/1000], trn los: 348.1221, trn r2: 0.4586, val loss: 2797.2113, val r2: 0.5165\n",
      "Epoch [ 333/1000], trn los: 325.0715, trn r2: 0.4879, val loss: 3051.0904, val r2: 0.4748\n",
      "Epoch [ 334/1000], trn los: 330.9629, trn r2: 0.4865, val loss: 2849.8453, val r2: 0.5082\n",
      "Epoch [ 335/1000], trn los: 303.8595, trn r2: 0.5216, val loss: 2737.4838, val r2: 0.5290\n",
      "Epoch [ 336/1000], trn los: 325.3866, trn r2: 0.4940, val loss: 2794.8418, val r2: 0.5212\n",
      "Epoch [ 337/1000], trn los: 336.7967, trn r2: 0.4775, val loss: 2733.1405, val r2: 0.5304\n",
      "Epoch [ 338/1000], trn los: 329.7767, trn r2: 0.4824, val loss: 3262.1310, val r2: 0.4373\n",
      "Epoch [ 339/1000], trn los: 327.5129, trn r2: 0.4746, val loss: 2799.8908, val r2: 0.5188\n",
      "Epoch [ 340/1000], trn los: 326.8723, trn r2: 0.4729, val loss: 3049.1060, val r2: 0.4833\n",
      "Epoch [ 341/1000], trn los: 317.6412, trn r2: 0.4875, val loss: 2879.3077, val r2: 0.5062\n",
      "Epoch [ 342/1000], trn los: 303.5808, trn r2: 0.5110, val loss: 2751.3754, val r2: 0.5275\n",
      "Epoch [ 343/1000], trn los: 322.6579, trn r2: 0.4839, val loss: 2764.6497, val r2: 0.5237\n",
      "Epoch [ 344/1000], trn los: 305.0921, trn r2: 0.5052, val loss: 2827.7514, val r2: 0.5145\n",
      "Epoch [ 345/1000], trn los: 320.1285, trn r2: 0.4776, val loss: 2951.7269, val r2: 0.4942\n",
      "Epoch [ 346/1000], trn los: 325.8987, trn r2: 0.4958, val loss: 3156.3704, val r2: 0.4640\n",
      "Epoch [ 347/1000], trn los: 329.0995, trn r2: 0.4805, val loss: 2970.8750, val r2: 0.4916\n",
      "Epoch [ 348/1000], trn los: 302.0462, trn r2: 0.5114, val loss: 2736.7902, val r2: 0.5304\n",
      "Epoch [ 349/1000], trn los: 327.2428, trn r2: 0.4656, val loss: 3291.9604, val r2: 0.4332\n",
      "Epoch [ 350/1000], trn los: 315.1073, trn r2: 0.4787, val loss: 3224.2458, val r2: 0.4497\n",
      "Epoch [ 351/1000], trn los: 327.6024, trn r2: 0.4591, val loss: 3017.7948, val r2: 0.4823\n",
      "Epoch [ 352/1000], trn los: 290.7129, trn r2: 0.5241, val loss: 2797.4921, val r2: 0.5248\n",
      "Epoch [ 353/1000], trn los: 309.2186, trn r2: 0.4900, val loss: 3075.1709, val r2: 0.4722\n",
      "Epoch [ 354/1000], trn los: 285.1080, trn r2: 0.5288, val loss: 2744.3062, val r2: 0.5262\n",
      "Epoch [ 355/1000], trn los: 290.6184, trn r2: 0.5184, val loss: 2936.9569, val r2: 0.4938\n",
      "Epoch [ 356/1000], trn los: 299.7519, trn r2: 0.5009, val loss: 2894.6954, val r2: 0.5044\n",
      "Epoch [ 357/1000], trn los: 305.6200, trn r2: 0.4982, val loss: 3038.7108, val r2: 0.4781\n",
      "Epoch [ 358/1000], trn los: 314.7758, trn r2: 0.4879, val loss: 2855.0013, val r2: 0.5102\n",
      "Epoch [ 359/1000], trn los: 290.4530, trn r2: 0.5052, val loss: 3068.4439, val r2: 0.4735\n",
      "Epoch [ 360/1000], trn los: 281.4644, trn r2: 0.5223, val loss: 2795.8535, val r2: 0.5279\n",
      "Epoch [ 361/1000], trn los: 304.3039, trn r2: 0.4864, val loss: 2811.4575, val r2: 0.5168\n",
      "Epoch [ 362/1000], trn los: 287.8906, trn r2: 0.5144, val loss: 2991.2473, val r2: 0.4880\n",
      "Epoch [ 363/1000], trn los: 277.4141, trn r2: 0.5286, val loss: 2753.6631, val r2: 0.5322\n",
      "Epoch [ 364/1000], trn los: 281.6474, trn r2: 0.5143, val loss: 2860.4559, val r2: 0.5114\n",
      "Epoch [ 365/1000], trn los: 272.9805, trn r2: 0.5268, val loss: 2810.1422, val r2: 0.5169\n",
      "Epoch [ 366/1000], trn los: 294.8674, trn r2: 0.4886, val loss: 2723.0388, val r2: 0.5310\n",
      "Epoch [ 367/1000], trn los: 264.9077, trn r2: 0.5445, val loss: 3500.0126, val r2: 0.3984\n",
      "Epoch [ 368/1000], trn los: 291.4833, trn r2: 0.4935, val loss: 2766.9515, val r2: 0.5257\n",
      "Epoch [ 369/1000], trn los: 287.9961, trn r2: 0.4957, val loss: 2982.9657, val r2: 0.4914\n",
      "Epoch [ 370/1000], trn los: 291.2705, trn r2: 0.4906, val loss: 3179.6499, val r2: 0.4594\n",
      "Epoch [ 371/1000], trn los: 280.1126, trn r2: 0.5148, val loss: 2959.2267, val r2: 0.4989\n",
      "Epoch [ 372/1000], trn los: 289.2252, trn r2: 0.5080, val loss: 3097.2289, val r2: 0.4674\n",
      "Epoch [ 373/1000], trn los: 280.9368, trn r2: 0.5139, val loss: 2762.8501, val r2: 0.5296\n",
      "Epoch [ 374/1000], trn los: 285.8631, trn r2: 0.4934, val loss: 3060.5122, val r2: 0.4766\n",
      "Epoch [ 375/1000], trn los: 279.1813, trn r2: 0.5255, val loss: 2730.1966, val r2: 0.5301\n",
      "Epoch [ 376/1000], trn los: 289.9733, trn r2: 0.4871, val loss: 2811.5142, val r2: 0.5177\n",
      "Epoch [ 377/1000], trn los: 308.9640, trn r2: 0.4547, val loss: 2768.0132, val r2: 0.5262\n",
      "Epoch [ 378/1000], trn los: 299.2037, trn r2: 0.4770, val loss: 3130.4628, val r2: 0.4639\n",
      "Epoch [ 379/1000], trn los: 307.1348, trn r2: 0.4649, val loss: 2907.2008, val r2: 0.5029\n",
      "Epoch [ 380/1000], trn los: 303.8138, trn r2: 0.4659, val loss: 3030.4207, val r2: 0.4802\n",
      "Epoch [ 381/1000], trn los: 279.8343, trn r2: 0.4999, val loss: 3234.9306, val r2: 0.4499\n",
      "Epoch [ 382/1000], trn los: 281.2313, trn r2: 0.4939, val loss: 2746.4227, val r2: 0.5312\n",
      "Epoch [ 383/1000], trn los: 287.4965, trn r2: 0.4777, val loss: 2894.3263, val r2: 0.5054\n",
      "Epoch [ 384/1000], trn los: 286.9218, trn r2: 0.4939, val loss: 3014.7283, val r2: 0.4880\n",
      "Epoch [ 385/1000], trn los: 281.0473, trn r2: 0.4983, val loss: 3170.7029, val r2: 0.4550\n",
      "Epoch [ 386/1000], trn los: 268.0646, trn r2: 0.5263, val loss: 2972.9826, val r2: 0.4910\n",
      "Epoch [ 387/1000], trn los: 248.7446, trn r2: 0.5463, val loss: 2770.1139, val r2: 0.5223\n",
      "Epoch [ 388/1000], trn los: 271.6145, trn r2: 0.5090, val loss: 3279.9978, val r2: 0.4449\n",
      "Epoch [ 389/1000], trn los: 281.0220, trn r2: 0.4915, val loss: 2730.0024, val r2: 0.5304\n",
      "Epoch [ 390/1000], trn los: 286.3797, trn r2: 0.4876, val loss: 2697.9715, val r2: 0.5366\n",
      "Epoch [ 391/1000], trn los: 276.6858, trn r2: 0.5015, val loss: 2800.1334, val r2: 0.5218\n",
      "Epoch [ 392/1000], trn los: 262.2113, trn r2: 0.5124, val loss: 2852.1194, val r2: 0.5123\n",
      "Epoch [ 393/1000], trn los: 288.0526, trn r2: 0.4660, val loss: 2895.9942, val r2: 0.5062\n",
      "Epoch [ 394/1000], trn los: 302.2084, trn r2: 0.4608, val loss: 2798.0307, val r2: 0.5173\n",
      "Epoch [ 395/1000], trn los: 280.6128, trn r2: 0.4839, val loss: 2716.9055, val r2: 0.5360\n",
      "Epoch [ 396/1000], trn los: 279.1232, trn r2: 0.4914, val loss: 2759.7484, val r2: 0.5275\n",
      "Epoch [ 397/1000], trn los: 269.4517, trn r2: 0.4967, val loss: 2971.9039, val r2: 0.4899\n",
      "Epoch [ 398/1000], trn los: 256.5304, trn r2: 0.5244, val loss: 2978.9956, val r2: 0.4883\n",
      "Epoch [ 399/1000], trn los: 254.7797, trn r2: 0.5222, val loss: 2796.4222, val r2: 0.5235\n",
      "Epoch [ 400/1000], trn los: 261.6170, trn r2: 0.5180, val loss: 2758.4300, val r2: 0.5290\n",
      "Epoch [ 401/1000], trn los: 263.6722, trn r2: 0.4993, val loss: 3248.3400, val r2: 0.4466\n",
      "Epoch [ 402/1000], trn los: 258.0668, trn r2: 0.5111, val loss: 2820.7019, val r2: 0.5160\n",
      "Epoch [ 403/1000], trn los: 255.1376, trn r2: 0.5119, val loss: 3037.3537, val r2: 0.4812\n",
      "Epoch [ 404/1000], trn los: 252.2463, trn r2: 0.5238, val loss: 2726.7586, val r2: 0.5304\n",
      "Epoch [ 405/1000], trn los: 245.1108, trn r2: 0.5341, val loss: 3131.8605, val r2: 0.4670\n",
      "Epoch [ 406/1000], trn los: 264.2610, trn r2: 0.4940, val loss: 3676.6748, val r2: 0.3716\n",
      "Epoch [ 407/1000], trn los: 271.8710, trn r2: 0.4907, val loss: 3217.3223, val r2: 0.4562\n",
      "Epoch [ 408/1000], trn los: 253.7184, trn r2: 0.5122, val loss: 3136.7540, val r2: 0.4622\n",
      "Epoch [ 409/1000], trn los: 246.8682, trn r2: 0.5309, val loss: 2889.3054, val r2: 0.5065\n",
      "Epoch [ 410/1000], trn los: 255.2180, trn r2: 0.5224, val loss: 3069.8713, val r2: 0.4732\n",
      "Epoch [ 411/1000], trn los: 267.6717, trn r2: 0.4875, val loss: 2726.6612, val r2: 0.5307\n",
      "Epoch [ 412/1000], trn los: 256.0727, trn r2: 0.5204, val loss: 2775.3153, val r2: 0.5279\n",
      "Epoch [ 413/1000], trn los: 263.0567, trn r2: 0.5104, val loss: 2840.4666, val r2: 0.5135\n",
      "Epoch [ 414/1000], trn los: 258.5151, trn r2: 0.5073, val loss: 2989.9540, val r2: 0.4899\n",
      "Epoch [ 415/1000], trn los: 255.1524, trn r2: 0.5135, val loss: 2872.2185, val r2: 0.5070\n",
      "Epoch [ 416/1000], trn los: 273.1659, trn r2: 0.4638, val loss: 3188.4489, val r2: 0.4526\n",
      "Epoch [ 417/1000], trn los: 251.4193, trn r2: 0.5166, val loss: 2757.7249, val r2: 0.5256\n",
      "Epoch [ 418/1000], trn los: 247.9463, trn r2: 0.5157, val loss: 2929.8430, val r2: 0.4961\n",
      "Epoch [ 419/1000], trn los: 224.6277, trn r2: 0.5597, val loss: 2820.7370, val r2: 0.5132\n",
      "Epoch [ 420/1000], trn los: 244.9439, trn r2: 0.5171, val loss: 2773.6051, val r2: 0.5243\n",
      "Epoch [ 421/1000], trn los: 228.5173, trn r2: 0.5577, val loss: 2771.7389, val r2: 0.5261\n",
      "Epoch [ 422/1000], trn los: 257.0831, trn r2: 0.4943, val loss: 2765.6633, val r2: 0.5263\n",
      "Epoch [ 423/1000], trn los: 240.7234, trn r2: 0.5241, val loss: 2809.7972, val r2: 0.5184\n",
      "Epoch [ 424/1000], trn los: 243.6678, trn r2: 0.5165, val loss: 2730.8102, val r2: 0.5286\n",
      "Epoch [ 425/1000], trn los: 260.8346, trn r2: 0.4818, val loss: 2746.2490, val r2: 0.5257\n",
      "Epoch [ 426/1000], trn los: 236.2034, trn r2: 0.5250, val loss: 2687.4806, val r2: 0.5379\n",
      "Epoch [ 427/1000], trn los: 246.6630, trn r2: 0.5218, val loss: 2715.0432, val r2: 0.5341\n",
      "Epoch [ 428/1000], trn los: 236.5119, trn r2: 0.5185, val loss: 2915.0052, val r2: 0.5048\n",
      "Epoch [ 429/1000], trn los: 240.1008, trn r2: 0.5183, val loss: 2849.5997, val r2: 0.5108\n",
      "Epoch [ 430/1000], trn los: 236.4195, trn r2: 0.5207, val loss: 2729.2658, val r2: 0.5305\n",
      "Epoch [ 431/1000], trn los: 241.0006, trn r2: 0.5066, val loss: 2721.6216, val r2: 0.5311\n",
      "Epoch [ 432/1000], trn los: 245.8840, trn r2: 0.4959, val loss: 2851.9714, val r2: 0.5104\n",
      "Epoch [ 433/1000], trn los: 235.3852, trn r2: 0.5182, val loss: 2767.6164, val r2: 0.5264\n",
      "Epoch [ 434/1000], trn los: 241.8914, trn r2: 0.5069, val loss: 2813.5130, val r2: 0.5205\n",
      "Epoch [ 435/1000], trn los: 261.0218, trn r2: 0.4679, val loss: 2952.9950, val r2: 0.4975\n",
      "Epoch [ 436/1000], trn los: 249.9490, trn r2: 0.4884, val loss: 2772.1375, val r2: 0.5230\n",
      "Epoch [ 437/1000], trn los: 229.1985, trn r2: 0.5367, val loss: 2852.1258, val r2: 0.5119\n",
      "Epoch [ 438/1000], trn los: 231.9340, trn r2: 0.5296, val loss: 3047.2872, val r2: 0.4804\n",
      "Epoch [ 439/1000], trn los: 225.7603, trn r2: 0.5298, val loss: 2739.6429, val r2: 0.5275\n",
      "Epoch [ 440/1000], trn los: 223.3542, trn r2: 0.5409, val loss: 3138.3937, val r2: 0.4582\n",
      "Epoch [ 441/1000], trn los: 239.9937, trn r2: 0.5105, val loss: 3380.3681, val r2: 0.4185\n",
      "Epoch [ 442/1000], trn los: 248.6518, trn r2: 0.4777, val loss: 2838.3628, val r2: 0.5117\n",
      "Epoch [ 443/1000], trn los: 226.0823, trn r2: 0.5346, val loss: 3054.8819, val r2: 0.4741\n",
      "Epoch [ 444/1000], trn los: 225.6516, trn r2: 0.5320, val loss: 2787.2618, val r2: 0.5255\n",
      "Epoch [ 445/1000], trn los: 211.5997, trn r2: 0.5654, val loss: 2780.7893, val r2: 0.5206\n",
      "Epoch [ 446/1000], trn los: 225.6950, trn r2: 0.5259, val loss: 3116.4727, val r2: 0.4704\n",
      "Epoch [ 447/1000], trn los: 241.2797, trn r2: 0.5032, val loss: 2882.8301, val r2: 0.5080\n",
      "Epoch [ 448/1000], trn los: 227.9083, trn r2: 0.5167, val loss: 2747.4707, val r2: 0.5291\n",
      "Epoch [ 449/1000], trn los: 237.6889, trn r2: 0.4942, val loss: 2897.5422, val r2: 0.5026\n",
      "Epoch [ 450/1000], trn los: 226.0824, trn r2: 0.5315, val loss: 2770.1401, val r2: 0.5258\n",
      "Epoch [ 451/1000], trn los: 233.5346, trn r2: 0.5051, val loss: 2858.4776, val r2: 0.5083\n",
      "Epoch [ 452/1000], trn los: 224.9501, trn r2: 0.5295, val loss: 2765.7115, val r2: 0.5242\n",
      "Epoch [ 453/1000], trn los: 208.8075, trn r2: 0.5604, val loss: 2819.9602, val r2: 0.5181\n",
      "Epoch [ 454/1000], trn los: 230.1173, trn r2: 0.5092, val loss: 2786.4693, val r2: 0.5256\n",
      "Epoch [ 455/1000], trn los: 220.0453, trn r2: 0.5312, val loss: 2834.5912, val r2: 0.5157\n",
      "Epoch [ 456/1000], trn los: 242.4029, trn r2: 0.4870, val loss: 2754.2286, val r2: 0.5279\n",
      "Epoch [ 457/1000], trn los: 225.9524, trn r2: 0.5226, val loss: 2881.7651, val r2: 0.5122\n",
      "Epoch [ 458/1000], trn los: 233.1046, trn r2: 0.4957, val loss: 2898.2400, val r2: 0.5013\n",
      "Epoch [ 459/1000], trn los: 248.8015, trn r2: 0.4572, val loss: 2752.7079, val r2: 0.5270\n",
      "Epoch [ 460/1000], trn los: 229.7138, trn r2: 0.5038, val loss: 2789.1467, val r2: 0.5202\n",
      "Epoch [ 461/1000], trn los: 226.4894, trn r2: 0.5060, val loss: 3016.7272, val r2: 0.4893\n",
      "Epoch [ 462/1000], trn los: 219.2717, trn r2: 0.5322, val loss: 2765.8733, val r2: 0.5247\n",
      "Epoch [ 463/1000], trn los: 215.6327, trn r2: 0.5294, val loss: 2802.8708, val r2: 0.5251\n",
      "Epoch [ 464/1000], trn los: 208.6902, trn r2: 0.5513, val loss: 2897.9986, val r2: 0.5013\n",
      "Epoch [ 465/1000], trn los: 217.1145, trn r2: 0.5239, val loss: 2916.9552, val r2: 0.4997\n",
      "Epoch [ 466/1000], trn los: 239.8868, trn r2: 0.4822, val loss: 2753.7134, val r2: 0.5267\n",
      "Epoch [ 467/1000], trn los: 222.3064, trn r2: 0.5112, val loss: 2858.4130, val r2: 0.5059\n",
      "Epoch [ 468/1000], trn los: 212.1936, trn r2: 0.5386, val loss: 2798.1155, val r2: 0.5202\n",
      "Epoch [ 469/1000], trn los: 204.3096, trn r2: 0.5545, val loss: 2818.2812, val r2: 0.5213\n",
      "Epoch [ 470/1000], trn los: 214.6565, trn r2: 0.5268, val loss: 2767.3989, val r2: 0.5228\n",
      "Epoch [ 471/1000], trn los: 235.8071, trn r2: 0.4963, val loss: 3269.9502, val r2: 0.4385\n",
      "Epoch [ 472/1000], trn los: 205.9675, trn r2: 0.5400, val loss: 3384.2304, val r2: 0.4272\n",
      "Epoch [ 473/1000], trn los: 230.5960, trn r2: 0.5004, val loss: 2747.9773, val r2: 0.5285\n",
      "Epoch [ 474/1000], trn los: 209.6450, trn r2: 0.5333, val loss: 3133.1449, val r2: 0.4659\n",
      "Epoch [ 475/1000], trn los: 218.1352, trn r2: 0.5260, val loss: 2729.8576, val r2: 0.5302\n",
      "Epoch [ 476/1000], trn los: 218.4109, trn r2: 0.5147, val loss: 2907.5624, val r2: 0.4985\n",
      "Epoch [ 477/1000], trn los: 206.0172, trn r2: 0.5350, val loss: 2754.2126, val r2: 0.5270\n",
      "Epoch [ 478/1000], trn los: 196.4237, trn r2: 0.5619, val loss: 2688.2726, val r2: 0.5394\n",
      "Epoch [ 479/1000], trn los: 201.0582, trn r2: 0.5428, val loss: 3082.7690, val r2: 0.4750\n",
      "Epoch [ 480/1000], trn los: 216.4891, trn r2: 0.5099, val loss: 2777.3547, val r2: 0.5250\n",
      "Epoch [ 481/1000], trn los: 216.0809, trn r2: 0.5251, val loss: 2701.5970, val r2: 0.5346\n",
      "Epoch [ 482/1000], trn los: 221.8119, trn r2: 0.4913, val loss: 2807.0191, val r2: 0.5181\n",
      "Epoch [ 483/1000], trn los: 242.1850, trn r2: 0.4668, val loss: 2752.6652, val r2: 0.5301\n",
      "Epoch [ 484/1000], trn los: 203.2537, trn r2: 0.5383, val loss: 2783.6034, val r2: 0.5231\n",
      "Epoch [ 485/1000], trn los: 196.0297, trn r2: 0.5536, val loss: 3292.1796, val r2: 0.4363\n",
      "Epoch [ 486/1000], trn los: 195.6735, trn r2: 0.5588, val loss: 2932.7548, val r2: 0.4976\n",
      "Epoch [ 487/1000], trn los: 200.3506, trn r2: 0.5389, val loss: 2830.3631, val r2: 0.5173\n",
      "Epoch [ 488/1000], trn los: 228.1410, trn r2: 0.4905, val loss: 3072.4744, val r2: 0.4729\n",
      "Epoch [ 489/1000], trn los: 196.3209, trn r2: 0.5513, val loss: 2730.2523, val r2: 0.5354\n",
      "Epoch [ 490/1000], trn los: 210.5773, trn r2: 0.5140, val loss: 2717.2808, val r2: 0.5325\n",
      "Epoch [ 491/1000], trn los: 196.5919, trn r2: 0.5519, val loss: 2711.3915, val r2: 0.5327\n",
      "Epoch [ 492/1000], trn los: 197.5579, trn r2: 0.5454, val loss: 2750.2799, val r2: 0.5296\n",
      "Epoch [ 493/1000], trn los: 198.9549, trn r2: 0.5356, val loss: 2787.0909, val r2: 0.5245\n",
      "Epoch [ 494/1000], trn los: 194.3032, trn r2: 0.5495, val loss: 2878.8150, val r2: 0.5069\n",
      "Epoch [ 495/1000], trn los: 214.9468, trn r2: 0.5081, val loss: 2777.0308, val r2: 0.5284\n",
      "Epoch [ 496/1000], trn los: 204.0707, trn r2: 0.5229, val loss: 2766.8161, val r2: 0.5259\n",
      "Epoch [ 497/1000], trn los: 209.8831, trn r2: 0.5139, val loss: 2797.1969, val r2: 0.5217\n",
      "Epoch [ 498/1000], trn los: 196.2787, trn r2: 0.5515, val loss: 2744.2390, val r2: 0.5310\n",
      "Epoch [ 499/1000], trn los: 201.0835, trn r2: 0.5261, val loss: 2785.7770, val r2: 0.5221\n",
      "Epoch [ 500/1000], trn los: 190.3871, trn r2: 0.5537, val loss: 2789.6832, val r2: 0.5203\n",
      "Epoch [ 501/1000], trn los: 207.2166, trn r2: 0.5132, val loss: 2851.9102, val r2: 0.5131\n",
      "Epoch [ 502/1000], trn los: 205.6812, trn r2: 0.5289, val loss: 3028.1978, val r2: 0.4798\n",
      "Epoch [ 503/1000], trn los: 211.2130, trn r2: 0.5122, val loss: 2863.2225, val r2: 0.5164\n",
      "Epoch [ 504/1000], trn los: 207.4958, trn r2: 0.5133, val loss: 2707.3488, val r2: 0.5342\n",
      "Epoch [ 505/1000], trn los: 212.1473, trn r2: 0.5041, val loss: 2731.8961, val r2: 0.5296\n",
      "Epoch [ 506/1000], trn los: 187.1216, trn r2: 0.5519, val loss: 2745.2973, val r2: 0.5290\n",
      "Epoch [ 507/1000], trn los: 202.9643, trn r2: 0.5193, val loss: 2816.8757, val r2: 0.5152\n",
      "Epoch [ 508/1000], trn los: 202.6840, trn r2: 0.5247, val loss: 2822.4019, val r2: 0.5146\n",
      "Epoch [ 509/1000], trn los: 196.2381, trn r2: 0.5285, val loss: 2806.4318, val r2: 0.5160\n",
      "Epoch [ 510/1000], trn los: 200.7142, trn r2: 0.5165, val loss: 2723.5722, val r2: 0.5361\n",
      "Epoch [ 511/1000], trn los: 202.4592, trn r2: 0.5199, val loss: 3017.8468, val r2: 0.4817\n",
      "Epoch [ 512/1000], trn los: 200.7296, trn r2: 0.5169, val loss: 2714.3149, val r2: 0.5335\n",
      "Epoch [ 513/1000], trn los: 194.0779, trn r2: 0.5284, val loss: 2743.7273, val r2: 0.5316\n",
      "Epoch [ 514/1000], trn los: 197.1764, trn r2: 0.5198, val loss: 2667.3750, val r2: 0.5405\n",
      "Epoch [ 515/1000], trn los: 181.5297, trn r2: 0.5673, val loss: 2750.1708, val r2: 0.5276\n",
      "Epoch [ 516/1000], trn los: 200.9354, trn r2: 0.5350, val loss: 2888.3240, val r2: 0.5040\n",
      "Epoch [ 517/1000], trn los: 203.8670, trn r2: 0.5196, val loss: 2761.5087, val r2: 0.5250\n",
      "Epoch [ 518/1000], trn los: 185.9398, trn r2: 0.5653, val loss: 3083.2529, val r2: 0.4736\n",
      "Epoch [ 519/1000], trn los: 205.3478, trn r2: 0.4999, val loss: 2667.8212, val r2: 0.5420\n",
      "Epoch [ 520/1000], trn los: 197.3090, trn r2: 0.5122, val loss: 2830.6984, val r2: 0.5137\n",
      "Epoch [ 521/1000], trn los: 198.8623, trn r2: 0.5182, val loss: 2700.5202, val r2: 0.5357\n",
      "Epoch [ 522/1000], trn los: 194.4931, trn r2: 0.5293, val loss: 2777.2265, val r2: 0.5219\n",
      "Epoch [ 523/1000], trn los: 190.2442, trn r2: 0.5307, val loss: 2745.9781, val r2: 0.5285\n",
      "Epoch [ 524/1000], trn los: 180.7971, trn r2: 0.5518, val loss: 2824.7703, val r2: 0.5194\n",
      "Epoch [ 525/1000], trn los: 191.1069, trn r2: 0.5347, val loss: 2742.4444, val r2: 0.5310\n",
      "Epoch [ 526/1000], trn los: 184.7680, trn r2: 0.5477, val loss: 3114.5718, val r2: 0.4743\n",
      "Epoch [ 527/1000], trn los: 212.8603, trn r2: 0.4908, val loss: 2721.5465, val r2: 0.5322\n",
      "Epoch [ 528/1000], trn los: 180.4153, trn r2: 0.5470, val loss: 2636.6019, val r2: 0.5458\n",
      "Epoch [ 529/1000], trn los: 197.0230, trn r2: 0.5184, val loss: 2900.1902, val r2: 0.5029\n",
      "Epoch [ 530/1000], trn los: 191.4916, trn r2: 0.5222, val loss: 2662.0279, val r2: 0.5433\n",
      "Epoch [ 531/1000], trn los: 205.3762, trn r2: 0.4947, val loss: 2685.8015, val r2: 0.5418\n",
      "Epoch [ 532/1000], trn los: 193.4873, trn r2: 0.5284, val loss: 2808.2749, val r2: 0.5177\n",
      "Epoch [ 533/1000], trn los: 184.5424, trn r2: 0.5324, val loss: 2758.1552, val r2: 0.5295\n",
      "Epoch [ 534/1000], trn los: 175.4963, trn r2: 0.5622, val loss: 2901.6405, val r2: 0.5035\n",
      "Epoch [ 535/1000], trn los: 193.9533, trn r2: 0.5147, val loss: 2668.0656, val r2: 0.5392\n",
      "Epoch [ 536/1000], trn los: 197.8009, trn r2: 0.4983, val loss: 2956.7967, val r2: 0.4928\n",
      "Epoch [ 537/1000], trn los: 190.9436, trn r2: 0.5391, val loss: 2767.4888, val r2: 0.5252\n",
      "Epoch [ 538/1000], trn los: 180.6863, trn r2: 0.5508, val loss: 2688.0944, val r2: 0.5368\n",
      "Epoch [ 539/1000], trn los: 181.3012, trn r2: 0.5393, val loss: 2864.3453, val r2: 0.5073\n",
      "Epoch [ 540/1000], trn los: 204.8051, trn r2: 0.5082, val loss: 2767.9237, val r2: 0.5258\n",
      "Epoch [ 541/1000], trn los: 175.4509, trn r2: 0.5517, val loss: 2708.3624, val r2: 0.5343\n",
      "Epoch [ 542/1000], trn los: 178.4017, trn r2: 0.5447, val loss: 2773.4316, val r2: 0.5247\n",
      "Epoch [ 543/1000], trn los: 186.3431, trn r2: 0.5340, val loss: 2720.8584, val r2: 0.5348\n",
      "Epoch [ 544/1000], trn los: 191.7311, trn r2: 0.5209, val loss: 2892.0972, val r2: 0.5049\n",
      "Epoch [ 545/1000], trn los: 186.2240, trn r2: 0.5343, val loss: 2838.9656, val r2: 0.5103\n",
      "Epoch [ 546/1000], trn los: 187.2056, trn r2: 0.5304, val loss: 2701.1611, val r2: 0.5355\n",
      "Epoch [ 547/1000], trn los: 182.3261, trn r2: 0.5252, val loss: 2750.5463, val r2: 0.5288\n",
      "Epoch [ 548/1000], trn los: 179.8425, trn r2: 0.5438, val loss: 2751.9667, val r2: 0.5288\n",
      "Epoch [ 549/1000], trn los: 183.5387, trn r2: 0.5347, val loss: 2999.3036, val r2: 0.4871\n",
      "Epoch [ 550/1000], trn los: 182.7078, trn r2: 0.5286, val loss: 3036.4740, val r2: 0.4791\n",
      "Epoch [ 551/1000], trn los: 187.1466, trn r2: 0.5414, val loss: 2770.2556, val r2: 0.5228\n",
      "Epoch [ 552/1000], trn los: 183.6444, trn r2: 0.5231, val loss: 2732.7533, val r2: 0.5344\n",
      "Epoch [ 553/1000], trn los: 172.7824, trn r2: 0.5650, val loss: 2880.8702, val r2: 0.5093\n",
      "Epoch [ 554/1000], trn los: 169.6239, trn r2: 0.5565, val loss: 2895.3493, val r2: 0.5009\n",
      "Epoch [ 555/1000], trn los: 175.0519, trn r2: 0.5460, val loss: 2897.9038, val r2: 0.5010\n",
      "Epoch [ 556/1000], trn los: 164.8537, trn r2: 0.5746, val loss: 2735.9823, val r2: 0.5279\n",
      "Epoch [ 557/1000], trn los: 183.4944, trn r2: 0.5310, val loss: 2706.4531, val r2: 0.5326\n",
      "Epoch [ 558/1000], trn los: 171.1688, trn r2: 0.5502, val loss: 3054.6544, val r2: 0.4777\n",
      "Epoch [ 559/1000], trn los: 174.7343, trn r2: 0.5405, val loss: 2732.4140, val r2: 0.5302\n",
      "Epoch [ 560/1000], trn los: 185.6136, trn r2: 0.5074, val loss: 2857.0189, val r2: 0.5093\n",
      "Epoch [ 561/1000], trn los: 182.1619, trn r2: 0.5145, val loss: 2686.0261, val r2: 0.5358\n",
      "Epoch [ 562/1000], trn los: 161.0205, trn r2: 0.5820, val loss: 2727.7794, val r2: 0.5315\n",
      "Epoch [ 563/1000], trn los: 182.6422, trn r2: 0.5303, val loss: 2687.6697, val r2: 0.5369\n",
      "Epoch [ 564/1000], trn los: 173.3409, trn r2: 0.5382, val loss: 2713.8056, val r2: 0.5340\n",
      "Epoch [ 565/1000], trn los: 171.4449, trn r2: 0.5424, val loss: 2831.4062, val r2: 0.5191\n",
      "Epoch [ 566/1000], trn los: 185.4610, trn r2: 0.5029, val loss: 2791.4128, val r2: 0.5179\n",
      "Epoch [ 567/1000], trn los: 168.1601, trn r2: 0.5485, val loss: 3237.3409, val r2: 0.4453\n",
      "Epoch [ 568/1000], trn los: 171.3170, trn r2: 0.5397, val loss: 2820.5180, val r2: 0.5186\n",
      "Epoch [ 569/1000], trn los: 180.3557, trn r2: 0.5209, val loss: 2725.1650, val r2: 0.5357\n",
      "Epoch [ 570/1000], trn los: 161.1738, trn r2: 0.5638, val loss: 2772.0293, val r2: 0.5256\n",
      "Epoch [ 571/1000], trn los: 177.7801, trn r2: 0.5316, val loss: 2679.8664, val r2: 0.5383\n",
      "Epoch [ 572/1000], trn los: 166.5054, trn r2: 0.5508, val loss: 2778.4995, val r2: 0.5287\n",
      "Epoch [ 573/1000], trn los: 167.5888, trn r2: 0.5511, val loss: 2679.5190, val r2: 0.5423\n",
      "Epoch [ 574/1000], trn los: 155.1659, trn r2: 0.5839, val loss: 2957.7509, val r2: 0.4916\n",
      "Epoch [ 575/1000], trn los: 178.3773, trn r2: 0.5215, val loss: 2696.3688, val r2: 0.5381\n",
      "Epoch [ 576/1000], trn los: 163.1142, trn r2: 0.5663, val loss: 2730.0157, val r2: 0.5310\n",
      "Epoch [ 577/1000], trn los: 171.8804, trn r2: 0.5318, val loss: 2756.0364, val r2: 0.5279\n",
      "Epoch [ 578/1000], trn los: 170.1937, trn r2: 0.5374, val loss: 2718.3477, val r2: 0.5326\n",
      "Epoch [ 579/1000], trn los: 174.2966, trn r2: 0.5237, val loss: 2873.5809, val r2: 0.5041\n",
      "Epoch [ 580/1000], trn los: 175.3619, trn r2: 0.5188, val loss: 2764.8534, val r2: 0.5238\n",
      "Epoch [ 581/1000], trn los: 177.5250, trn r2: 0.5104, val loss: 2779.3315, val r2: 0.5256\n",
      "Epoch [ 582/1000], trn los: 167.4317, trn r2: 0.5498, val loss: 2694.7733, val r2: 0.5364\n",
      "Epoch [ 583/1000], trn los: 168.0311, trn r2: 0.5406, val loss: 2656.5731, val r2: 0.5420\n",
      "Epoch [ 584/1000], trn los: 175.7571, trn r2: 0.5324, val loss: 2677.0395, val r2: 0.5414\n",
      "Epoch [ 585/1000], trn los: 168.1445, trn r2: 0.5417, val loss: 2766.1761, val r2: 0.5222\n",
      "Epoch [ 586/1000], trn los: 169.4713, trn r2: 0.5295, val loss: 3032.9251, val r2: 0.4848\n",
      "Epoch [ 587/1000], trn los: 171.4631, trn r2: 0.5237, val loss: 2744.9320, val r2: 0.5290\n",
      "Epoch [ 588/1000], trn los: 168.1071, trn r2: 0.5377, val loss: 2695.7583, val r2: 0.5383\n",
      "Epoch [ 589/1000], trn los: 162.8577, trn r2: 0.5631, val loss: 2836.3628, val r2: 0.5150\n",
      "Epoch [ 590/1000], trn los: 168.9215, trn r2: 0.5325, val loss: 2783.1491, val r2: 0.5209\n",
      "Epoch [ 591/1000], trn los: 160.3500, trn r2: 0.5555, val loss: 2665.3394, val r2: 0.5425\n",
      "Epoch [ 592/1000], trn los: 162.5021, trn r2: 0.5562, val loss: 2724.8809, val r2: 0.5326\n",
      "Epoch [ 593/1000], trn los: 170.1175, trn r2: 0.5285, val loss: 2765.3941, val r2: 0.5232\n",
      "Epoch [ 594/1000], trn los: 161.9016, trn r2: 0.5508, val loss: 2640.5775, val r2: 0.5455\n",
      "Epoch [ 595/1000], trn los: 176.2501, trn r2: 0.5050, val loss: 3000.9097, val r2: 0.4882\n",
      "Epoch [ 596/1000], trn los: 157.7049, trn r2: 0.5584, val loss: 2716.0338, val r2: 0.5336\n",
      "Epoch [ 597/1000], trn los: 161.7954, trn r2: 0.5527, val loss: 2897.8047, val r2: 0.5025\n",
      "Epoch [ 598/1000], trn los: 175.1547, trn r2: 0.5235, val loss: 2787.0609, val r2: 0.5219\n",
      "Epoch [ 599/1000], trn los: 167.8668, trn r2: 0.5399, val loss: 2992.4298, val r2: 0.4879\n",
      "Epoch [ 600/1000], trn los: 168.0804, trn r2: 0.5260, val loss: 2682.9910, val r2: 0.5389\n",
      "Epoch [ 601/1000], trn los: 152.9876, trn r2: 0.5675, val loss: 2832.9761, val r2: 0.5117\n",
      "Epoch [ 602/1000], trn los: 172.9096, trn r2: 0.5082, val loss: 2725.1021, val r2: 0.5352\n",
      "Epoch [ 603/1000], trn los: 157.7003, trn r2: 0.5558, val loss: 2666.6769, val r2: 0.5418\n",
      "Epoch [ 604/1000], trn los: 154.9859, trn r2: 0.5581, val loss: 2702.9026, val r2: 0.5383\n",
      "Epoch [ 605/1000], trn los: 164.3319, trn r2: 0.5367, val loss: 2780.2230, val r2: 0.5249\n",
      "Epoch [ 606/1000], trn los: 162.9970, trn r2: 0.5413, val loss: 2751.3312, val r2: 0.5241\n",
      "Epoch [ 607/1000], trn los: 156.1998, trn r2: 0.5527, val loss: 2724.3458, val r2: 0.5342\n",
      "Epoch [ 608/1000], trn los: 154.9967, trn r2: 0.5551, val loss: 2907.1985, val r2: 0.5050\n",
      "Epoch [ 609/1000], trn los: 157.0751, trn r2: 0.5497, val loss: 2694.3416, val r2: 0.5381\n",
      "Epoch [ 610/1000], trn los: 164.2129, trn r2: 0.5243, val loss: 2690.5573, val r2: 0.5401\n",
      "Epoch [ 611/1000], trn los: 156.5963, trn r2: 0.5460, val loss: 2871.8751, val r2: 0.5041\n",
      "Epoch [ 612/1000], trn los: 162.9932, trn r2: 0.5271, val loss: 2995.7362, val r2: 0.4895\n",
      "Epoch [ 613/1000], trn los: 150.1291, trn r2: 0.5688, val loss: 2927.9004, val r2: 0.5009\n",
      "Epoch [ 614/1000], trn los: 176.5528, trn r2: 0.5004, val loss: 2950.9788, val r2: 0.4920\n",
      "Epoch [ 615/1000], trn los: 163.9713, trn r2: 0.5224, val loss: 2737.6551, val r2: 0.5288\n",
      "Epoch [ 616/1000], trn los: 155.7805, trn r2: 0.5520, val loss: 2732.5061, val r2: 0.5287\n",
      "Epoch [ 617/1000], trn los: 157.0706, trn r2: 0.5470, val loss: 2729.2761, val r2: 0.5321\n",
      "Epoch [ 618/1000], trn los: 155.7091, trn r2: 0.5459, val loss: 2925.6776, val r2: 0.4968\n",
      "Epoch [ 619/1000], trn los: 162.7259, trn r2: 0.5296, val loss: 2813.9325, val r2: 0.5194\n",
      "Epoch [ 620/1000], trn los: 165.2839, trn r2: 0.5242, val loss: 2808.8457, val r2: 0.5194\n",
      "Epoch [ 621/1000], trn los: 159.0566, trn r2: 0.5348, val loss: 2689.7659, val r2: 0.5427\n",
      "Epoch [ 622/1000], trn los: 159.5736, trn r2: 0.5510, val loss: 2666.7874, val r2: 0.5417\n",
      "Epoch [ 623/1000], trn los: 146.4538, trn r2: 0.5752, val loss: 2721.2185, val r2: 0.5329\n",
      "Epoch [ 624/1000], trn los: 151.7647, trn r2: 0.5509, val loss: 2704.7269, val r2: 0.5387\n",
      "Epoch [ 625/1000], trn los: 157.5809, trn r2: 0.5413, val loss: 2798.8101, val r2: 0.5166\n",
      "Epoch [ 626/1000], trn los: 167.9570, trn r2: 0.5225, val loss: 2783.3793, val r2: 0.5226\n",
      "Epoch [ 627/1000], trn los: 156.8076, trn r2: 0.5412, val loss: 2735.3166, val r2: 0.5295\n",
      "Epoch [ 628/1000], trn los: 164.2548, trn r2: 0.5259, val loss: 2779.8654, val r2: 0.5228\n",
      "Epoch [ 629/1000], trn los: 145.9488, trn r2: 0.5632, val loss: 2696.7830, val r2: 0.5363\n",
      "Epoch [ 630/1000], trn los: 154.1669, trn r2: 0.5540, val loss: 2691.9309, val r2: 0.5396\n",
      "Epoch [ 631/1000], trn los: 149.0284, trn r2: 0.5592, val loss: 2704.3066, val r2: 0.5378\n",
      "Epoch [ 632/1000], trn los: 141.0778, trn r2: 0.5759, val loss: 2697.6573, val r2: 0.5369\n",
      "Epoch [ 633/1000], trn los: 133.3567, trn r2: 0.6063, val loss: 2734.6523, val r2: 0.5293\n",
      "Epoch [ 634/1000], trn los: 156.6087, trn r2: 0.5362, val loss: 2713.0208, val r2: 0.5338\n",
      "Epoch [ 635/1000], trn los: 153.0113, trn r2: 0.5396, val loss: 3000.5209, val r2: 0.4841\n",
      "Epoch [ 636/1000], trn los: 150.8762, trn r2: 0.5471, val loss: 2866.5130, val r2: 0.5167\n",
      "Epoch [ 637/1000], trn los: 155.2502, trn r2: 0.5356, val loss: 2687.4284, val r2: 0.5382\n",
      "Epoch [ 638/1000], trn los: 146.2684, trn r2: 0.5611, val loss: 2904.5397, val r2: 0.5013\n",
      "Epoch [ 639/1000], trn los: 160.3678, trn r2: 0.5420, val loss: 2714.8406, val r2: 0.5346\n",
      "Epoch [ 640/1000], trn los: 145.7836, trn r2: 0.5573, val loss: 2766.7505, val r2: 0.5232\n",
      "Epoch [ 641/1000], trn los: 142.9048, trn r2: 0.5671, val loss: 2811.7306, val r2: 0.5252\n",
      "Epoch [ 642/1000], trn los: 137.6610, trn r2: 0.5840, val loss: 2726.8823, val r2: 0.5341\n",
      "Epoch [ 643/1000], trn los: 143.7250, trn r2: 0.5614, val loss: 3298.5620, val r2: 0.4355\n",
      "Epoch [ 644/1000], trn los: 161.0438, trn r2: 0.5284, val loss: 2635.0942, val r2: 0.5511\n",
      "Epoch [ 645/1000], trn los: 150.3521, trn r2: 0.5457, val loss: 2615.9098, val r2: 0.5504\n",
      "Epoch [ 646/1000], trn los: 148.2607, trn r2: 0.5510, val loss: 2649.7428, val r2: 0.5453\n",
      "Epoch [ 647/1000], trn los: 146.8974, trn r2: 0.5658, val loss: 2651.9827, val r2: 0.5462\n",
      "Epoch [ 648/1000], trn los: 141.9216, trn r2: 0.5708, val loss: 2635.5784, val r2: 0.5492\n",
      "Epoch [ 649/1000], trn los: 151.3945, trn r2: 0.5484, val loss: 2808.3354, val r2: 0.5142\n",
      "Epoch [ 650/1000], trn los: 146.1001, trn r2: 0.5537, val loss: 2632.9194, val r2: 0.5527\n",
      "Epoch [ 651/1000], trn los: 147.1791, trn r2: 0.5456, val loss: 2657.8557, val r2: 0.5438\n",
      "Epoch [ 652/1000], trn los: 131.4467, trn r2: 0.5949, val loss: 2677.3370, val r2: 0.5384\n",
      "Epoch [ 653/1000], trn los: 145.4319, trn r2: 0.5522, val loss: 2640.4075, val r2: 0.5447\n",
      "Epoch [ 654/1000], trn los: 136.1587, trn r2: 0.5790, val loss: 2647.7465, val r2: 0.5439\n",
      "Epoch [ 655/1000], trn los: 151.5666, trn r2: 0.5374, val loss: 2687.4237, val r2: 0.5380\n",
      "Epoch [ 656/1000], trn los: 161.8080, trn r2: 0.5141, val loss: 2804.1133, val r2: 0.5198\n",
      "Epoch [ 657/1000], trn los: 142.9931, trn r2: 0.5572, val loss: 2697.8612, val r2: 0.5411\n",
      "Epoch [ 658/1000], trn los: 144.9861, trn r2: 0.5586, val loss: 2693.9978, val r2: 0.5404\n",
      "Epoch [ 659/1000], trn los: 143.6164, trn r2: 0.5629, val loss: 2691.2224, val r2: 0.5361\n",
      "Epoch [ 660/1000], trn los: 136.1306, trn r2: 0.5739, val loss: 2655.7496, val r2: 0.5444\n",
      "Epoch [ 661/1000], trn los: 142.7366, trn r2: 0.5622, val loss: 2646.4677, val r2: 0.5435\n",
      "Epoch [ 662/1000], trn los: 136.8820, trn r2: 0.5722, val loss: 2638.9321, val r2: 0.5454\n",
      "Epoch [ 663/1000], trn los: 132.3392, trn r2: 0.5947, val loss: 2645.4854, val r2: 0.5483\n",
      "Epoch [ 664/1000], trn los: 140.8642, trn r2: 0.5652, val loss: 2649.3726, val r2: 0.5426\n",
      "Epoch [ 665/1000], trn los: 137.0183, trn r2: 0.5809, val loss: 2810.4891, val r2: 0.5154\n",
      "Epoch [ 666/1000], trn los: 143.2501, trn r2: 0.5579, val loss: 2605.8960, val r2: 0.5529\n",
      "Epoch [ 667/1000], trn los: 153.1809, trn r2: 0.5199, val loss: 2769.5810, val r2: 0.5280\n",
      "Epoch [ 668/1000], trn los: 136.8505, trn r2: 0.5769, val loss: 2784.0608, val r2: 0.5233\n",
      "Epoch [ 669/1000], trn los: 145.0176, trn r2: 0.5407, val loss: 2849.3778, val r2: 0.5101\n",
      "Epoch [ 670/1000], trn los: 141.0402, trn r2: 0.5594, val loss: 2716.9485, val r2: 0.5325\n",
      "Epoch [ 671/1000], trn los: 133.9076, trn r2: 0.5730, val loss: 2743.8853, val r2: 0.5310\n",
      "Epoch [ 672/1000], trn los: 132.8951, trn r2: 0.5920, val loss: 2764.7679, val r2: 0.5262\n",
      "Epoch [ 673/1000], trn los: 147.8680, trn r2: 0.5498, val loss: 2954.8451, val r2: 0.4928\n",
      "Epoch [ 674/1000], trn los: 151.9785, trn r2: 0.5157, val loss: 2778.6951, val r2: 0.5249\n",
      "Epoch [ 675/1000], trn los: 141.2344, trn r2: 0.5608, val loss: 2770.0406, val r2: 0.5257\n",
      "Epoch [ 676/1000], trn los: 139.6108, trn r2: 0.5530, val loss: 2681.6341, val r2: 0.5392\n",
      "Epoch [ 677/1000], trn los: 137.0223, trn r2: 0.5683, val loss: 2668.3794, val r2: 0.5460\n",
      "Epoch [ 678/1000], trn los: 144.7022, trn r2: 0.5545, val loss: 2901.9205, val r2: 0.5023\n",
      "Epoch [ 679/1000], trn los: 137.8392, trn r2: 0.5593, val loss: 2804.8542, val r2: 0.5187\n",
      "Epoch [ 680/1000], trn los: 136.8027, trn r2: 0.5595, val loss: 2726.8447, val r2: 0.5333\n",
      "Epoch [ 681/1000], trn los: 135.9031, trn r2: 0.5843, val loss: 2647.0764, val r2: 0.5423\n",
      "Epoch [ 682/1000], trn los: 125.7730, trn r2: 0.5951, val loss: 2927.5880, val r2: 0.4959\n",
      "Epoch [ 683/1000], trn los: 136.3093, trn r2: 0.5705, val loss: 2690.8887, val r2: 0.5387\n",
      "Epoch [ 684/1000], trn los: 130.1574, trn r2: 0.5813, val loss: 2670.9994, val r2: 0.5422\n",
      "Epoch [ 685/1000], trn los: 136.3258, trn r2: 0.5651, val loss: 2848.7870, val r2: 0.5110\n",
      "Epoch [ 686/1000], trn los: 133.8849, trn r2: 0.5789, val loss: 2612.1067, val r2: 0.5508\n",
      "Epoch [ 687/1000], trn los: 128.6093, trn r2: 0.5800, val loss: 2654.5823, val r2: 0.5451\n",
      "Epoch [ 688/1000], trn los: 131.9493, trn r2: 0.5712, val loss: 2697.1656, val r2: 0.5349\n",
      "Epoch [ 689/1000], trn los: 126.0235, trn r2: 0.5926, val loss: 2737.2892, val r2: 0.5276\n",
      "Epoch [ 690/1000], trn los: 134.7114, trn r2: 0.5692, val loss: 2787.8488, val r2: 0.5200\n",
      "Epoch [ 691/1000], trn los: 125.4167, trn r2: 0.5941, val loss: 2853.4779, val r2: 0.5082\n",
      "Epoch [ 692/1000], trn los: 134.1720, trn r2: 0.5594, val loss: 2653.9341, val r2: 0.5433\n",
      "Epoch [ 693/1000], trn los: 141.6893, trn r2: 0.5446, val loss: 2716.0568, val r2: 0.5342\n",
      "Epoch [ 694/1000], trn los: 124.6259, trn r2: 0.5924, val loss: 2695.8400, val r2: 0.5375\n",
      "Epoch [ 695/1000], trn los: 129.3939, trn r2: 0.5769, val loss: 2755.8100, val r2: 0.5270\n",
      "Epoch [ 696/1000], trn los: 140.9254, trn r2: 0.5462, val loss: 2682.4106, val r2: 0.5386\n",
      "Epoch [ 697/1000], trn los: 128.7242, trn r2: 0.5831, val loss: 2712.6326, val r2: 0.5368\n",
      "Epoch [ 698/1000], trn los: 149.3791, trn r2: 0.5366, val loss: 3547.4239, val r2: 0.3965\n",
      "Epoch [ 699/1000], trn los: 126.9665, trn r2: 0.5887, val loss: 2653.5886, val r2: 0.5461\n",
      "Epoch [ 700/1000], trn los: 126.6270, trn r2: 0.5929, val loss: 2698.2550, val r2: 0.5447\n",
      "Epoch [ 701/1000], trn los: 139.3395, trn r2: 0.5410, val loss: 2651.6434, val r2: 0.5443\n",
      "Epoch [ 702/1000], trn los: 133.8473, trn r2: 0.5705, val loss: 2866.8399, val r2: 0.5128\n",
      "Epoch [ 703/1000], trn los: 128.9814, trn r2: 0.5769, val loss: 2673.0774, val r2: 0.5416\n",
      "Epoch [ 704/1000], trn los: 133.4295, trn r2: 0.5589, val loss: 2731.3480, val r2: 0.5327\n",
      "Epoch [ 705/1000], trn los: 133.6293, trn r2: 0.5609, val loss: 2766.7877, val r2: 0.5269\n",
      "Epoch [ 706/1000], trn los: 131.9048, trn r2: 0.5584, val loss: 2650.1739, val r2: 0.5497\n",
      "Epoch [ 707/1000], trn los: 126.2569, trn r2: 0.5903, val loss: 2776.8812, val r2: 0.5214\n",
      "Epoch [ 708/1000], trn los: 129.9187, trn r2: 0.5709, val loss: 2675.5218, val r2: 0.5411\n",
      "Epoch [ 709/1000], trn los: 125.2887, trn r2: 0.5774, val loss: 2690.4433, val r2: 0.5397\n",
      "Epoch [ 710/1000], trn los: 128.9819, trn r2: 0.5827, val loss: 2680.8534, val r2: 0.5376\n",
      "Epoch [ 711/1000], trn los: 135.6513, trn r2: 0.5470, val loss: 2754.8606, val r2: 0.5324\n",
      "Epoch [ 712/1000], trn los: 129.8672, trn r2: 0.5811, val loss: 2853.4862, val r2: 0.5103\n",
      "Epoch [ 713/1000], trn los: 133.2411, trn r2: 0.5670, val loss: 2844.8164, val r2: 0.5127\n",
      "Epoch [ 714/1000], trn los: 139.4589, trn r2: 0.5398, val loss: 2688.3470, val r2: 0.5405\n",
      "Epoch [ 715/1000], trn los: 128.2901, trn r2: 0.5716, val loss: 2938.2695, val r2: 0.4988\n",
      "Epoch [ 716/1000], trn los: 121.0414, trn r2: 0.5901, val loss: 2673.6104, val r2: 0.5427\n",
      "Epoch [ 717/1000], trn los: 140.3794, trn r2: 0.5372, val loss: 2744.2186, val r2: 0.5335\n",
      "Epoch [ 718/1000], trn los: 126.9533, trn r2: 0.5689, val loss: 2622.4482, val r2: 0.5505\n",
      "Epoch [ 719/1000], trn los: 126.6513, trn r2: 0.5774, val loss: 2645.9121, val r2: 0.5436\n",
      "Epoch [ 720/1000], trn los: 130.4795, trn r2: 0.5628, val loss: 2630.8243, val r2: 0.5496\n",
      "Epoch [ 721/1000], trn los: 127.9689, trn r2: 0.5735, val loss: 2768.9749, val r2: 0.5252\n",
      "Epoch [ 722/1000], trn los: 129.0977, trn r2: 0.5678, val loss: 2721.2238, val r2: 0.5308\n",
      "Epoch [ 723/1000], trn los: 119.8892, trn r2: 0.5882, val loss: 2957.1529, val r2: 0.4908\n",
      "Epoch [ 724/1000], trn los: 129.6378, trn r2: 0.5565, val loss: 2737.6886, val r2: 0.5296\n",
      "Epoch [ 725/1000], trn los: 124.3591, trn r2: 0.5806, val loss: 2666.0106, val r2: 0.5392\n",
      "Epoch [ 726/1000], trn los: 124.1978, trn r2: 0.5861, val loss: 2793.2984, val r2: 0.5220\n",
      "Epoch [ 727/1000], trn los: 127.8764, trn r2: 0.5707, val loss: 2790.6510, val r2: 0.5190\n",
      "Epoch [ 728/1000], trn los: 133.4804, trn r2: 0.5463, val loss: 3086.7093, val r2: 0.4720\n",
      "Epoch [ 729/1000], trn los: 132.8693, trn r2: 0.5526, val loss: 2796.1576, val r2: 0.5192\n",
      "Epoch [ 730/1000], trn los: 125.1317, trn r2: 0.5777, val loss: 2867.1022, val r2: 0.5064\n",
      "Epoch [ 731/1000], trn los: 128.9857, trn r2: 0.5538, val loss: 2695.2551, val r2: 0.5400\n",
      "Epoch [ 732/1000], trn los: 129.8028, trn r2: 0.5513, val loss: 2690.0376, val r2: 0.5430\n",
      "Epoch [ 733/1000], trn los: 123.1966, trn r2: 0.5737, val loss: 2606.5665, val r2: 0.5509\n",
      "Epoch [ 734/1000], trn los: 126.2804, trn r2: 0.5614, val loss: 2698.6443, val r2: 0.5368\n",
      "Epoch [ 735/1000], trn los: 115.1716, trn r2: 0.6019, val loss: 2657.2715, val r2: 0.5416\n",
      "Epoch [ 736/1000], trn los: 125.0822, trn r2: 0.5671, val loss: 2754.0945, val r2: 0.5337\n",
      "Epoch [ 737/1000], trn los: 119.1574, trn r2: 0.5891, val loss: 2707.2384, val r2: 0.5356\n",
      "Epoch [ 738/1000], trn los: 125.1062, trn r2: 0.5616, val loss: 2787.3585, val r2: 0.5227\n",
      "Epoch [ 739/1000], trn los: 122.9089, trn r2: 0.5706, val loss: 2620.4104, val r2: 0.5482\n",
      "Epoch [ 740/1000], trn los: 130.6480, trn r2: 0.5425, val loss: 2665.1694, val r2: 0.5415\n",
      "Epoch [ 741/1000], trn los: 117.9297, trn r2: 0.5863, val loss: 2660.3761, val r2: 0.5441\n",
      "Epoch [ 742/1000], trn los: 119.1835, trn r2: 0.5839, val loss: 2666.5843, val r2: 0.5491\n",
      "Epoch [ 743/1000], trn los: 122.0668, trn r2: 0.5766, val loss: 3008.0107, val r2: 0.4871\n",
      "Epoch [ 744/1000], trn los: 122.4084, trn r2: 0.5694, val loss: 2903.6244, val r2: 0.5028\n",
      "Epoch [ 745/1000], trn los: 121.5051, trn r2: 0.5766, val loss: 2624.6896, val r2: 0.5471\n",
      "Epoch [ 746/1000], trn los: 123.1434, trn r2: 0.5634, val loss: 2658.9226, val r2: 0.5454\n",
      "Epoch [ 747/1000], trn los: 121.6603, trn r2: 0.5695, val loss: 2791.2462, val r2: 0.5214\n",
      "Epoch [ 748/1000], trn los: 115.8755, trn r2: 0.5890, val loss: 2686.8124, val r2: 0.5415\n",
      "Epoch [ 749/1000], trn los: 117.8089, trn r2: 0.5891, val loss: 2680.1458, val r2: 0.5434\n",
      "Epoch [ 750/1000], trn los: 113.8910, trn r2: 0.5948, val loss: 2626.1068, val r2: 0.5518\n",
      "Epoch [ 751/1000], trn los: 123.2575, trn r2: 0.5798, val loss: 2664.2835, val r2: 0.5431\n",
      "Epoch [ 752/1000], trn los: 120.1234, trn r2: 0.5728, val loss: 2627.1788, val r2: 0.5500\n",
      "Epoch [ 753/1000], trn los: 127.5427, trn r2: 0.5656, val loss: 2691.9527, val r2: 0.5410\n",
      "Epoch [ 754/1000], trn los: 113.1489, trn r2: 0.5979, val loss: 2736.9123, val r2: 0.5294\n",
      "Epoch [ 755/1000], trn los: 116.3707, trn r2: 0.5863, val loss: 2619.8682, val r2: 0.5517\n",
      "Epoch [ 756/1000], trn los: 122.1260, trn r2: 0.5725, val loss: 2852.5865, val r2: 0.5079\n",
      "Epoch [ 757/1000], trn los: 124.0275, trn r2: 0.5665, val loss: 2713.3841, val r2: 0.5340\n",
      "Epoch [ 758/1000], trn los: 115.4840, trn r2: 0.5992, val loss: 2773.3458, val r2: 0.5218\n",
      "Epoch [ 759/1000], trn los: 113.4233, trn r2: 0.5940, val loss: 2664.4127, val r2: 0.5417\n",
      "Epoch [ 760/1000], trn los: 117.0683, trn r2: 0.5769, val loss: 2755.6796, val r2: 0.5270\n",
      "Epoch [ 761/1000], trn los: 113.6515, trn r2: 0.5985, val loss: 2854.2726, val r2: 0.5074\n",
      "Epoch [ 762/1000], trn los: 112.1802, trn r2: 0.5945, val loss: 2716.1009, val r2: 0.5386\n",
      "Epoch [ 763/1000], trn los: 120.9309, trn r2: 0.5664, val loss: 2695.0883, val r2: 0.5426\n",
      "Epoch [ 764/1000], trn los: 116.2335, trn r2: 0.5884, val loss: 2734.1935, val r2: 0.5333\n",
      "Epoch [ 765/1000], trn los: 114.8940, trn r2: 0.5901, val loss: 2546.8044, val r2: 0.5608\n",
      "Epoch [ 766/1000], trn los: 113.9400, trn r2: 0.5963, val loss: 2711.1647, val r2: 0.5348\n",
      "Epoch [ 767/1000], trn los: 125.1046, trn r2: 0.5614, val loss: 2544.6721, val r2: 0.5619\n",
      "Epoch [ 768/1000], trn los: 121.9309, trn r2: 0.5704, val loss: 2598.9425, val r2: 0.5547\n",
      "Epoch [ 769/1000], trn los: 114.7701, trn r2: 0.5907, val loss: 2593.5517, val r2: 0.5548\n",
      "Epoch [ 770/1000], trn los: 118.1038, trn r2: 0.5801, val loss: 2629.7870, val r2: 0.5495\n",
      "Epoch [ 771/1000], trn los: 122.2376, trn r2: 0.5627, val loss: 2712.2134, val r2: 0.5355\n",
      "Epoch [ 772/1000], trn los: 111.5773, trn r2: 0.5988, val loss: 2700.5685, val r2: 0.5390\n",
      "Epoch [ 773/1000], trn los: 113.7976, trn r2: 0.5841, val loss: 2730.8013, val r2: 0.5324\n",
      "Epoch [ 774/1000], trn los: 116.4637, trn r2: 0.5746, val loss: 2709.0645, val r2: 0.5386\n",
      "Epoch [ 775/1000], trn los: 111.9979, trn r2: 0.5948, val loss: 2678.7597, val r2: 0.5406\n",
      "Epoch [ 776/1000], trn los: 111.6809, trn r2: 0.6036, val loss: 2739.8019, val r2: 0.5321\n",
      "Epoch [ 777/1000], trn los: 115.7493, trn r2: 0.5751, val loss: 2774.6159, val r2: 0.5245\n",
      "Epoch [ 778/1000], trn los: 115.8637, trn r2: 0.5713, val loss: 2618.6532, val r2: 0.5502\n",
      "Epoch [ 779/1000], trn los: 108.2366, trn r2: 0.6011, val loss: 2976.6876, val r2: 0.4909\n",
      "Epoch [ 780/1000], trn los: 120.7477, trn r2: 0.5538, val loss: 2709.3806, val r2: 0.5355\n",
      "Epoch [ 781/1000], trn los: 110.5083, trn r2: 0.5915, val loss: 2735.6783, val r2: 0.5334\n",
      "Epoch [ 782/1000], trn los: 117.3116, trn r2: 0.5720, val loss: 2620.3753, val r2: 0.5495\n",
      "Epoch [ 783/1000], trn los: 106.0992, trn r2: 0.6097, val loss: 2785.1850, val r2: 0.5247\n",
      "Epoch [ 784/1000], trn los: 119.8441, trn r2: 0.5753, val loss: 2752.9910, val r2: 0.5259\n",
      "Epoch [ 785/1000], trn los: 119.8557, trn r2: 0.5640, val loss: 2660.8093, val r2: 0.5427\n",
      "Epoch [ 786/1000], trn los: 112.4796, trn r2: 0.5831, val loss: 2683.9250, val r2: 0.5415\n",
      "Epoch [ 787/1000], trn los: 115.2086, trn r2: 0.5759, val loss: 2707.6180, val r2: 0.5349\n",
      "Epoch [ 788/1000], trn los: 106.6084, trn r2: 0.6055, val loss: 2657.7418, val r2: 0.5464\n",
      "Epoch [ 789/1000], trn los: 115.4091, trn r2: 0.5730, val loss: 2653.8792, val r2: 0.5448\n",
      "Epoch [ 790/1000], trn los: 110.5347, trn r2: 0.5867, val loss: 2750.0939, val r2: 0.5280\n",
      "Epoch [ 791/1000], trn los: 112.7634, trn r2: 0.5953, val loss: 2648.5460, val r2: 0.5453\n",
      "Epoch [ 792/1000], trn los: 106.9213, trn r2: 0.6044, val loss: 2705.4582, val r2: 0.5327\n",
      "Epoch [ 793/1000], trn los: 102.9916, trn r2: 0.6121, val loss: 2732.3507, val r2: 0.5302\n",
      "Epoch [ 794/1000], trn los: 117.3237, trn r2: 0.5819, val loss: 2714.2927, val r2: 0.5357\n",
      "Epoch [ 795/1000], trn los: 121.2447, trn r2: 0.5745, val loss: 2789.9243, val r2: 0.5213\n",
      "Epoch [ 796/1000], trn los:  95.3118, trn r2: 0.6451, val loss: 2747.3910, val r2: 0.5261\n",
      "Epoch [ 797/1000], trn los: 114.9712, trn r2: 0.5744, val loss: 2647.9112, val r2: 0.5469\n",
      "Epoch [ 798/1000], trn los: 106.0508, trn r2: 0.5994, val loss: 2630.9997, val r2: 0.5473\n",
      "Epoch [ 799/1000], trn los: 111.3969, trn r2: 0.5816, val loss: 2688.0100, val r2: 0.5385\n",
      "Epoch [ 800/1000], trn los: 110.6003, trn r2: 0.5907, val loss: 2716.8472, val r2: 0.5329\n",
      "Epoch [ 801/1000], trn los: 103.4438, trn r2: 0.6107, val loss: 2605.7999, val r2: 0.5530\n",
      "Epoch [ 802/1000], trn los: 107.4668, trn r2: 0.6084, val loss: 2666.4593, val r2: 0.5423\n",
      "Epoch [ 803/1000], trn los: 109.6176, trn r2: 0.5810, val loss: 2781.3514, val r2: 0.5216\n",
      "Epoch [ 804/1000], trn los: 113.3313, trn r2: 0.5694, val loss: 2631.0991, val r2: 0.5454\n",
      "Epoch [ 805/1000], trn los: 106.0442, trn r2: 0.5980, val loss: 2786.6469, val r2: 0.5243\n",
      "Epoch [ 806/1000], trn los: 109.7787, trn r2: 0.5826, val loss: 2675.5253, val r2: 0.5404\n",
      "Epoch [ 807/1000], trn los: 101.3323, trn r2: 0.6141, val loss: 2739.6202, val r2: 0.5310\n",
      "Epoch [ 808/1000], trn los: 107.7435, trn r2: 0.5890, val loss: 2673.8939, val r2: 0.5416\n",
      "Epoch [ 809/1000], trn los: 103.4809, trn r2: 0.6044, val loss: 2869.4877, val r2: 0.5077\n",
      "Epoch [ 810/1000], trn los: 105.2556, trn r2: 0.5962, val loss: 2786.1112, val r2: 0.5258\n",
      "Epoch [ 811/1000], trn los: 107.8925, trn r2: 0.5970, val loss: 2685.2033, val r2: 0.5408\n",
      "Epoch [ 812/1000], trn los: 110.8402, trn r2: 0.5963, val loss: 2696.0911, val r2: 0.5376\n",
      "Epoch [ 813/1000], trn los: 112.9945, trn r2: 0.5927, val loss: 2661.2568, val r2: 0.5431\n",
      "Epoch [ 814/1000], trn los: 111.1652, trn r2: 0.5830, val loss: 2748.5096, val r2: 0.5262\n",
      "Epoch [ 815/1000], trn los: 104.0175, trn r2: 0.6127, val loss: 2737.3743, val r2: 0.5309\n",
      "Epoch [ 816/1000], trn los: 109.0344, trn r2: 0.5850, val loss: 2765.1329, val r2: 0.5266\n",
      "Epoch [ 817/1000], trn los: 111.8177, trn r2: 0.5864, val loss: 2586.4103, val r2: 0.5568\n",
      "Epoch [ 818/1000], trn los: 110.4760, trn r2: 0.5814, val loss: 2669.7914, val r2: 0.5408\n",
      "Epoch [ 819/1000], trn los: 102.1424, trn r2: 0.6122, val loss: 2563.2868, val r2: 0.5631\n",
      "Epoch [ 820/1000], trn los: 102.0648, trn r2: 0.6098, val loss: 2603.0279, val r2: 0.5542\n",
      "Epoch [ 821/1000], trn los: 107.7648, trn r2: 0.5857, val loss: 2598.2067, val r2: 0.5555\n",
      "Epoch [ 822/1000], trn los:  94.7075, trn r2: 0.6315, val loss: 2750.5412, val r2: 0.5308\n",
      "Epoch [ 823/1000], trn los: 100.7972, trn r2: 0.6122, val loss: 2821.2308, val r2: 0.5188\n",
      "Epoch [ 824/1000], trn los: 101.8555, trn r2: 0.6130, val loss: 2840.9528, val r2: 0.5157\n",
      "Epoch [ 825/1000], trn los: 106.7427, trn r2: 0.5968, val loss: 2636.8625, val r2: 0.5471\n",
      "Epoch [ 826/1000], trn los: 102.8018, trn r2: 0.5960, val loss: 2701.6412, val r2: 0.5361\n",
      "Epoch [ 827/1000], trn los: 107.6270, trn r2: 0.5796, val loss: 2614.8904, val r2: 0.5524\n",
      "Epoch [ 828/1000], trn los: 105.2438, trn r2: 0.5918, val loss: 2657.1016, val r2: 0.5434\n",
      "Epoch [ 829/1000], trn los: 112.5637, trn r2: 0.5627, val loss: 2622.0716, val r2: 0.5477\n",
      "Epoch [ 830/1000], trn los: 108.9129, trn r2: 0.5828, val loss: 2681.2900, val r2: 0.5397\n",
      "Epoch [ 831/1000], trn los:  99.9822, trn r2: 0.6069, val loss: 2827.3336, val r2: 0.5151\n",
      "Epoch [ 832/1000], trn los: 103.9615, trn r2: 0.5997, val loss: 2784.6402, val r2: 0.5234\n",
      "Epoch [ 833/1000], trn los:  98.4499, trn r2: 0.6138, val loss: 2783.8522, val r2: 0.5213\n",
      "Epoch [ 834/1000], trn los: 100.7443, trn r2: 0.6044, val loss: 2704.9364, val r2: 0.5355\n",
      "Epoch [ 835/1000], trn los: 101.5628, trn r2: 0.6069, val loss: 2827.9353, val r2: 0.5157\n",
      "Epoch [ 836/1000], trn los: 100.7095, trn r2: 0.6076, val loss: 2653.6372, val r2: 0.5431\n",
      "Epoch [ 837/1000], trn los:  99.0115, trn r2: 0.6196, val loss: 2691.3944, val r2: 0.5373\n",
      "Epoch [ 838/1000], trn los:  98.8037, trn r2: 0.6171, val loss: 2713.8482, val r2: 0.5309\n",
      "Epoch [ 839/1000], trn los: 102.9031, trn r2: 0.5897, val loss: 2660.2490, val r2: 0.5460\n",
      "Epoch [ 840/1000], trn los:  96.0160, trn r2: 0.6333, val loss: 2736.9945, val r2: 0.5341\n",
      "Epoch [ 841/1000], trn los:  98.3538, trn r2: 0.6099, val loss: 2711.5369, val r2: 0.5348\n",
      "Epoch [ 842/1000], trn los:  98.2058, trn r2: 0.6096, val loss: 2685.5952, val r2: 0.5384\n",
      "Epoch [ 843/1000], trn los: 102.0510, trn r2: 0.5967, val loss: 2683.8985, val r2: 0.5432\n",
      "Epoch [ 844/1000], trn los:  97.7477, trn r2: 0.6108, val loss: 2936.4266, val r2: 0.4954\n",
      "Epoch [ 845/1000], trn los: 106.8087, trn r2: 0.5866, val loss: 3050.5898, val r2: 0.4759\n",
      "Epoch [ 846/1000], trn los:  98.5849, trn r2: 0.6044, val loss: 2881.3378, val r2: 0.5052\n",
      "Epoch [ 847/1000], trn los:  98.7314, trn r2: 0.6171, val loss: 2693.9467, val r2: 0.5432\n",
      "Epoch [ 848/1000], trn los:  88.4486, trn r2: 0.6440, val loss: 2672.6529, val r2: 0.5423\n",
      "Epoch [ 849/1000], trn los:  95.0257, trn r2: 0.6204, val loss: 2634.0103, val r2: 0.5554\n",
      "Epoch [ 850/1000], trn los:  99.8326, trn r2: 0.6175, val loss: 2710.2210, val r2: 0.5386\n",
      "Epoch [ 851/1000], trn los: 108.7858, trn r2: 0.5623, val loss: 2739.6215, val r2: 0.5282\n",
      "Epoch [ 852/1000], trn los:  95.8838, trn r2: 0.6163, val loss: 2668.0321, val r2: 0.5408\n",
      "Epoch [ 853/1000], trn los: 101.5764, trn r2: 0.5918, val loss: 2919.1475, val r2: 0.4984\n",
      "Epoch [ 854/1000], trn los: 100.3938, trn r2: 0.6041, val loss: 2794.3112, val r2: 0.5187\n",
      "Epoch [ 855/1000], trn los:  95.5154, trn r2: 0.6155, val loss: 2748.7479, val r2: 0.5279\n",
      "Epoch [ 856/1000], trn los:  96.3489, trn r2: 0.6201, val loss: 2815.0209, val r2: 0.5174\n",
      "Epoch [ 857/1000], trn los:  93.9031, trn r2: 0.6200, val loss: 3043.7158, val r2: 0.4770\n",
      "Epoch [ 858/1000], trn los:  91.7608, trn r2: 0.6253, val loss: 2683.0139, val r2: 0.5404\n",
      "Epoch [ 859/1000], trn los:  90.7515, trn r2: 0.6306, val loss: 2679.3584, val r2: 0.5396\n",
      "Epoch [ 860/1000], trn los:  95.1761, trn r2: 0.6119, val loss: 2702.3218, val r2: 0.5344\n",
      "Epoch [ 861/1000], trn los:  92.8530, trn r2: 0.6231, val loss: 2656.7151, val r2: 0.5443\n",
      "Epoch [ 862/1000], trn los:  94.1611, trn r2: 0.6189, val loss: 2687.2893, val r2: 0.5386\n",
      "Epoch [ 863/1000], trn los: 103.7044, trn r2: 0.5854, val loss: 3399.3634, val r2: 0.4193\n",
      "Epoch [ 864/1000], trn los: 102.3409, trn r2: 0.5792, val loss: 2857.0327, val r2: 0.5085\n",
      "Epoch [ 865/1000], trn los:  97.1545, trn r2: 0.6094, val loss: 2698.6894, val r2: 0.5374\n",
      "Epoch [ 866/1000], trn los:  98.1875, trn r2: 0.5991, val loss: 2732.3131, val r2: 0.5317\n",
      "Epoch [ 867/1000], trn los:  92.2843, trn r2: 0.6255, val loss: 2704.7129, val r2: 0.5359\n",
      "Epoch [ 868/1000], trn los:  98.2792, trn r2: 0.5999, val loss: 2783.7518, val r2: 0.5245\n",
      "Epoch [ 869/1000], trn los:  94.1975, trn r2: 0.6127, val loss: 2694.2876, val r2: 0.5371\n",
      "Epoch [ 870/1000], trn los:  97.9991, trn r2: 0.5970, val loss: 2802.3564, val r2: 0.5197\n",
      "Epoch [ 871/1000], trn los: 100.0539, trn r2: 0.6006, val loss: 2741.9881, val r2: 0.5280\n",
      "Epoch [ 872/1000], trn los:  92.0162, trn r2: 0.6214, val loss: 2897.7775, val r2: 0.5010\n",
      "Epoch [ 873/1000], trn los: 106.0185, trn r2: 0.5980, val loss: 2908.2571, val r2: 0.5016\n",
      "Epoch [ 874/1000], trn los:  97.7113, trn r2: 0.6024, val loss: 2780.3920, val r2: 0.5237\n",
      "Epoch [ 875/1000], trn los:  94.6012, trn r2: 0.6090, val loss: 2839.4980, val r2: 0.5172\n",
      "Epoch [ 876/1000], trn los:  91.3706, trn r2: 0.6249, val loss: 2723.6729, val r2: 0.5323\n",
      "Epoch [ 877/1000], trn los:  99.3520, trn r2: 0.5998, val loss: 2843.4651, val r2: 0.5147\n",
      "Epoch [ 878/1000], trn los: 104.9954, trn r2: 0.5758, val loss: 2735.2621, val r2: 0.5293\n",
      "Epoch [ 879/1000], trn los:  91.9182, trn r2: 0.6172, val loss: 2633.6419, val r2: 0.5457\n",
      "Epoch [ 880/1000], trn los:  94.4284, trn r2: 0.6072, val loss: 2672.9779, val r2: 0.5429\n",
      "Epoch [ 881/1000], trn los:  98.7092, trn r2: 0.5890, val loss: 3071.1805, val r2: 0.4740\n",
      "Epoch [ 882/1000], trn los:  92.8843, trn r2: 0.6114, val loss: 2781.5957, val r2: 0.5283\n",
      "Epoch [ 883/1000], trn los:  92.2043, trn r2: 0.6163, val loss: 2801.8858, val r2: 0.5216\n",
      "Epoch [ 884/1000], trn los:  88.5551, trn r2: 0.6355, val loss: 2674.7289, val r2: 0.5385\n",
      "Epoch [ 885/1000], trn los:  89.4774, trn r2: 0.6246, val loss: 2691.4992, val r2: 0.5380\n",
      "Epoch [ 886/1000], trn los:  91.8247, trn r2: 0.6235, val loss: 2796.8561, val r2: 0.5224\n",
      "Epoch [ 887/1000], trn los:  87.2884, trn r2: 0.6390, val loss: 2769.3480, val r2: 0.5282\n",
      "Epoch [ 888/1000], trn los:  89.6423, trn r2: 0.6246, val loss: 2831.6534, val r2: 0.5121\n",
      "Epoch [ 889/1000], trn los:  91.0665, trn r2: 0.6186, val loss: 2707.3305, val r2: 0.5376\n",
      "Epoch [ 890/1000], trn los:  92.7501, trn r2: 0.6093, val loss: 2800.8192, val r2: 0.5221\n",
      "Epoch [ 891/1000], trn los:  91.9261, trn r2: 0.6132, val loss: 2744.6698, val r2: 0.5305\n",
      "Epoch [ 892/1000], trn los:  94.6412, trn r2: 0.6223, val loss: 2750.5659, val r2: 0.5306\n",
      "Epoch [ 893/1000], trn los:  83.9528, trn r2: 0.6451, val loss: 2737.7469, val r2: 0.5303\n",
      "Epoch [ 894/1000], trn los:  86.8396, trn r2: 0.6317, val loss: 2994.8272, val r2: 0.4889\n",
      "Epoch [ 895/1000], trn los:  87.4010, trn r2: 0.6293, val loss: 2631.2064, val r2: 0.5469\n",
      "Epoch [ 896/1000], trn los:  91.5752, trn r2: 0.6145, val loss: 2724.6638, val r2: 0.5357\n",
      "Epoch [ 897/1000], trn los:  90.4022, trn r2: 0.6246, val loss: 2751.6666, val r2: 0.5289\n",
      "Epoch [ 898/1000], trn los:  91.3358, trn r2: 0.6344, val loss: 2753.8897, val r2: 0.5269\n",
      "Epoch [ 899/1000], trn los:  87.5319, trn r2: 0.6354, val loss: 2872.0527, val r2: 0.5087\n",
      "Epoch [ 900/1000], trn los:  89.7511, trn r2: 0.6199, val loss: 2740.8882, val r2: 0.5366\n",
      "Epoch [ 901/1000], trn los:  82.8853, trn r2: 0.6482, val loss: 2862.0948, val r2: 0.5129\n",
      "Epoch [ 902/1000], trn los:  86.9802, trn r2: 0.6272, val loss: 2659.3992, val r2: 0.5428\n",
      "Epoch [ 903/1000], trn los:  94.3337, trn r2: 0.6077, val loss: 2778.8647, val r2: 0.5274\n",
      "Epoch [ 904/1000], trn los:  92.7168, trn r2: 0.6096, val loss: 2675.8160, val r2: 0.5453\n",
      "Epoch [ 905/1000], trn los:  89.2692, trn r2: 0.6194, val loss: 2879.2775, val r2: 0.5091\n",
      "Epoch [ 906/1000], trn los:  88.0272, trn r2: 0.6225, val loss: 2721.8002, val r2: 0.5337\n",
      "Epoch [ 907/1000], trn los:  91.2872, trn r2: 0.6130, val loss: 2907.3668, val r2: 0.4989\n",
      "Epoch [ 908/1000], trn los:  94.1721, trn r2: 0.5999, val loss: 2781.6405, val r2: 0.5230\n",
      "Epoch [ 909/1000], trn los:  88.1315, trn r2: 0.6218, val loss: 2949.7443, val r2: 0.4913\n",
      "Epoch [ 910/1000], trn los:  83.5933, trn r2: 0.6447, val loss: 2734.0536, val r2: 0.5317\n",
      "Epoch [ 911/1000], trn los:  88.9803, trn r2: 0.6200, val loss: 2762.7148, val r2: 0.5292\n",
      "Epoch [ 912/1000], trn los:  93.7905, trn r2: 0.6065, val loss: 2723.9581, val r2: 0.5312\n",
      "Epoch [ 913/1000], trn los:  83.3743, trn r2: 0.6432, val loss: 2757.0572, val r2: 0.5314\n",
      "Epoch [ 914/1000], trn los:  80.1133, trn r2: 0.6576, val loss: 2649.5028, val r2: 0.5466\n",
      "Epoch [ 915/1000], trn los:  85.8291, trn r2: 0.6289, val loss: 2684.3322, val r2: 0.5374\n",
      "Epoch [ 916/1000], trn los:  86.9523, trn r2: 0.6263, val loss: 2821.5443, val r2: 0.5238\n",
      "Epoch [ 917/1000], trn los:  86.2755, trn r2: 0.6307, val loss: 2771.2076, val r2: 0.5296\n",
      "Epoch [ 918/1000], trn los:  85.3482, trn r2: 0.6396, val loss: 2755.9595, val r2: 0.5274\n",
      "Epoch [ 919/1000], trn los:  83.8130, trn r2: 0.6384, val loss: 2742.9235, val r2: 0.5355\n",
      "Epoch [ 920/1000], trn los:  86.2220, trn r2: 0.6390, val loss: 2844.9479, val r2: 0.5089\n",
      "Epoch [ 921/1000], trn los:  93.2904, trn r2: 0.5997, val loss: 2680.9326, val r2: 0.5370\n",
      "Epoch [ 922/1000], trn los:  85.0109, trn r2: 0.6347, val loss: 2723.4516, val r2: 0.5300\n",
      "Epoch [ 923/1000], trn los:  85.2691, trn r2: 0.6312, val loss: 2818.8835, val r2: 0.5169\n",
      "Epoch [ 924/1000], trn los:  87.8904, trn r2: 0.6249, val loss: 2795.2002, val r2: 0.5182\n",
      "Epoch [ 925/1000], trn los:  72.6090, trn r2: 0.6847, val loss: 2722.7820, val r2: 0.5365\n",
      "Epoch [ 926/1000], trn los:  86.6620, trn r2: 0.6253, val loss: 2916.9959, val r2: 0.5040\n",
      "Epoch [ 927/1000], trn los:  85.6263, trn r2: 0.6286, val loss: 2827.6838, val r2: 0.5170\n",
      "Epoch [ 928/1000], trn los:  87.6728, trn r2: 0.6139, val loss: 2855.4864, val r2: 0.5131\n",
      "Epoch [ 929/1000], trn los:  78.4681, trn r2: 0.6566, val loss: 2889.7543, val r2: 0.5058\n",
      "Epoch [ 930/1000], trn los:  86.4170, trn r2: 0.6214, val loss: 2793.6774, val r2: 0.5225\n",
      "Epoch [ 931/1000], trn los:  81.9258, trn r2: 0.6469, val loss: 2726.8444, val r2: 0.5293\n",
      "Epoch [ 932/1000], trn los:  80.2603, trn r2: 0.6479, val loss: 2696.9627, val r2: 0.5377\n",
      "Epoch [ 933/1000], trn los:  82.2168, trn r2: 0.6385, val loss: 2728.0336, val r2: 0.5318\n",
      "Epoch [ 934/1000], trn los:  79.3911, trn r2: 0.6489, val loss: 2714.5610, val r2: 0.5315\n",
      "Epoch [ 935/1000], trn los:  80.3249, trn r2: 0.6460, val loss: 2876.7961, val r2: 0.5107\n",
      "Epoch [ 936/1000], trn los:  76.7994, trn r2: 0.6611, val loss: 2728.9933, val r2: 0.5349\n",
      "Epoch [ 937/1000], trn los:  76.2376, trn r2: 0.6622, val loss: 2865.1331, val r2: 0.5106\n",
      "Epoch [ 938/1000], trn los:  90.8706, trn r2: 0.6080, val loss: 2792.4005, val r2: 0.5200\n",
      "Epoch [ 939/1000], trn los:  88.5548, trn r2: 0.6152, val loss: 2817.2727, val r2: 0.5150\n",
      "Epoch [ 940/1000], trn los:  81.2015, trn r2: 0.6367, val loss: 2715.3454, val r2: 0.5334\n",
      "Epoch [ 941/1000], trn los:  92.0884, trn r2: 0.6005, val loss: 2920.5729, val r2: 0.4998\n",
      "Epoch [ 942/1000], trn los:  84.4791, trn r2: 0.6249, val loss: 2773.6785, val r2: 0.5280\n",
      "Epoch [ 943/1000], trn los:  77.7199, trn r2: 0.6595, val loss: 2863.0892, val r2: 0.5087\n",
      "Epoch [ 944/1000], trn los:  79.2725, trn r2: 0.6453, val loss: 2763.9281, val r2: 0.5237\n",
      "Epoch [ 945/1000], trn los:  77.0222, trn r2: 0.6570, val loss: 2746.0619, val r2: 0.5257\n",
      "Epoch [ 946/1000], trn los:  76.1179, trn r2: 0.6695, val loss: 2792.9995, val r2: 0.5258\n",
      "Epoch [ 947/1000], trn los:  84.2681, trn r2: 0.6280, val loss: 2835.6517, val r2: 0.5159\n",
      "Epoch [ 948/1000], trn los:  81.0808, trn r2: 0.6342, val loss: 2817.4833, val r2: 0.5220\n",
      "Epoch [ 949/1000], trn los:  82.8466, trn r2: 0.6355, val loss: 2767.9754, val r2: 0.5227\n",
      "Epoch [ 950/1000], trn los:  79.2975, trn r2: 0.6467, val loss: 2821.9329, val r2: 0.5169\n",
      "Epoch [ 951/1000], trn los:  80.7173, trn r2: 0.6392, val loss: 3017.6772, val r2: 0.4880\n",
      "Epoch [ 952/1000], trn los:  82.2927, trn r2: 0.6273, val loss: 2810.2651, val r2: 0.5179\n",
      "Epoch [ 953/1000], trn los:  80.4785, trn r2: 0.6549, val loss: 2826.2816, val r2: 0.5139\n",
      "Epoch [ 954/1000], trn los:  77.1358, trn r2: 0.6584, val loss: 2630.8514, val r2: 0.5466\n",
      "Epoch [ 955/1000], trn los:  81.1207, trn r2: 0.6393, val loss: 2699.2069, val r2: 0.5334\n",
      "Epoch [ 956/1000], trn los:  85.9595, trn r2: 0.6330, val loss: 2834.3636, val r2: 0.5139\n",
      "Epoch [ 957/1000], trn los:  74.8366, trn r2: 0.6662, val loss: 2846.1791, val r2: 0.5146\n",
      "Epoch [ 958/1000], trn los:  80.4163, trn r2: 0.6374, val loss: 2736.8134, val r2: 0.5351\n",
      "Epoch [ 959/1000], trn los:  72.5514, trn r2: 0.6721, val loss: 2769.2948, val r2: 0.5238\n",
      "Epoch [ 960/1000], trn los:  85.0951, trn r2: 0.6140, val loss: 2699.3497, val r2: 0.5391\n",
      "Epoch [ 961/1000], trn los:  78.2111, trn r2: 0.6557, val loss: 2767.9668, val r2: 0.5240\n",
      "Epoch [ 962/1000], trn los:  76.6068, trn r2: 0.6565, val loss: 2801.6079, val r2: 0.5257\n",
      "Epoch [ 963/1000], trn los:  82.1546, trn r2: 0.6327, val loss: 2877.7714, val r2: 0.5070\n",
      "Epoch [ 964/1000], trn los:  76.7615, trn r2: 0.6586, val loss: 2844.8969, val r2: 0.5140\n",
      "Epoch [ 965/1000], trn los:  76.8215, trn r2: 0.6478, val loss: 2746.3178, val r2: 0.5288\n",
      "Epoch [ 966/1000], trn los:  81.0512, trn r2: 0.6329, val loss: 2765.2164, val r2: 0.5264\n",
      "Epoch [ 967/1000], trn los:  71.7328, trn r2: 0.6755, val loss: 2904.7779, val r2: 0.5038\n",
      "Epoch [ 968/1000], trn los:  78.1885, trn r2: 0.6586, val loss: 3093.1294, val r2: 0.4823\n",
      "Epoch [ 969/1000], trn los:  82.1712, trn r2: 0.6285, val loss: 2793.8757, val r2: 0.5214\n",
      "Epoch [ 970/1000], trn los:  72.6189, trn r2: 0.6661, val loss: 2976.0101, val r2: 0.4883\n",
      "Epoch [ 971/1000], trn los:  76.2807, trn r2: 0.6499, val loss: 2907.9163, val r2: 0.4979\n",
      "Epoch [ 972/1000], trn los:  74.1185, trn r2: 0.6740, val loss: 2818.8955, val r2: 0.5163\n",
      "Epoch [ 973/1000], trn los:  77.1233, trn r2: 0.6530, val loss: 2992.9725, val r2: 0.4862\n",
      "Epoch [ 974/1000], trn los:  72.9022, trn r2: 0.6674, val loss: 2805.6677, val r2: 0.5238\n",
      "Epoch [ 975/1000], trn los:  79.9857, trn r2: 0.6405, val loss: 2754.3780, val r2: 0.5260\n",
      "Epoch [ 976/1000], trn los:  74.9937, trn r2: 0.6661, val loss: 2892.5126, val r2: 0.5049\n",
      "Epoch [ 977/1000], trn los:  76.1898, trn r2: 0.6509, val loss: 2794.4453, val r2: 0.5172\n",
      "Epoch [ 978/1000], trn los:  78.8333, trn r2: 0.6361, val loss: 2739.1208, val r2: 0.5310\n",
      "Epoch [ 979/1000], trn los:  74.8910, trn r2: 0.6593, val loss: 2824.9446, val r2: 0.5149\n",
      "Epoch [ 980/1000], trn los:  81.4759, trn r2: 0.6261, val loss: 2720.3298, val r2: 0.5325\n",
      "Epoch [ 981/1000], trn los:  82.9151, trn r2: 0.6265, val loss: 2713.2712, val r2: 0.5352\n",
      "Epoch [ 982/1000], trn los:  73.1604, trn r2: 0.6604, val loss: 2753.1943, val r2: 0.5251\n",
      "Epoch [ 983/1000], trn los:  72.2163, trn r2: 0.6661, val loss: 2833.8185, val r2: 0.5122\n",
      "Epoch [ 984/1000], trn los:  69.6727, trn r2: 0.6747, val loss: 2705.2219, val r2: 0.5345\n",
      "Epoch [ 985/1000], trn los:  75.9122, trn r2: 0.6447, val loss: 2874.4973, val r2: 0.5086\n",
      "Epoch [ 986/1000], trn los:  77.6886, trn r2: 0.6400, val loss: 2720.8906, val r2: 0.5315\n",
      "Epoch [ 987/1000], trn los:  75.2175, trn r2: 0.6507, val loss: 2726.5810, val r2: 0.5323\n",
      "Epoch [ 988/1000], trn los:  74.9922, trn r2: 0.6507, val loss: 2770.0782, val r2: 0.5264\n",
      "Epoch [ 989/1000], trn los:  69.9935, trn r2: 0.6834, val loss: 2704.5671, val r2: 0.5359\n",
      "Epoch [ 990/1000], trn los:  71.6064, trn r2: 0.6785, val loss: 2960.5834, val r2: 0.4943\n",
      "Epoch [ 991/1000], trn los:  75.5765, trn r2: 0.6448, val loss: 2793.5455, val r2: 0.5195\n",
      "Epoch [ 992/1000], trn los:  69.8941, trn r2: 0.6736, val loss: 2845.6317, val r2: 0.5116\n",
      "Epoch [ 993/1000], trn los:  66.6363, trn r2: 0.6912, val loss: 2833.2411, val r2: 0.5151\n",
      "Epoch [ 994/1000], trn los:  69.2156, trn r2: 0.6742, val loss: 2834.4939, val r2: 0.5115\n",
      "Epoch [ 995/1000], trn los:  69.9727, trn r2: 0.6699, val loss: 2786.0962, val r2: 0.5221\n",
      "Epoch [ 996/1000], trn los:  69.2083, trn r2: 0.6769, val loss: 2855.4629, val r2: 0.5111\n",
      "Epoch [ 997/1000], trn los:  76.3936, trn r2: 0.6520, val loss: 2846.1882, val r2: 0.5109\n",
      "Epoch [ 998/1000], trn los:  69.9794, trn r2: 0.6682, val loss: 2853.0671, val r2: 0.5126\n",
      "Epoch [ 999/1000], trn los:  72.3767, trn r2: 0.6589, val loss: 2779.4897, val r2: 0.5208\n",
      "Epoch [1000/1000], trn los:  68.0498, trn r2: 0.6871, val loss: 2906.0048, val r2: 0.4994\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ddbb6cbf74ee9b26"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
